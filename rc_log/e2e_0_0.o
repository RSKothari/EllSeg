------
parsed arguments:
{'batchsize': 48,
 'curObj': 0,
 'disp': 0,
 'epochs': 100,
 'expname': 'e2e_0_0',
 'loadfile': '',
 'lr': 0.0005,
 'model': 'ritnet',
 'overfit': 0,
 'path2data': '/home/rsk3900/Datasets/',
 'prec': 32,
 'resume': 0,
 'selfCorr': 0,
 'workers': 8}
Total number of trainable parameters: 1606317

Epoch:0 [0/412], Loss: 4395.429
Epoch:0 [10/412], Loss: 107.958
Epoch:0 [20/412], Loss: 118.851
Epoch:0 [30/412], Loss: 20.119
Epoch:0 [40/412], Loss: 19.050
Epoch:0 [50/412], Loss: 14.530
Epoch:0 [60/412], Loss: 13.281
Epoch:0 [70/412], Loss: 11.867
Epoch:0 [80/412], Loss: 10.231
Epoch:0 [90/412], Loss: 9.086
Epoch:0 [100/412], Loss: 7.634
Epoch:0 [110/412], Loss: 8.981
Epoch:0 [120/412], Loss: 8.554
Epoch:0 [130/412], Loss: 6.039
Epoch:0 [140/412], Loss: 7.355
Epoch:0 [150/412], Loss: 6.456
Epoch:0 [160/412], Loss: 5.923
Epoch:0 [170/412], Loss: 6.229
Epoch:0 [180/412], Loss: 6.184
Epoch:0 [190/412], Loss: 4.805
Epoch:0 [200/412], Loss: 5.325
Epoch:0 [210/412], Loss: 4.176
Epoch:0 [220/412], Loss: 4.877
Epoch:0 [230/412], Loss: 4.681
Epoch:0 [240/412], Loss: 4.368
Epoch:0 [250/412], Loss: 4.630
Epoch:0 [260/412], Loss: 4.159
Epoch:0 [270/412], Loss: 4.399
Epoch:0 [280/412], Loss: 4.913
Epoch:0 [290/412], Loss: 3.914
Epoch:0 [300/412], Loss: 3.611
Epoch:0 [310/412], Loss: 3.938
Epoch:0 [320/412], Loss: 3.040
Epoch:0 [330/412], Loss: 4.072
Epoch:0 [340/412], Loss: 3.483
Epoch:0 [350/412], Loss: 3.307
Epoch:0 [360/412], Loss: 3.213
Epoch:0 [370/412], Loss: 3.045
Epoch:0 [380/412], Loss: 3.227
Epoch:0 [390/412], Loss: 2.933
Epoch:0 [400/412], Loss: 3.315
Epoch:0 [410/412], Loss: 3.080
Epoch:0, Train IoU: [0.91067534 0.41605654 0.59818165]
Epoch:0, Valid Loss: 2.519, mIoU: 0.8439730467539146
Validation metric decreased (inf --> 2.518551).  Saving model ...
Epoch:1 [0/412], Loss: 3.420
Epoch:1 [10/412], Loss: 2.999
Epoch:1 [20/412], Loss: 3.417
Epoch:1 [30/412], Loss: 2.507
Epoch:1 [40/412], Loss: 2.709
Epoch:1 [50/412], Loss: 3.471
Epoch:1 [60/412], Loss: 3.162
Epoch:1 [70/412], Loss: 2.820
Epoch:1 [80/412], Loss: 2.570
Epoch:1 [90/412], Loss: 3.257
Epoch:1 [100/412], Loss: 3.004
Epoch:1 [110/412], Loss: 2.609
Epoch:1 [120/412], Loss: 3.781
Epoch:1 [130/412], Loss: 2.428
Epoch:1 [140/412], Loss: 3.068
Epoch:1 [150/412], Loss: 3.310
Epoch:1 [160/412], Loss: 2.776
Epoch:1 [170/412], Loss: 2.683
Epoch:1 [180/412], Loss: 3.365
Epoch:1 [190/412], Loss: 2.827
Epoch:1 [200/412], Loss: 2.264
Epoch:1 [210/412], Loss: 2.555
Epoch:1 [220/412], Loss: 2.423
Epoch:1 [230/412], Loss: 2.524
Epoch:1 [240/412], Loss: 2.444
Epoch:1 [250/412], Loss: 2.397
Epoch:1 [260/412], Loss: 2.717
Epoch:1 [270/412], Loss: 2.662
Epoch:1 [280/412], Loss: 1.949
Epoch:1 [290/412], Loss: 2.534
Epoch:1 [300/412], Loss: 2.259
Epoch:1 [310/412], Loss: 2.395
Epoch:1 [320/412], Loss: 2.241
Epoch:1 [330/412], Loss: 2.760
Epoch:1 [340/412], Loss: 2.102
Epoch:1 [350/412], Loss: 1.979
Epoch:1 [360/412], Loss: 2.380
Epoch:1 [370/412], Loss: 2.618
Epoch:1 [380/412], Loss: 2.377
Epoch:1 [390/412], Loss: 2.153
Epoch:1 [400/412], Loss: 2.266
Epoch:1 [410/412], Loss: 2.091
Epoch:1, Train IoU: [0.96352828 0.72295245 0.82244599]
Epoch:1, Valid Loss: 1.737, mIoU: 0.8868945600338741
Validation metric decreased (2.518551 --> 1.736672).  Saving model ...
Epoch:2 [0/412], Loss: 2.215
Epoch:2 [10/412], Loss: 2.075
Epoch:2 [20/412], Loss: 1.841
Epoch:2 [30/412], Loss: 2.082
Epoch:2 [40/412], Loss: 1.887
Epoch:2 [50/412], Loss: 2.022
Epoch:2 [60/412], Loss: 2.020
Epoch:2 [70/412], Loss: 2.013
Epoch:2 [80/412], Loss: 1.825
Epoch:2 [90/412], Loss: 1.875
Epoch:2 [100/412], Loss: 1.806
Epoch:2 [110/412], Loss: 2.281
Epoch:2 [120/412], Loss: 2.323
Epoch:2 [130/412], Loss: 1.861
Epoch:2 [140/412], Loss: 2.011
Epoch:2 [150/412], Loss: 1.936
Epoch:2 [160/412], Loss: 2.277
Epoch:2 [170/412], Loss: 2.066
Epoch:2 [180/412], Loss: 1.681
Epoch:2 [190/412], Loss: 1.754
Epoch:2 [200/412], Loss: 2.084
Epoch:2 [210/412], Loss: 1.709
Epoch:2 [220/412], Loss: 1.752
Epoch:2 [230/412], Loss: 1.864
Epoch:2 [240/412], Loss: 2.427
Epoch:2 [250/412], Loss: 2.047
Epoch:2 [260/412], Loss: 1.856
Epoch:2 [270/412], Loss: 2.032
Epoch:2 [280/412], Loss: 2.140
Epoch:2 [290/412], Loss: 2.114
Epoch:2 [300/412], Loss: 1.831
Epoch:2 [310/412], Loss: 2.030
Epoch:2 [320/412], Loss: 1.546
Epoch:2 [330/412], Loss: 2.076
Epoch:2 [340/412], Loss: 1.928
Epoch:2 [350/412], Loss: 1.946
Epoch:2 [360/412], Loss: 1.901
Epoch:2 [370/412], Loss: 1.692
Epoch:2 [380/412], Loss: 1.578
Epoch:2 [390/412], Loss: 1.620
Epoch:2 [400/412], Loss: 1.606
Epoch:2 [410/412], Loss: 1.694
Epoch:2, Train IoU: [0.97289298 0.78849032 0.85821944]
Epoch:2, Valid Loss: 1.420, mIoU: 0.9046224886902042
Validation metric decreased (1.736672 --> 1.420436).  Saving model ...
Epoch:3 [0/412], Loss: 1.865
Epoch:3 [10/412], Loss: 1.882
Epoch:3 [20/412], Loss: 1.977
Epoch:3 [30/412], Loss: 1.763
Epoch:3 [40/412], Loss: 1.971
Epoch:3 [50/412], Loss: 1.596
Epoch:3 [60/412], Loss: 1.687
Epoch:3 [70/412], Loss: 1.633
Epoch:3 [80/412], Loss: 1.779
Epoch:3 [90/412], Loss: 1.715
Epoch:3 [100/412], Loss: 1.353
Epoch:3 [110/412], Loss: 1.441
Epoch:3 [120/412], Loss: 1.764
Epoch:3 [130/412], Loss: 1.676
Epoch:3 [140/412], Loss: 1.611
Epoch:3 [150/412], Loss: 1.964
Epoch:3 [160/412], Loss: 1.768
Epoch:3 [170/412], Loss: 1.467
Epoch:3 [180/412], Loss: 1.467
Epoch:3 [190/412], Loss: 1.612
Epoch:3 [200/412], Loss: 1.497
Epoch:3 [210/412], Loss: 1.573
Epoch:3 [220/412], Loss: 1.510
Epoch:3 [230/412], Loss: 1.291
Epoch:3 [240/412], Loss: 1.546
Epoch:3 [250/412], Loss: 1.840
Epoch:3 [260/412], Loss: 1.784
Epoch:3 [270/412], Loss: 1.655
Epoch:3 [280/412], Loss: 1.666
Epoch:3 [290/412], Loss: 1.914
Epoch:3 [300/412], Loss: 1.937
Epoch:3 [310/412], Loss: 1.318
Epoch:3 [320/412], Loss: 1.737
Epoch:3 [330/412], Loss: 1.379
Epoch:3 [340/412], Loss: 1.685
Epoch:3 [350/412], Loss: 1.957
Epoch:3 [360/412], Loss: 1.592
Epoch:3 [370/412], Loss: 1.615
Epoch:3 [380/412], Loss: 2.061
Epoch:3 [390/412], Loss: 1.835
Epoch:3 [400/412], Loss: 1.486
Epoch:3 [410/412], Loss: 1.402
Epoch:3, Train IoU: [0.97746165 0.82030746 0.87071206]
Epoch:3, Valid Loss: 1.266, mIoU: 0.9138263093698816
Validation metric decreased (1.420436 --> 1.265610).  Saving model ...
Epoch:4 [0/412], Loss: 1.843
Epoch:4 [10/412], Loss: 1.628
Epoch:4 [20/412], Loss: 1.806
Epoch:4 [30/412], Loss: 1.571
Epoch:4 [40/412], Loss: 1.522
Epoch:4 [50/412], Loss: 1.419
Epoch:4 [60/412], Loss: 1.460
Epoch:4 [70/412], Loss: 1.476
Epoch:4 [80/412], Loss: 1.452
Epoch:4 [90/412], Loss: 1.609
Epoch:4 [100/412], Loss: 1.479
Epoch:4 [110/412], Loss: 1.344
Epoch:4 [120/412], Loss: 1.716
Epoch:4 [130/412], Loss: 1.678
Epoch:4 [140/412], Loss: 1.199
Epoch:4 [150/412], Loss: 1.553
Epoch:4 [160/412], Loss: 1.247
Epoch:4 [170/412], Loss: 1.236
Epoch:4 [180/412], Loss: 1.465
Epoch:4 [190/412], Loss: 1.638
Epoch:4 [200/412], Loss: 1.850
Epoch:4 [210/412], Loss: 1.471
Epoch:4 [220/412], Loss: 1.372
Epoch:4 [230/412], Loss: 1.165
Epoch:4 [240/412], Loss: 1.341
Epoch:4 [250/412], Loss: 1.226
Epoch:4 [260/412], Loss: 1.231
Epoch:4 [270/412], Loss: 1.651
Epoch:4 [280/412], Loss: 1.439
Epoch:4 [290/412], Loss: 1.240
Epoch:4 [300/412], Loss: 1.324
Epoch:4 [310/412], Loss: 1.392
Epoch:4 [320/412], Loss: 1.532
Epoch:4 [330/412], Loss: 1.316
Epoch:4 [340/412], Loss: 1.879
Epoch:4 [350/412], Loss: 1.532
Epoch:4 [360/412], Loss: 1.179
Epoch:4 [370/412], Loss: 2.005
Epoch:4 [380/412], Loss: 1.177
Epoch:4 [390/412], Loss: 1.240
Epoch:4 [400/412], Loss: 1.380
Epoch:4 [410/412], Loss: 1.446
Epoch:4, Train IoU: [0.98060156 0.84262432 0.8842168 ]
Epoch:4, Valid Loss: 1.149, mIoU: 0.9211267654043759
Validation metric decreased (1.265610 --> 1.148892).  Saving model ...
Epoch:5 [0/412], Loss: 1.325
Epoch:5 [10/412], Loss: 1.252
Epoch:5 [20/412], Loss: 1.191
Epoch:5 [30/412], Loss: 1.319
Epoch:5 [40/412], Loss: 1.511
Epoch:5 [50/412], Loss: 1.434
Epoch:5 [60/412], Loss: 1.167
Epoch:5 [70/412], Loss: 1.229
Epoch:5 [80/412], Loss: 1.205
Epoch:5 [90/412], Loss: 1.350
Epoch:5 [100/412], Loss: 1.134
Epoch:5 [110/412], Loss: 1.356
Epoch:5 [120/412], Loss: 1.321
Epoch:5 [130/412], Loss: 1.246
Epoch:5 [140/412], Loss: 1.480
Epoch:5 [150/412], Loss: 1.374
Epoch:5 [160/412], Loss: 1.263
Epoch:5 [170/412], Loss: 1.152
Epoch:5 [180/412], Loss: 1.122
Epoch:5 [190/412], Loss: 1.911
Epoch:5 [200/412], Loss: 1.241
Epoch:5 [210/412], Loss: 1.303
Epoch:5 [220/412], Loss: 1.129
Epoch:5 [230/412], Loss: 1.044
Epoch:5 [240/412], Loss: 1.103
Epoch:5 [250/412], Loss: 1.235
Epoch:5 [260/412], Loss: 1.098
Epoch:5 [270/412], Loss: 1.222
Epoch:5 [280/412], Loss: 1.387
Epoch:5 [290/412], Loss: 1.173
Epoch:5 [300/412], Loss: 1.748
Epoch:5 [310/412], Loss: 1.028
Epoch:5 [320/412], Loss: 1.145
Epoch:5 [330/412], Loss: 1.079
Epoch:5 [340/412], Loss: 0.953
Epoch:5 [350/412], Loss: 1.165
Epoch:5 [360/412], Loss: 1.274
Epoch:5 [370/412], Loss: 1.066
Epoch:5 [380/412], Loss: 1.560
Epoch:5 [390/412], Loss: 1.048
Epoch:5 [400/412], Loss: 1.146
Epoch:5 [410/412], Loss: 1.433
Epoch:5, Train IoU: [0.98301803 0.85989466 0.89217736]
Epoch:5, Valid Loss: 1.056, mIoU: 0.9285124755918414
Validation metric decreased (1.148892 --> 1.055619).  Saving model ...
Epoch:6 [0/412], Loss: 1.501
Epoch:6 [10/412], Loss: 1.257
Epoch:6 [20/412], Loss: 1.341
Epoch:6 [30/412], Loss: 1.148
Epoch:6 [40/412], Loss: 1.423
Epoch:6 [50/412], Loss: 0.924
Epoch:6 [60/412], Loss: 1.573
Epoch:6 [70/412], Loss: 1.384
Epoch:6 [80/412], Loss: 1.384
Epoch:6 [90/412], Loss: 1.013
Epoch:6 [100/412], Loss: 1.111
Epoch:6 [110/412], Loss: 1.038
Epoch:6 [120/412], Loss: 1.127
Epoch:6 [130/412], Loss: 1.134
Epoch:6 [140/412], Loss: 1.433
Epoch:6 [150/412], Loss: 1.275
Epoch:6 [160/412], Loss: 1.155
Epoch:6 [170/412], Loss: 0.988
Epoch:6 [180/412], Loss: 0.972
Epoch:6 [190/412], Loss: 1.622
Epoch:6 [200/412], Loss: 1.478
Epoch:6 [210/412], Loss: 1.540
Epoch:6 [220/412], Loss: 1.069
Epoch:6 [230/412], Loss: 1.072
Epoch:6 [240/412], Loss: 1.151
Epoch:6 [250/412], Loss: 0.995
Epoch:6 [260/412], Loss: 1.133
Epoch:6 [270/412], Loss: 1.361
Epoch:6 [280/412], Loss: 0.964
Epoch:6 [290/412], Loss: 1.602
Epoch:6 [300/412], Loss: 1.222
Epoch:6 [310/412], Loss: 0.922
Epoch:6 [320/412], Loss: 0.953
Epoch:6 [330/412], Loss: 1.189
Epoch:6 [340/412], Loss: 1.060
Epoch:6 [350/412], Loss: 1.573
Epoch:6 [360/412], Loss: 1.060
Epoch:6 [370/412], Loss: 1.302
Epoch:6 [380/412], Loss: 1.132
Epoch:6 [390/412], Loss: 1.060
Epoch:6 [400/412], Loss: 1.218
Epoch:6 [410/412], Loss: 0.959
Epoch:6, Train IoU: [0.98465098 0.8722102  0.89895515]
Epoch:6, Valid Loss: 0.911, mIoU: 0.9351705164716938
Validation metric decreased (1.055619 --> 0.910845).  Saving model ...
Epoch:7 [0/412], Loss: 0.944
Epoch:7 [10/412], Loss: 1.050
Epoch:7 [20/412], Loss: 0.918
Epoch:7 [30/412], Loss: 1.137
Epoch:7 [40/412], Loss: 1.325
Epoch:7 [50/412], Loss: 1.214
Epoch:7 [60/412], Loss: 1.014
Epoch:7 [70/412], Loss: 0.935
Epoch:7 [80/412], Loss: 0.930
Epoch:7 [90/412], Loss: 0.897
Epoch:7 [100/412], Loss: 1.174
Epoch:7 [110/412], Loss: 1.039
Epoch:7 [120/412], Loss: 1.306
Epoch:7 [130/412], Loss: 0.974
Epoch:7 [140/412], Loss: 1.057
Epoch:7 [150/412], Loss: 1.040
Epoch:7 [160/412], Loss: 1.429
Epoch:7 [170/412], Loss: 0.845
Epoch:7 [180/412], Loss: 1.054
Epoch:7 [190/412], Loss: 0.976
Epoch:7 [200/412], Loss: 0.894
Epoch:7 [210/412], Loss: 1.066
Epoch:7 [220/412], Loss: 1.334
Epoch:7 [230/412], Loss: 0.974
Epoch:7 [240/412], Loss: 1.117
Epoch:7 [250/412], Loss: 1.143
Epoch:7 [260/412], Loss: 0.866
Epoch:7 [270/412], Loss: 1.009
Epoch:7 [280/412], Loss: 1.060
Epoch:7 [290/412], Loss: 0.853
Epoch:7 [300/412], Loss: 1.050
Epoch:7 [310/412], Loss: 0.936
Epoch:7 [320/412], Loss: 1.485
Epoch:7 [330/412], Loss: 1.017
Epoch:7 [340/412], Loss: 1.288
Epoch:7 [350/412], Loss: 0.966
Epoch:7 [360/412], Loss: 0.963
Epoch:7 [370/412], Loss: 0.977
Epoch:7 [380/412], Loss: 0.971
Epoch:7 [390/412], Loss: 1.029
Epoch:7 [400/412], Loss: 0.879
Epoch:7 [410/412], Loss: 0.987
Epoch:7, Train IoU: [0.98560822 0.87956743 0.90389271]
Epoch:7, Valid Loss: 0.880, mIoU: 0.9362862649759199
Validation metric decreased (0.910845 --> 0.879841).  Saving model ...
Epoch:8 [0/412], Loss: 0.838
Epoch:8 [10/412], Loss: 0.965
Epoch:8 [20/412], Loss: 0.959
Epoch:8 [30/412], Loss: 0.905
Epoch:8 [40/412], Loss: 0.997
Epoch:8 [50/412], Loss: 1.478
Epoch:8 [60/412], Loss: 1.028
Epoch:8 [70/412], Loss: 0.938
Epoch:8 [80/412], Loss: 0.889
Epoch:8 [90/412], Loss: 0.985
Epoch:8 [100/412], Loss: 1.222
Epoch:8 [110/412], Loss: 0.920
Epoch:8 [120/412], Loss: 0.821
Epoch:8 [130/412], Loss: 1.305
Epoch:8 [140/412], Loss: 1.045
Epoch:8 [150/412], Loss: 1.101
Epoch:8 [160/412], Loss: 0.817
Epoch:8 [170/412], Loss: 0.958
Epoch:8 [180/412], Loss: 0.801
Epoch:8 [190/412], Loss: 1.147
Epoch:8 [200/412], Loss: 1.453
Epoch:8 [210/412], Loss: 1.171
Epoch:8 [220/412], Loss: 0.857
Epoch:8 [230/412], Loss: 0.850
Epoch:8 [240/412], Loss: 0.933
Epoch:8 [250/412], Loss: 0.930
Epoch:8 [260/412], Loss: 1.074
Epoch:8 [270/412], Loss: 0.818
Epoch:8 [280/412], Loss: 1.005
Epoch:8 [290/412], Loss: 0.960
Epoch:8 [300/412], Loss: 1.445
Epoch:8 [310/412], Loss: 0.869
Epoch:8 [320/412], Loss: 0.853
Epoch:8 [330/412], Loss: 1.098
Epoch:8 [340/412], Loss: 0.860
Epoch:8 [350/412], Loss: 0.959
Epoch:8 [360/412], Loss: 1.044
Epoch:8 [370/412], Loss: 0.925
Epoch:8 [380/412], Loss: 1.013
Epoch:8 [390/412], Loss: 0.785
Epoch:8 [400/412], Loss: 0.854
Epoch:8 [410/412], Loss: 0.952
Epoch:8, Train IoU: [0.98647517 0.88709332 0.90695475]
Epoch:8, Valid Loss: 0.786, mIoU: 0.9411069434689256
Validation metric decreased (0.879841 --> 0.786431).  Saving model ...
Epoch:9 [0/412], Loss: 1.061
Epoch:9 [10/412], Loss: 0.775
Epoch:9 [20/412], Loss: 1.345
Epoch:9 [30/412], Loss: 0.978
Epoch:9 [40/412], Loss: 0.856
Epoch:9 [50/412], Loss: 0.970
Epoch:9 [60/412], Loss: 1.050
Epoch:9 [70/412], Loss: 1.024
Epoch:9 [80/412], Loss: 0.994
Epoch:9 [90/412], Loss: 0.819
Epoch:9 [100/412], Loss: 0.979
Epoch:9 [110/412], Loss: 1.249
Epoch:9 [120/412], Loss: 1.126
Epoch:9 [130/412], Loss: 1.020
Epoch:9 [140/412], Loss: 0.820
Epoch:9 [150/412], Loss: 0.845
Epoch:9 [160/412], Loss: 0.856
Epoch:9 [170/412], Loss: 0.974
Epoch:9 [180/412], Loss: 0.824
Epoch:9 [190/412], Loss: 0.743
Epoch:9 [200/412], Loss: 1.040
Epoch:9 [210/412], Loss: 0.890
Epoch:9 [220/412], Loss: 1.029
Epoch:9 [230/412], Loss: 0.939
Epoch:9 [240/412], Loss: 0.817
Epoch:9 [250/412], Loss: 1.092
Epoch:9 [260/412], Loss: 0.837
Epoch:9 [270/412], Loss: 0.783
Epoch:9 [280/412], Loss: 1.158
Epoch:9 [290/412], Loss: 0.923
Epoch:9 [300/412], Loss: 0.872
Epoch:9 [310/412], Loss: 1.138
Epoch:9 [320/412], Loss: 0.962
Epoch:9 [330/412], Loss: 0.797
Epoch:9 [340/412], Loss: 1.099
Epoch:9 [350/412], Loss: 0.948
Epoch:9 [360/412], Loss: 0.860
Epoch:9 [370/412], Loss: 0.746
Epoch:9 [380/412], Loss: 0.955
Epoch:9 [390/412], Loss: 0.887
Epoch:9 [400/412], Loss: 0.945
Epoch:9 [410/412], Loss: 1.168
Epoch:9, Train IoU: [0.98726543 0.89346191 0.91259908]
Epoch:9, Valid Loss: 0.752, mIoU: 0.9436763366001407
Validation metric decreased (0.786431 --> 0.751783).  Saving model ...
Epoch:10 [0/412], Loss: 0.872
Epoch:10 [10/412], Loss: 0.812
Epoch:10 [20/412], Loss: 0.787
Epoch:10 [30/412], Loss: 1.064
Epoch:10 [40/412], Loss: 0.808
Epoch:10 [50/412], Loss: 1.170
Epoch:10 [60/412], Loss: 1.044
Epoch:10 [70/412], Loss: 0.761
Epoch:10 [80/412], Loss: 0.863
Epoch:10 [90/412], Loss: 0.810
Epoch:10 [100/412], Loss: 0.828
Epoch:10 [110/412], Loss: 0.936
Epoch:10 [120/412], Loss: 0.932
Epoch:10 [130/412], Loss: 0.793
Epoch:10 [140/412], Loss: 0.741
Epoch:10 [150/412], Loss: 0.869
Epoch:10 [160/412], Loss: 1.013
Epoch:10 [170/412], Loss: 0.753
Epoch:10 [180/412], Loss: 0.867
Epoch:10 [190/412], Loss: 1.168
Epoch:10 [200/412], Loss: 0.896
Epoch:10 [210/412], Loss: 1.215
Epoch:10 [220/412], Loss: 0.949
Epoch:10 [230/412], Loss: 0.954
Epoch:10 [240/412], Loss: 0.852
Epoch:10 [250/412], Loss: 0.705
Epoch:10 [260/412], Loss: 0.866
Epoch:10 [270/412], Loss: 1.027
Epoch:10 [280/412], Loss: 0.817
Epoch:10 [290/412], Loss: 0.826
Epoch:10 [300/412], Loss: 0.774
Epoch:10 [310/412], Loss: 0.745
Epoch:10 [320/412], Loss: 0.756
Epoch:10 [330/412], Loss: 1.186
Epoch:10 [340/412], Loss: 0.719
Epoch:10 [350/412], Loss: 0.943
Epoch:10 [360/412], Loss: 0.866
Epoch:10 [370/412], Loss: 0.670
Epoch:10 [380/412], Loss: 1.003
Epoch:10 [390/412], Loss: 0.861
Epoch:10 [400/412], Loss: 0.793
Epoch:10 [410/412], Loss: 0.924
Epoch:10, Train IoU: [0.98807005 0.9003182  0.91500601]
Epoch:10, Valid Loss: 0.770, mIoU: 0.9416583119959526
EarlyStopping counter: 1 out of 100
Epoch:11 [0/412], Loss: 0.977
Epoch:11 [10/412], Loss: 0.871
Epoch:11 [20/412], Loss: 0.665
Epoch:11 [30/412], Loss: 0.676
Epoch:11 [40/412], Loss: 0.873
Epoch:11 [50/412], Loss: 0.940
Epoch:11 [60/412], Loss: 0.822
Epoch:11 [70/412], Loss: 0.883
Epoch:11 [80/412], Loss: 0.688
Epoch:11 [90/412], Loss: 0.715
Epoch:11 [100/412], Loss: 1.022
Epoch:11 [110/412], Loss: 0.727
Epoch:11 [120/412], Loss: 0.634
Epoch:11 [130/412], Loss: 0.843
Epoch:11 [140/412], Loss: 0.781
Epoch:11 [150/412], Loss: 1.368
Epoch:11 [160/412], Loss: 0.845
Epoch:11 [170/412], Loss: 0.856
Epoch:11 [180/412], Loss: 0.773
Epoch:11 [190/412], Loss: 0.750
Epoch:11 [200/412], Loss: 0.890
Epoch:11 [210/412], Loss: 0.766
Epoch:11 [220/412], Loss: 0.869
Epoch:11 [230/412], Loss: 0.731
Epoch:11 [240/412], Loss: 0.708
Epoch:11 [250/412], Loss: 1.011
Epoch:11 [260/412], Loss: 0.717
Epoch:11 [270/412], Loss: 0.894
Epoch:11 [280/412], Loss: 0.762
Epoch:11 [290/412], Loss: 0.743
Epoch:11 [300/412], Loss: 0.946
Epoch:11 [310/412], Loss: 0.834
Epoch:11 [320/412], Loss: 0.784
Epoch:11 [330/412], Loss: 0.892
Epoch:11 [340/412], Loss: 0.847
Epoch:11 [350/412], Loss: 0.773
Epoch:11 [360/412], Loss: 0.842
Epoch:11 [370/412], Loss: 0.971
Epoch:11 [380/412], Loss: 0.940
Epoch:11 [390/412], Loss: 0.885
Epoch:11 [400/412], Loss: 0.906
Epoch:11 [410/412], Loss: 0.971
Epoch:11, Train IoU: [0.98807494 0.90050679 0.91805347]
Epoch:11, Valid Loss: 0.671, mIoU: 0.946216193726276
Validation metric decreased (0.751783 --> 0.670617).  Saving model ...
Epoch:12 [0/412], Loss: 0.706
Epoch:12 [10/412], Loss: 0.737
Epoch:12 [20/412], Loss: 0.908
Epoch:12 [30/412], Loss: 0.693
Epoch:12 [40/412], Loss: 0.777
Epoch:12 [50/412], Loss: 0.759
Epoch:12 [60/412], Loss: 0.649
Epoch:12 [70/412], Loss: 0.662
Epoch:12 [80/412], Loss: 0.730
Epoch:12 [90/412], Loss: 0.933
Epoch:12 [100/412], Loss: 0.664
Epoch:12 [110/412], Loss: 0.677
Epoch:12 [120/412], Loss: 0.957
Epoch:12 [130/412], Loss: 0.843
Epoch:12 [140/412], Loss: 0.918
Epoch:12 [150/412], Loss: 0.729
Epoch:12 [160/412], Loss: 0.768
Epoch:12 [170/412], Loss: 0.725
Epoch:12 [180/412], Loss: 0.721
Epoch:12 [190/412], Loss: 0.650
Epoch:12 [200/412], Loss: 0.759
Epoch:12 [210/412], Loss: 0.897
Epoch:12 [220/412], Loss: 0.629
Epoch:12 [230/412], Loss: 0.648
Epoch:12 [240/412], Loss: 1.078
Epoch:12 [250/412], Loss: 0.884
Epoch:12 [260/412], Loss: 0.954
Epoch:12 [270/412], Loss: 0.588
Epoch:12 [280/412], Loss: 0.873
Epoch:12 [290/412], Loss: 0.710
Epoch:12 [300/412], Loss: 0.952
Epoch:12 [310/412], Loss: 0.913
Epoch:12 [320/412], Loss: 0.994
Epoch:12 [330/412], Loss: 0.659
Epoch:12 [340/412], Loss: 0.643
Epoch:12 [350/412], Loss: 0.699
Epoch:12 [360/412], Loss: 0.691
Epoch:12 [370/412], Loss: 1.010
Epoch:12 [380/412], Loss: 0.886
Epoch:12 [390/412], Loss: 0.841
Epoch:12 [400/412], Loss: 0.746
Epoch:12 [410/412], Loss: 0.670
Epoch:12, Train IoU: [0.98879945 0.90669903 0.9207533 ]
Epoch:12, Valid Loss: 0.656, mIoU: 0.94883263263406
Validation metric decreased (0.670617 --> 0.656437).  Saving model ...
Epoch:13 [0/412], Loss: 0.688
Epoch:13 [10/412], Loss: 0.634
Epoch:13 [20/412], Loss: 0.752
Epoch:13 [30/412], Loss: 0.771
Epoch:13 [40/412], Loss: 0.773
Epoch:13 [50/412], Loss: 0.712
Epoch:13 [60/412], Loss: 0.720
Epoch:13 [70/412], Loss: 0.664
Epoch:13 [80/412], Loss: 0.752
Epoch:13 [90/412], Loss: 0.644
Epoch:13 [100/412], Loss: 0.607
Epoch:13 [110/412], Loss: 0.721
Epoch:13 [120/412], Loss: 0.746
Epoch:13 [130/412], Loss: 0.637
Epoch:13 [140/412], Loss: 0.596
Epoch:13 [150/412], Loss: 0.648
Epoch:13 [160/412], Loss: 0.943
Epoch:13 [170/412], Loss: 0.704
Epoch:13 [180/412], Loss: 0.646
Epoch:13 [190/412], Loss: 0.775
Epoch:13 [200/412], Loss: 0.700
Epoch:13 [210/412], Loss: 0.733
Epoch:13 [220/412], Loss: 0.679
Epoch:13 [230/412], Loss: 0.991
Epoch:13 [240/412], Loss: 0.702
Epoch:13 [250/412], Loss: 0.609
Epoch:13 [260/412], Loss: 0.773
Epoch:13 [270/412], Loss: 0.921
Epoch:13 [280/412], Loss: 0.665
Epoch:13 [290/412], Loss: 0.654
Epoch:13 [300/412], Loss: 0.914
Epoch:13 [310/412], Loss: 1.168
Epoch:13 [320/412], Loss: 0.917
Epoch:13 [330/412], Loss: 0.648
Epoch:13 [340/412], Loss: 0.680
Epoch:13 [350/412], Loss: 0.695
Epoch:13 [360/412], Loss: 0.660
Epoch:13 [370/412], Loss: 0.647
Epoch:13 [380/412], Loss: 0.707
Epoch:13 [390/412], Loss: 0.783
Epoch:13 [400/412], Loss: 0.724
Epoch:13 [410/412], Loss: 0.852
Epoch:13, Train IoU: [0.98919525 0.91047896 0.92225161]
Epoch:13, Valid Loss: 0.636, mIoU: 0.9469426840729381
Validation metric decreased (0.656437 --> 0.635632).  Saving model ...
Epoch:14 [0/412], Loss: 0.705
Epoch:14 [10/412], Loss: 0.600
Epoch:14 [20/412], Loss: 0.821
Epoch:14 [30/412], Loss: 0.423
Epoch:14 [40/412], Loss: 0.655
Epoch:14 [50/412], Loss: 0.827
Epoch:14 [60/412], Loss: 0.879
Epoch:14 [70/412], Loss: 0.928
Epoch:14 [80/412], Loss: 0.759
Epoch:14 [90/412], Loss: 0.853
Epoch:14 [100/412], Loss: 0.709
Epoch:14 [110/412], Loss: 0.747
Epoch:14 [120/412], Loss: 0.710
Epoch:14 [130/412], Loss: 0.820
Epoch:14 [140/412], Loss: 0.891
Epoch:14 [150/412], Loss: 0.759
Epoch:14 [160/412], Loss: 0.811
Epoch:14 [170/412], Loss: 0.668
Epoch:14 [180/412], Loss: 0.837
Epoch:14 [190/412], Loss: 0.768
Epoch:14 [200/412], Loss: 0.578
Epoch:14 [210/412], Loss: 0.670
Epoch:14 [220/412], Loss: 0.674
Epoch:14 [230/412], Loss: 0.545
Epoch:14 [240/412], Loss: 0.753
Epoch:14 [250/412], Loss: 1.043
Epoch:14 [260/412], Loss: 0.596
Epoch:14 [270/412], Loss: 0.589
Epoch:14 [280/412], Loss: 0.620
Epoch:14 [290/412], Loss: 0.804
Epoch:14 [300/412], Loss: 0.684
Epoch:14 [310/412], Loss: 0.693
Epoch:14 [320/412], Loss: 0.616
Epoch:14 [330/412], Loss: 0.612
Epoch:14 [340/412], Loss: 0.961
Epoch:14 [350/412], Loss: 0.767
Epoch:14 [360/412], Loss: 0.666
Epoch:14 [370/412], Loss: 0.751
Epoch:14 [380/412], Loss: 0.677
Epoch:14 [390/412], Loss: 0.701
Epoch:14 [400/412], Loss: 0.572
Epoch:14 [410/412], Loss: 0.719
Epoch:14, Train IoU: [0.98953408 0.91352804 0.9259007 ]
Epoch:14, Valid Loss: 0.561, mIoU: 0.9531142083566083
Validation metric decreased (0.635632 --> 0.560718).  Saving model ...
Epoch:15 [0/412], Loss: 0.463
Epoch:15 [10/412], Loss: 0.581
Epoch:15 [20/412], Loss: 0.629
Epoch:15 [30/412], Loss: 1.019
Epoch:15 [40/412], Loss: 0.772
Epoch:15 [50/412], Loss: 0.557
Epoch:15 [60/412], Loss: 0.724
Epoch:15 [70/412], Loss: 0.553
Epoch:15 [80/412], Loss: 0.549
Epoch:15 [90/412], Loss: 0.520
Epoch:15 [100/412], Loss: 0.677
Epoch:15 [110/412], Loss: 0.651
Epoch:15 [120/412], Loss: 1.173
Epoch:15 [130/412], Loss: 0.736
Epoch:15 [140/412], Loss: 0.546
Epoch:15 [150/412], Loss: 0.646
Epoch:15 [160/412], Loss: 0.590
Epoch:15 [170/412], Loss: 0.625
Epoch:15 [180/412], Loss: 0.910
Epoch:15 [190/412], Loss: 0.741
Epoch:15 [200/412], Loss: 0.693
Epoch:15 [210/412], Loss: 0.606
Epoch:15 [220/412], Loss: 0.682
Epoch:15 [230/412], Loss: 0.666
Epoch:15 [240/412], Loss: 0.758
Epoch:15 [250/412], Loss: 0.806
Epoch:15 [260/412], Loss: 0.752
Epoch:15 [270/412], Loss: 0.515
Epoch:15 [280/412], Loss: 0.536
Epoch:15 [290/412], Loss: 0.839
Epoch:15 [300/412], Loss: 0.541
Epoch:15 [310/412], Loss: 1.013
Epoch:15 [320/412], Loss: 0.713
Epoch:15 [330/412], Loss: 0.648
Epoch:15 [340/412], Loss: 0.811
Epoch:15 [350/412], Loss: 0.809
Epoch:15 [360/412], Loss: 0.715
Epoch:15 [370/412], Loss: 1.001
Epoch:15 [380/412], Loss: 0.697
Epoch:15 [390/412], Loss: 0.789
Epoch:15 [400/412], Loss: 0.665
Epoch:15 [410/412], Loss: 0.562
Epoch:15, Train IoU: [0.98996328 0.91719622 0.92729709]
Epoch:15, Valid Loss: 0.543, mIoU: 0.9525355496880707
Validation metric decreased (0.560718 --> 0.543045).  Saving model ...
Epoch:16 [0/412], Loss: 0.509
Epoch:16 [10/412], Loss: 0.555
Epoch:16 [20/412], Loss: 0.516
Epoch:16 [30/412], Loss: 0.797
Epoch:16 [40/412], Loss: 0.703
Epoch:16 [50/412], Loss: 0.608
Epoch:16 [60/412], Loss: 0.698
Epoch:16 [70/412], Loss: 0.607
Epoch:16 [80/412], Loss: 0.637
Epoch:16 [90/412], Loss: 0.586
Epoch:16 [100/412], Loss: 0.614
Epoch:16 [110/412], Loss: 0.487
Epoch:16 [120/412], Loss: 1.006
Epoch:16 [130/412], Loss: 0.699
Epoch:16 [140/412], Loss: 0.803
Epoch:16 [150/412], Loss: 0.761
Epoch:16 [160/412], Loss: 0.540
Epoch:16 [170/412], Loss: 0.753
Epoch:16 [180/412], Loss: 0.697
Epoch:16 [190/412], Loss: 0.594
Epoch:16 [200/412], Loss: 0.627
Epoch:16 [210/412], Loss: 0.525
Epoch:16 [220/412], Loss: 0.520
Epoch:16 [230/412], Loss: 0.680
Epoch:16 [240/412], Loss: 0.514
Epoch:16 [250/412], Loss: 0.698
Epoch:16 [260/412], Loss: 0.571
Epoch:16 [270/412], Loss: 0.573
Epoch:16 [280/412], Loss: 0.553
Epoch:16 [290/412], Loss: 0.669
Epoch:16 [300/412], Loss: 0.569
Epoch:16 [310/412], Loss: 0.685
Epoch:16 [320/412], Loss: 0.561
Epoch:16 [330/412], Loss: 0.696
Epoch:16 [340/412], Loss: 0.717
Epoch:16 [350/412], Loss: 0.608
Epoch:16 [360/412], Loss: 0.634
Epoch:16 [370/412], Loss: 0.510
Epoch:16 [380/412], Loss: 0.576
Epoch:16 [390/412], Loss: 0.728
Epoch:16 [400/412], Loss: 1.004
Epoch:16 [410/412], Loss: 0.556
Epoch:16, Train IoU: [0.99020737 0.91991842 0.92959201]
Epoch:16, Valid Loss: 0.530, mIoU: 0.9518339003688748
Validation metric decreased (0.543045 --> 0.530127).  Saving model ...
Epoch:17 [0/412], Loss: 0.733
Epoch:17 [10/412], Loss: 0.622
Epoch:17 [20/412], Loss: 0.619
Epoch:17 [30/412], Loss: 0.737
Epoch:17 [40/412], Loss: 0.618
Epoch:17 [50/412], Loss: 0.626
Epoch:17 [60/412], Loss: 0.852
Epoch:17 [70/412], Loss: 0.637
Epoch:17 [80/412], Loss: 0.513
Epoch:17 [90/412], Loss: 0.658
Epoch:17 [100/412], Loss: 0.541
Epoch:17 [110/412], Loss: 0.612
Epoch:17 [120/412], Loss: 0.513
Epoch:17 [130/412], Loss: 0.658
Epoch:17 [140/412], Loss: 0.563
Epoch:17 [150/412], Loss: 0.514
Epoch:17 [160/412], Loss: 0.566
Epoch:17 [170/412], Loss: 0.583
Epoch:17 [180/412], Loss: 0.759
Epoch:17 [190/412], Loss: 0.817
Epoch:17 [200/412], Loss: 0.501
Epoch:17 [210/412], Loss: 0.649
Epoch:17 [220/412], Loss: 0.635
Epoch:17 [230/412], Loss: 0.483
Epoch:17 [240/412], Loss: 0.542
Epoch:17 [250/412], Loss: 0.624
Epoch:17 [260/412], Loss: 0.825
Epoch:17 [270/412], Loss: 0.531
Epoch:17 [280/412], Loss: 0.618
Epoch:17 [290/412], Loss: 0.953
Epoch:17 [300/412], Loss: 0.468
Epoch:17 [310/412], Loss: 0.674
Epoch:17 [320/412], Loss: 0.676
Epoch:17 [330/412], Loss: 0.553
Epoch:17 [340/412], Loss: 0.373
Epoch:17 [350/412], Loss: 0.422
Epoch:17 [360/412], Loss: 0.573
Epoch:17 [370/412], Loss: 0.596
Epoch:17 [380/412], Loss: 0.600
Epoch:17 [390/412], Loss: 0.606
Epoch:17 [400/412], Loss: 0.625
Epoch:17 [410/412], Loss: 0.581
Epoch:17, Train IoU: [0.99040731 0.92204051 0.9313271 ]
Epoch:17, Valid Loss: 0.508, mIoU: 0.9558788964461732
Validation metric decreased (0.530127 --> 0.507616).  Saving model ...
Epoch:18 [0/412], Loss: 0.469
Epoch:18 [10/412], Loss: 0.424
Epoch:18 [20/412], Loss: 0.644
Epoch:18 [30/412], Loss: 0.487
Epoch:18 [40/412], Loss: 0.511
Epoch:18 [50/412], Loss: 0.688
Epoch:18 [60/412], Loss: 0.586
Epoch:18 [70/412], Loss: 0.615
Epoch:18 [80/412], Loss: 0.698
Epoch:18 [90/412], Loss: 0.640
Epoch:18 [100/412], Loss: 0.571
Epoch:18 [110/412], Loss: 0.696
Epoch:18 [120/412], Loss: 0.733
Epoch:18 [130/412], Loss: 0.791
Epoch:18 [140/412], Loss: 0.641
Epoch:18 [150/412], Loss: 0.647
Epoch:18 [160/412], Loss: 0.530
Epoch:18 [170/412], Loss: 0.762
Epoch:18 [180/412], Loss: 0.611
Epoch:18 [190/412], Loss: 0.463
Epoch:18 [200/412], Loss: 0.605
Epoch:18 [210/412], Loss: 0.418
Epoch:18 [220/412], Loss: 0.676
Epoch:18 [230/412], Loss: 0.622
Epoch:18 [240/412], Loss: 0.882
Epoch:18 [250/412], Loss: 0.549
Epoch:18 [260/412], Loss: 0.484
Epoch:18 [270/412], Loss: 0.492
Epoch:18 [280/412], Loss: 0.560
Epoch:18 [290/412], Loss: 0.491
Epoch:18 [300/412], Loss: 0.552
Epoch:18 [310/412], Loss: 0.691
Epoch:18 [320/412], Loss: 0.805
Epoch:18 [330/412], Loss: 0.448
Epoch:18 [340/412], Loss: 0.721
Epoch:18 [350/412], Loss: 0.493
Epoch:18 [360/412], Loss: 0.492
Epoch:18 [370/412], Loss: 0.452
Epoch:18 [380/412], Loss: 0.415
Epoch:18 [390/412], Loss: 0.484
Epoch:18 [400/412], Loss: 0.434
Epoch:18 [410/412], Loss: 0.587
Epoch:18, Train IoU: [0.99059302 0.92369482 0.93168912]
Epoch:18, Valid Loss: 0.483, mIoU: 0.9584686904509739
Validation metric decreased (0.507616 --> 0.482583).  Saving model ...
Epoch:19 [0/412], Loss: 0.448
Epoch:19 [10/412], Loss: 0.517
Epoch:19 [20/412], Loss: 0.545
Epoch:19 [30/412], Loss: 0.536
Epoch:19 [40/412], Loss: 0.463
Epoch:19 [50/412], Loss: 0.479
Epoch:19 [60/412], Loss: 0.538
Epoch:19 [70/412], Loss: 0.522
Epoch:19 [80/412], Loss: 0.526
Epoch:19 [90/412], Loss: 0.482
Epoch:19 [100/412], Loss: 0.459
Epoch:19 [110/412], Loss: 0.549
Epoch:19 [120/412], Loss: 0.530
Epoch:19 [130/412], Loss: 0.701
Epoch:19 [140/412], Loss: 0.513
Epoch:19 [150/412], Loss: 0.459
Epoch:19 [160/412], Loss: 0.454
Epoch:19 [170/412], Loss: 0.435
Epoch:19 [180/412], Loss: 0.601
Epoch:19 [190/412], Loss: 0.469
Epoch:19 [200/412], Loss: 0.562
Epoch:19 [210/412], Loss: 0.535
Epoch:19 [220/412], Loss: 0.529
Epoch:19 [230/412], Loss: 0.494
Epoch:19 [240/412], Loss: 0.496
Epoch:19 [250/412], Loss: 0.440
Epoch:19 [260/412], Loss: 0.593
Epoch:19 [270/412], Loss: 0.452
Epoch:19 [280/412], Loss: 0.484
Epoch:19 [290/412], Loss: 0.465
Epoch:19 [300/412], Loss: 0.453
Epoch:19 [310/412], Loss: 0.554
Epoch:19 [320/412], Loss: 0.529
Epoch:19 [330/412], Loss: 0.495
Epoch:19 [340/412], Loss: 0.456
Epoch:19 [350/412], Loss: 0.532
Epoch:19 [360/412], Loss: 0.486
Epoch:19 [370/412], Loss: 0.559
Epoch:19 [380/412], Loss: 0.646
Epoch:19 [390/412], Loss: 0.838
Epoch:19 [400/412], Loss: 0.478
Epoch:19 [410/412], Loss: 0.546
Epoch:19, Train IoU: [0.99090783 0.92674705 0.93430874]
Epoch:19, Valid Loss: 0.476, mIoU: 0.955974799026524
Validation metric decreased (0.482583 --> 0.475881).  Saving model ...
Epoch:20 [0/412], Loss: 0.532
Epoch:20 [10/412], Loss: 0.422
Epoch:20 [20/412], Loss: 0.471
Epoch:20 [30/412], Loss: 0.550
Epoch:20 [40/412], Loss: 0.500
Epoch:20 [50/412], Loss: 0.458
Epoch:20 [60/412], Loss: 0.479
Epoch:20 [70/412], Loss: 0.394
Epoch:20 [80/412], Loss: 0.391
Epoch:20 [90/412], Loss: 0.455
Epoch:20 [100/412], Loss: 0.490
Epoch:20 [110/412], Loss: 0.503
Epoch:20 [120/412], Loss: 0.514
Epoch:20 [130/412], Loss: 0.415
Epoch:20 [140/412], Loss: 0.459
Epoch:20 [150/412], Loss: 0.579
Epoch:20 [160/412], Loss: 0.548
Epoch:20 [170/412], Loss: 0.509
Epoch:20 [180/412], Loss: 0.626
Epoch:20 [190/412], Loss: 0.422
Epoch:20 [200/412], Loss: 0.623
Epoch:20 [210/412], Loss: 0.533
Epoch:20 [220/412], Loss: 0.529
Epoch:20 [230/412], Loss: 0.487
Epoch:20 [240/412], Loss: 0.440
Epoch:20 [250/412], Loss: 0.574
Epoch:20 [260/412], Loss: 0.377
Epoch:20 [270/412], Loss: 0.496
Epoch:20 [280/412], Loss: 0.467
Epoch:20 [290/412], Loss: 0.764
Epoch:20 [300/412], Loss: 0.527
Epoch:20 [310/412], Loss: 0.403
Epoch:20 [320/412], Loss: 0.564
Epoch:20 [330/412], Loss: 0.618
Epoch:20 [340/412], Loss: 0.592
Epoch:20 [350/412], Loss: 0.388
Epoch:20 [360/412], Loss: 0.516
Epoch:20 [370/412], Loss: 0.646
Epoch:20 [380/412], Loss: 0.459
Epoch:20 [390/412], Loss: 0.456
Epoch:20 [400/412], Loss: 0.378
Epoch:20 [410/412], Loss: 0.452
Epoch:20, Train IoU: [0.99100155 0.92734449 0.93527837]
Epoch:20, Valid Loss: 0.435, mIoU: 0.9587097461204129
Validation metric decreased (0.475881 --> 0.435156).  Saving model ...
Epoch:21 [0/412], Loss: 0.377
Epoch:21 [10/412], Loss: 0.621
Epoch:21 [20/412], Loss: 0.534
Epoch:21 [30/412], Loss: 0.510
Epoch:21 [40/412], Loss: 0.503
Epoch:21 [50/412], Loss: 0.766
Epoch:21 [60/412], Loss: 0.568
Epoch:21 [70/412], Loss: 0.414
Epoch:21 [80/412], Loss: 0.651
Epoch:21 [90/412], Loss: 0.407
Epoch:21 [100/412], Loss: 0.347
Epoch:21 [110/412], Loss: 0.538
Epoch:21 [120/412], Loss: 0.561
Epoch:21 [130/412], Loss: 0.492
Epoch:21 [140/412], Loss: 0.504
Epoch:21 [150/412], Loss: 0.417
Epoch:21 [160/412], Loss: 0.466
Epoch:21 [170/412], Loss: 0.672
Epoch:21 [180/412], Loss: 0.641
Epoch:21 [190/412], Loss: 0.519
Epoch:21 [200/412], Loss: 0.461
Epoch:21 [210/412], Loss: 0.496
Epoch:21 [220/412], Loss: 0.446
Epoch:21 [230/412], Loss: 0.466
Epoch:21 [240/412], Loss: 0.527
Epoch:21 [250/412], Loss: 0.661
Epoch:21 [260/412], Loss: 0.624
Epoch:21 [270/412], Loss: 0.623
Epoch:21 [280/412], Loss: 0.571
Epoch:21 [290/412], Loss: 0.557
Epoch:21 [300/412], Loss: 0.442
Epoch:21 [310/412], Loss: 0.406
Epoch:21 [320/412], Loss: 0.534
Epoch:21 [330/412], Loss: 0.556
Epoch:21 [340/412], Loss: 0.698
Epoch:21 [350/412], Loss: 0.484
Epoch:21 [360/412], Loss: 0.402
Epoch:21 [370/412], Loss: 0.739
Epoch:21 [380/412], Loss: 0.483
Epoch:21 [390/412], Loss: 0.404
Epoch:21 [400/412], Loss: 0.609
Epoch:21 [410/412], Loss: 0.335
Epoch:21, Train IoU: [0.99136212 0.9309047  0.93578268]
Epoch:21, Valid Loss: 0.422, mIoU: 0.9596095268291401
Validation metric decreased (0.435156 --> 0.421665).  Saving model ...
Epoch:22 [0/412], Loss: 0.451
Epoch:22 [10/412], Loss: 0.528
Epoch:22 [20/412], Loss: 0.418
Epoch:22 [30/412], Loss: 0.384
Epoch:22 [40/412], Loss: 0.515
Epoch:22 [50/412], Loss: 0.408
Epoch:22 [60/412], Loss: 0.400
Epoch:22 [70/412], Loss: 0.370
Epoch:22 [80/412], Loss: 0.439
Epoch:22 [90/412], Loss: 0.493
Epoch:22 [100/412], Loss: 0.543
Epoch:22 [110/412], Loss: 0.432
Epoch:22 [120/412], Loss: 0.369
Epoch:22 [130/412], Loss: 0.635
Epoch:22 [140/412], Loss: 0.688
Epoch:22 [150/412], Loss: 0.551
Epoch:22 [160/412], Loss: 0.491
Epoch:22 [170/412], Loss: 0.524
Epoch:22 [180/412], Loss: 0.381
Epoch:22 [190/412], Loss: 0.474
Epoch:22 [200/412], Loss: 0.681
Epoch:22 [210/412], Loss: 0.465
Epoch:22 [220/412], Loss: 0.583
Epoch:22 [230/412], Loss: 0.652
Epoch:22 [240/412], Loss: 0.480
Epoch:22 [250/412], Loss: 0.373
Epoch:22 [260/412], Loss: 0.394
Epoch:22 [270/412], Loss: 0.497
Epoch:22 [280/412], Loss: 0.456
Epoch:22 [290/412], Loss: 0.589
Epoch:22 [300/412], Loss: 0.438
Epoch:22 [310/412], Loss: 0.550
Epoch:22 [320/412], Loss: 0.438
Epoch:22 [330/412], Loss: 2.144
Epoch:22 [340/412], Loss: 0.842
Epoch:22 [350/412], Loss: 0.682
Epoch:22 [360/412], Loss: 0.610
Epoch:22 [370/412], Loss: 0.497
Epoch:22 [380/412], Loss: 0.552
Epoch:22 [390/412], Loss: 0.598
Epoch:22 [400/412], Loss: 0.561
Epoch:22 [410/412], Loss: 0.489
Epoch:22, Train IoU: [0.99083104 0.92689171 0.93317852]
Epoch:22, Valid Loss: 0.437, mIoU: 0.9578214533424388
EarlyStopping counter: 1 out of 100
Epoch:23 [0/412], Loss: 0.471
Epoch:23 [10/412], Loss: 0.552
Epoch:23 [20/412], Loss: 0.434
Epoch:23 [30/412], Loss: 0.595
Epoch:23 [40/412], Loss: 0.407
Epoch:23 [50/412], Loss: 0.438
Epoch:23 [60/412], Loss: 0.373
Epoch:23 [70/412], Loss: 0.401
Epoch:23 [80/412], Loss: 0.401
Epoch:23 [90/412], Loss: 0.411
Epoch:23 [100/412], Loss: 0.546
Epoch:23 [110/412], Loss: 0.428
Epoch:23 [120/412], Loss: 0.564
Epoch:23 [130/412], Loss: 0.414
Epoch:23 [140/412], Loss: 0.544
Epoch:23 [150/412], Loss: 0.391
Epoch:23 [160/412], Loss: 0.417
Epoch:23 [170/412], Loss: 0.425
Epoch:23 [180/412], Loss: 0.564
Epoch:23 [190/412], Loss: 0.351
Epoch:23 [200/412], Loss: 0.487
Epoch:23 [210/412], Loss: 0.315
Epoch:23 [220/412], Loss: 0.342
Epoch:23 [230/412], Loss: 0.476
Epoch:23 [240/412], Loss: 0.480
Epoch:23 [250/412], Loss: 0.539
Epoch:23 [260/412], Loss: 0.360
Epoch:23 [270/412], Loss: 0.548
Epoch:23 [280/412], Loss: 0.502
Epoch:23 [290/412], Loss: 0.376
Epoch:23 [300/412], Loss: 0.379
Epoch:23 [310/412], Loss: 0.379
Epoch:23 [320/412], Loss: 0.425
Epoch:23 [330/412], Loss: 0.709
Epoch:23 [340/412], Loss: 0.435
Epoch:23 [350/412], Loss: 0.516
Epoch:23 [360/412], Loss: 0.505
Epoch:23 [370/412], Loss: 0.386
Epoch:23 [380/412], Loss: 0.376
Epoch:23 [390/412], Loss: 0.329
Epoch:23 [400/412], Loss: 0.379
Epoch:23 [410/412], Loss: 0.530
Epoch:23, Train IoU: [0.99141124 0.93163887 0.93779359]
Epoch:23, Valid Loss: 0.349, mIoU: 0.9634505756958905
Validation metric decreased (0.421665 --> 0.349332).  Saving model ...
Epoch:24 [0/412], Loss: 0.465
Epoch:24 [10/412], Loss: 0.369
Epoch:24 [20/412], Loss: 0.431
Epoch:24 [30/412], Loss: 0.420
Epoch:24 [40/412], Loss: 0.451
Epoch:24 [50/412], Loss: 0.516
Epoch:24 [60/412], Loss: 0.399
Epoch:24 [70/412], Loss: 0.385
Epoch:24 [80/412], Loss: 0.385
Epoch:24 [90/412], Loss: 0.590
Epoch:24 [100/412], Loss: 0.391
Epoch:24 [110/412], Loss: 0.401
Epoch:24 [120/412], Loss: 0.394
Epoch:24 [130/412], Loss: 0.373
Epoch:24 [140/412], Loss: 0.346
Epoch:24 [150/412], Loss: 0.403
Epoch:24 [160/412], Loss: 0.469
Epoch:24 [170/412], Loss: 0.432
Epoch:24 [180/412], Loss: 0.326
Epoch:24 [190/412], Loss: 0.483
Epoch:24 [200/412], Loss: 0.451
Epoch:24 [210/412], Loss: 0.492
Epoch:24 [220/412], Loss: 0.498
Epoch:24 [230/412], Loss: 0.429
Epoch:24 [240/412], Loss: 0.405
Epoch:24 [250/412], Loss: 0.434
Epoch:24 [260/412], Loss: 0.353
Epoch:24 [270/412], Loss: 0.384
Epoch:24 [280/412], Loss: 0.633
Epoch:24 [290/412], Loss: 0.372
Epoch:24 [300/412], Loss: 0.339
Epoch:24 [310/412], Loss: 0.386
Epoch:24 [320/412], Loss: 0.470
Epoch:24 [330/412], Loss: 0.383
Epoch:24 [340/412], Loss: 0.427
Epoch:24 [350/412], Loss: 0.451
Epoch:24 [360/412], Loss: 0.413
Epoch:24 [370/412], Loss: 0.446
Epoch:24 [380/412], Loss: 0.443
Epoch:24 [390/412], Loss: 0.534
Epoch:24 [400/412], Loss: 0.401
Epoch:24 [410/412], Loss: 0.768
Epoch:24, Train IoU: [0.99173638 0.93477708 0.94001999]
Epoch:24, Valid Loss: 0.364, mIoU: 0.9598598988029005
EarlyStopping counter: 1 out of 100
Epoch:25 [0/412], Loss: 0.365
Epoch:25 [10/412], Loss: 0.373
Epoch:25 [20/412], Loss: 0.396
Epoch:25 [30/412], Loss: 0.411
Epoch:25 [40/412], Loss: 0.421
Epoch:25 [50/412], Loss: 0.589
Epoch:25 [60/412], Loss: 0.319
Epoch:25 [70/412], Loss: 0.459
Epoch:25 [80/412], Loss: 0.429
Epoch:25 [90/412], Loss: 0.517
Epoch:25 [100/412], Loss: 0.375
Epoch:25 [110/412], Loss: 0.378
Epoch:25 [120/412], Loss: 0.480
Epoch:25 [130/412], Loss: 0.500
Epoch:25 [140/412], Loss: 0.310
Epoch:25 [150/412], Loss: 0.346
Epoch:25 [160/412], Loss: 0.256
Epoch:25 [170/412], Loss: 0.316
Epoch:25 [180/412], Loss: 0.391
Epoch:25 [190/412], Loss: 0.365
Epoch:25 [200/412], Loss: 0.369
Epoch:25 [210/412], Loss: 0.448
Epoch:25 [220/412], Loss: 0.370
Epoch:25 [230/412], Loss: 0.250
Epoch:25 [240/412], Loss: 0.366
Epoch:25 [250/412], Loss: 0.404
Epoch:25 [260/412], Loss: 0.479
Epoch:25 [270/412], Loss: 0.465
Epoch:25 [280/412], Loss: 0.299
Epoch:25 [290/412], Loss: 0.425
Epoch:25 [300/412], Loss: 0.334
Epoch:25 [310/412], Loss: 0.453
Epoch:25 [320/412], Loss: 0.346
Epoch:25 [330/412], Loss: 0.541
Epoch:25 [340/412], Loss: 0.452
Epoch:25 [350/412], Loss: 0.424
Epoch:25 [360/412], Loss: 0.541
Epoch:25 [370/412], Loss: 0.527
Epoch:25 [380/412], Loss: 0.384
Epoch:25 [390/412], Loss: 0.358
Epoch:25 [400/412], Loss: 0.398
Epoch:25 [410/412], Loss: 0.309
Epoch:25, Train IoU: [0.99202313 0.93764136 0.9421385 ]
Epoch:25, Valid Loss: 0.364, mIoU: 0.9614245536656648
EarlyStopping counter: 2 out of 100
Epoch:26 [0/412], Loss: 0.432
Epoch:26 [10/412], Loss: 0.344
Epoch:26 [20/412], Loss: 0.466
Epoch:26 [30/412], Loss: 0.361
Epoch:26 [40/412], Loss: 0.545
Epoch:26 [50/412], Loss: 0.358
Epoch:26 [60/412], Loss: 0.942
Epoch:26 [70/412], Loss: 0.307
Epoch:26 [80/412], Loss: 0.483
Epoch:26 [90/412], Loss: 0.338
Epoch:26 [100/412], Loss: 0.483
Epoch:26 [110/412], Loss: 0.389
Epoch:26 [120/412], Loss: 0.322
Epoch:26 [130/412], Loss: 0.303
Epoch:26 [140/412], Loss: 0.367
Epoch:26 [150/412], Loss: 0.518
Epoch:26 [160/412], Loss: 0.318
Epoch:26 [170/412], Loss: 0.372
Epoch:26 [180/412], Loss: 0.407
Epoch:26 [190/412], Loss: 0.417
Epoch:26 [200/412], Loss: 0.462
Epoch:26 [210/412], Loss: 0.313
Epoch:26 [220/412], Loss: 0.345
Epoch:26 [230/412], Loss: 0.690
Epoch:26 [240/412], Loss: 0.374
Epoch:26 [250/412], Loss: 0.407
Epoch:26 [260/412], Loss: 0.480
Epoch:26 [270/412], Loss: 0.375
Epoch:26 [280/412], Loss: 0.328
Epoch:26 [290/412], Loss: 0.391
Epoch:26 [300/412], Loss: 0.458
Epoch:26 [310/412], Loss: 0.448
Epoch:26 [320/412], Loss: 0.343
Epoch:26 [330/412], Loss: 0.333
Epoch:26 [340/412], Loss: 0.326
Epoch:26 [350/412], Loss: 0.332
Epoch:26 [360/412], Loss: 0.263
Epoch:26 [370/412], Loss: 0.392
Epoch:26 [380/412], Loss: 0.411
Epoch:26 [390/412], Loss: 0.309
Epoch:26 [400/412], Loss: 0.289
Epoch:26 [410/412], Loss: 0.347
Epoch:26, Train IoU: [0.99218348 0.93929987 0.94316666]
Epoch:26, Valid Loss: 0.322, mIoU: 0.9629494889858208
Validation metric decreased (0.349332 --> 0.321783).  Saving model ...
Epoch:27 [0/412], Loss: 0.301
Epoch:27 [10/412], Loss: 0.246
Epoch:27 [20/412], Loss: 0.423
Epoch:27 [30/412], Loss: 0.376
Epoch:27 [40/412], Loss: 0.439
Epoch:27 [50/412], Loss: 0.383
Epoch:27 [60/412], Loss: 0.220
Epoch:27 [70/412], Loss: 0.336
Epoch:27 [80/412], Loss: 0.363
Epoch:27 [90/412], Loss: 0.325
Epoch:27 [100/412], Loss: 0.511
Epoch:27 [110/412], Loss: 0.345
Epoch:27 [120/412], Loss: 0.396
Epoch:27 [130/412], Loss: 0.322
Epoch:27 [140/412], Loss: 0.292
Epoch:27 [150/412], Loss: 0.491
Epoch:27 [160/412], Loss: 0.402
Epoch:27 [170/412], Loss: 0.658
Epoch:27 [180/412], Loss: 0.272
Epoch:27 [190/412], Loss: 0.328
Epoch:27 [200/412], Loss: 0.390
Epoch:27 [210/412], Loss: 0.399
Epoch:27 [220/412], Loss: 0.322
Epoch:27 [230/412], Loss: 0.252
Epoch:27 [240/412], Loss: 0.277
Epoch:27 [250/412], Loss: 0.405
Epoch:27 [260/412], Loss: 0.343
Epoch:27 [270/412], Loss: 0.475
Epoch:27 [280/412], Loss: 0.350
Epoch:27 [290/412], Loss: 0.272
Epoch:27 [300/412], Loss: 0.331
Epoch:27 [310/412], Loss: 0.332
Epoch:27 [320/412], Loss: 0.362
Epoch:27 [330/412], Loss: 0.302
Epoch:27 [340/412], Loss: 0.365
Epoch:27 [350/412], Loss: 0.381
Epoch:27 [360/412], Loss: 0.497
Epoch:27 [370/412], Loss: 0.471
Epoch:27 [380/412], Loss: 0.348
Epoch:27 [390/412], Loss: 0.453
Epoch:27 [400/412], Loss: 0.289
Epoch:27 [410/412], Loss: 0.427
Epoch:27, Train IoU: [0.99204288 0.9382506  0.94172724]
Epoch:27, Valid Loss: 0.384, mIoU: 0.9564604366112005
EarlyStopping counter: 1 out of 100
Epoch:28 [0/412], Loss: 0.541
Epoch:28 [10/412], Loss: 0.315
Epoch:28 [20/412], Loss: 0.384
Epoch:28 [30/412], Loss: 0.470
Epoch:28 [40/412], Loss: 0.254
Epoch:28 [50/412], Loss: 0.317
Epoch:28 [60/412], Loss: 0.304
Epoch:28 [70/412], Loss: 0.405
Epoch:28 [80/412], Loss: 0.294
Epoch:28 [90/412], Loss: 0.340
Epoch:28 [100/412], Loss: 0.293
Epoch:28 [110/412], Loss: 0.460
Epoch:28 [120/412], Loss: 0.350
Epoch:28 [130/412], Loss: 0.243
Epoch:28 [140/412], Loss: 0.372
Epoch:28 [150/412], Loss: 0.220
Epoch:28 [160/412], Loss: 0.283
Epoch:28 [170/412], Loss: 0.300
Epoch:28 [180/412], Loss: 0.322
Epoch:28 [190/412], Loss: 0.332
Epoch:28 [200/412], Loss: 0.339
Epoch:28 [210/412], Loss: 0.331
Epoch:28 [220/412], Loss: 0.283
Epoch:28 [230/412], Loss: 0.305
Epoch:28 [240/412], Loss: 0.361
Epoch:28 [250/412], Loss: 0.301
Epoch:28 [260/412], Loss: 0.279
Epoch:28 [270/412], Loss: 0.277
Epoch:28 [280/412], Loss: 0.238
Epoch:28 [290/412], Loss: 0.389
Epoch:28 [300/412], Loss: 0.317
Epoch:28 [310/412], Loss: 0.328
Epoch:28 [320/412], Loss: 0.283
Epoch:28 [330/412], Loss: 0.315
Epoch:28 [340/412], Loss: 0.452
Epoch:28 [350/412], Loss: 0.414
Epoch:28 [360/412], Loss: 0.413
Epoch:28 [370/412], Loss: 0.289
Epoch:28 [380/412], Loss: 0.555
Epoch:28 [390/412], Loss: 0.379
Epoch:28 [400/412], Loss: 0.430
Epoch:28 [410/412], Loss: 0.298
Epoch:28, Train IoU: [0.99231568 0.94049889 0.94462967]
Epoch:28, Valid Loss: 0.298, mIoU: 0.9636156722078676
Validation metric decreased (0.321783 --> 0.298059).  Saving model ...
Epoch:29 [0/412], Loss: 0.332
Epoch:29 [10/412], Loss: 0.519
Epoch:29 [20/412], Loss: 0.284
Epoch:29 [30/412], Loss: 0.315
Epoch:29 [40/412], Loss: 0.418
Epoch:29 [50/412], Loss: 0.414
Epoch:29 [60/412], Loss: 0.331
Epoch:29 [70/412], Loss: 0.293
Epoch:29 [80/412], Loss: 0.231
Epoch:29 [90/412], Loss: 0.412
Epoch:29 [100/412], Loss: 0.532
Epoch:29 [110/412], Loss: 0.404
Epoch:29 [120/412], Loss: 0.317
Epoch:29 [130/412], Loss: 0.364
Epoch:29 [140/412], Loss: 0.387
Epoch:29 [150/412], Loss: 0.404
Epoch:29 [160/412], Loss: 0.378
Epoch:29 [170/412], Loss: 0.371
Epoch:29 [180/412], Loss: 0.311
Epoch:29 [190/412], Loss: 0.288
Epoch:29 [200/412], Loss: 0.276
Epoch:29 [210/412], Loss: 0.346
Epoch:29 [220/412], Loss: 0.305
Epoch:29 [230/412], Loss: 0.276
Epoch:29 [240/412], Loss: 0.335
Epoch:29 [250/412], Loss: 0.348
Epoch:29 [260/412], Loss: 0.353
Epoch:29 [270/412], Loss: 0.440
Epoch:29 [280/412], Loss: 0.311
Epoch:29 [290/412], Loss: 0.315
Epoch:29 [300/412], Loss: 0.369
Epoch:29 [310/412], Loss: 0.380
Epoch:29 [320/412], Loss: 0.456
Epoch:29 [330/412], Loss: 0.329
Epoch:29 [340/412], Loss: 0.371
Epoch:29 [350/412], Loss: 0.357
Epoch:29 [360/412], Loss: 0.296
Epoch:29 [370/412], Loss: 0.230
Epoch:29 [380/412], Loss: 0.420
Epoch:29 [390/412], Loss: 0.514
Epoch:29 [400/412], Loss: 0.355
Epoch:29 [410/412], Loss: 0.378
Epoch:29, Train IoU: [0.99247101 0.94189717 0.94386182]
Epoch:29, Valid Loss: 0.295, mIoU: 0.9638087619800375
Validation metric decreased (0.298059 --> 0.295324).  Saving model ...
Epoch:30 [0/412], Loss: 0.347
Epoch:30 [10/412], Loss: 0.266
Epoch:30 [20/412], Loss: 0.302
Epoch:30 [30/412], Loss: 0.180
Epoch:30 [40/412], Loss: 0.273
Epoch:30 [50/412], Loss: 0.304
Epoch:30 [60/412], Loss: 0.363
Epoch:30 [70/412], Loss: 0.378
Epoch:30 [80/412], Loss: 0.296
Epoch:30 [90/412], Loss: 0.209
Epoch:30 [100/412], Loss: 0.289
Epoch:30 [110/412], Loss: 0.307
Epoch:30 [120/412], Loss: 0.443
Epoch:30 [130/412], Loss: 0.365
Epoch:30 [140/412], Loss: 0.217
Epoch:30 [150/412], Loss: 0.394
Epoch:30 [160/412], Loss: 0.432
Epoch:30 [170/412], Loss: 0.337
Epoch:30 [180/412], Loss: 0.281
Epoch:30 [190/412], Loss: 0.238
Epoch:30 [200/412], Loss: 0.254
Epoch:30 [210/412], Loss: 0.493
Epoch:30 [220/412], Loss: 0.244
Epoch:30 [230/412], Loss: 0.313
Epoch:30 [240/412], Loss: 0.341
Epoch:30 [250/412], Loss: 0.419
Epoch:30 [260/412], Loss: 0.292
Epoch:30 [270/412], Loss: 0.266
Epoch:30 [280/412], Loss: 0.260
Epoch:30 [290/412], Loss: 0.166
Epoch:30 [300/412], Loss: 0.343
Epoch:30 [310/412], Loss: 0.414
Epoch:30 [320/412], Loss: 0.271
Epoch:30 [330/412], Loss: 0.279
Epoch:30 [340/412], Loss: 0.323
Epoch:30 [350/412], Loss: 0.376
Epoch:30 [360/412], Loss: 0.310
Epoch:30 [370/412], Loss: 0.435
Epoch:30 [380/412], Loss: 0.272
Epoch:30 [390/412], Loss: 0.294
Epoch:30 [400/412], Loss: 0.299
Epoch:30 [410/412], Loss: 0.376
Epoch:30, Train IoU: [0.99251289 0.94259667 0.94538537]
Epoch:30, Valid Loss: 0.265, mIoU: 0.9652553455112066
Validation metric decreased (0.295324 --> 0.264691).  Saving model ...
Epoch:31 [0/412], Loss: 0.497
Epoch:31 [10/412], Loss: 0.466
Epoch:31 [20/412], Loss: 0.308
Epoch:31 [30/412], Loss: 0.256
Epoch:31 [40/412], Loss: 0.409
Epoch:31 [50/412], Loss: 0.375
Epoch:31 [60/412], Loss: 0.193
Epoch:31 [70/412], Loss: 0.286
Epoch:31 [80/412], Loss: 0.245
Epoch:31 [90/412], Loss: 0.265
Epoch:31 [100/412], Loss: 0.330
Epoch:31 [110/412], Loss: 0.358
Epoch:31 [120/412], Loss: 0.276
Epoch:31 [130/412], Loss: 0.358
Epoch:31 [140/412], Loss: 0.433
Epoch:31 [150/412], Loss: 0.232
Epoch:31 [160/412], Loss: 0.397
Epoch:31 [170/412], Loss: 0.298
Epoch:31 [180/412], Loss: 0.270
Epoch:31 [190/412], Loss: 0.245
Epoch:31 [200/412], Loss: 0.286
Epoch:31 [210/412], Loss: 0.389
Epoch:31 [220/412], Loss: 0.262
Epoch:31 [230/412], Loss: 0.207
Epoch:31 [240/412], Loss: 0.308
Epoch:31 [250/412], Loss: 0.380
Epoch:31 [260/412], Loss: 0.559
Epoch:31 [270/412], Loss: 0.313
Epoch:31 [280/412], Loss: 0.315
Epoch:31 [290/412], Loss: 0.306
Epoch:31 [300/412], Loss: 0.293
Epoch:31 [310/412], Loss: 0.237
Epoch:31 [320/412], Loss: 0.303
Epoch:31 [330/412], Loss: 0.365
Epoch:31 [340/412], Loss: 0.246
Epoch:31 [350/412], Loss: 0.306
Epoch:31 [360/412], Loss: 0.326
Epoch:31 [370/412], Loss: 0.362
Epoch:31 [380/412], Loss: 0.380
Epoch:31 [390/412], Loss: 0.485
Epoch:31 [400/412], Loss: 0.444
Epoch:31 [410/412], Loss: 0.414
Epoch:31, Train IoU: [0.99253143 0.94285372 0.94467687]
Epoch:31, Valid Loss: 0.258, mIoU: 0.9647533498762048
Validation metric decreased (0.264691 --> 0.257918).  Saving model ...
Epoch:32 [0/412], Loss: 0.264
Epoch:32 [10/412], Loss: 0.344
Epoch:32 [20/412], Loss: 0.155
Epoch:32 [30/412], Loss: 0.277
Epoch:32 [40/412], Loss: 0.303
Epoch:32 [50/412], Loss: 0.232
Epoch:32 [60/412], Loss: 0.326
Epoch:32 [70/412], Loss: 0.333
Epoch:32 [80/412], Loss: 0.186
Epoch:32 [90/412], Loss: 0.220
Epoch:32 [100/412], Loss: 0.286
Epoch:32 [110/412], Loss: 0.296
Epoch:32 [120/412], Loss: 0.282
Epoch:32 [130/412], Loss: 0.340
Epoch:32 [140/412], Loss: 0.335
Epoch:32 [150/412], Loss: 0.309
Epoch:32 [160/412], Loss: 0.426
Epoch:32 [170/412], Loss: 0.342
Epoch:32 [180/412], Loss: 0.318
Epoch:32 [190/412], Loss: 0.339
Epoch:32 [200/412], Loss: 0.337
Epoch:32 [210/412], Loss: 0.342
Epoch:32 [220/412], Loss: 0.817
Epoch:32 [230/412], Loss: 0.315
Epoch:32 [240/412], Loss: 0.205
Epoch:32 [250/412], Loss: 0.292
Epoch:32 [260/412], Loss: 0.265
Epoch:32 [270/412], Loss: 0.284
Epoch:32 [280/412], Loss: 0.246
Epoch:32 [290/412], Loss: 0.314
Epoch:32 [300/412], Loss: 0.513
Epoch:32 [310/412], Loss: 0.143
Epoch:32 [320/412], Loss: 0.367
Epoch:32 [330/412], Loss: 0.233
Epoch:32 [340/412], Loss: 0.220
Epoch:32 [350/412], Loss: 0.289
Epoch:32 [360/412], Loss: 0.465
Epoch:32 [370/412], Loss: 0.269
Epoch:32 [380/412], Loss: 0.273
Epoch:32 [390/412], Loss: 0.347
Epoch:32 [400/412], Loss: 0.296
Epoch:32 [410/412], Loss: 0.401
Epoch:32, Train IoU: [0.99249135 0.94270825 0.94635536]
Epoch:32, Valid Loss: 0.261, mIoU: 0.9636859780305089
Validation metric decreased (0.257918 --> 0.260659).  Saving model ...
Epoch:33 [0/412], Loss: 0.325
Epoch:33 [10/412], Loss: 0.417
Epoch:33 [20/412], Loss: 0.239
Epoch:33 [30/412], Loss: 0.249
Epoch:33 [40/412], Loss: 0.375
Epoch:33 [50/412], Loss: 0.258
Epoch:33 [60/412], Loss: 0.277
Epoch:33 [70/412], Loss: 0.416
Epoch:33 [80/412], Loss: 0.267
Epoch:33 [90/412], Loss: 0.250
Epoch:33 [100/412], Loss: 0.411
Epoch:33 [110/412], Loss: 0.341
Epoch:33 [120/412], Loss: 0.217
Epoch:33 [130/412], Loss: 0.424
Epoch:33 [140/412], Loss: 0.229
Epoch:33 [150/412], Loss: 0.244
Epoch:33 [160/412], Loss: 0.503
Epoch:33 [170/412], Loss: 0.319
Epoch:33 [180/412], Loss: 0.208
Epoch:33 [190/412], Loss: 0.279
Epoch:33 [200/412], Loss: 0.171
Epoch:33 [210/412], Loss: 0.188
Epoch:33 [220/412], Loss: 0.203
Epoch:33 [230/412], Loss: 0.293
Epoch:33 [240/412], Loss: 0.311
Epoch:33 [250/412], Loss: 0.221
Epoch:33 [260/412], Loss: 0.264
Epoch:33 [270/412], Loss: 0.293
Epoch:33 [280/412], Loss: 0.359
Epoch:33 [290/412], Loss: 0.180
Epoch:33 [300/412], Loss: 0.232
Epoch:33 [310/412], Loss: 0.371
Epoch:33 [320/412], Loss: 0.297
Epoch:33 [330/412], Loss: 0.307
Epoch:33 [340/412], Loss: 0.393
Epoch:33 [350/412], Loss: 0.288
Epoch:33 [360/412], Loss: 0.244
Epoch:33 [370/412], Loss: 0.389
Epoch:33 [380/412], Loss: 0.301
Epoch:33 [390/412], Loss: 0.270
Epoch:33 [400/412], Loss: 0.225
Epoch:33 [410/412], Loss: 0.287
Epoch:33, Train IoU: [0.99268736 0.94476277 0.9466881 ]
Epoch:33, Valid Loss: 0.228, mIoU: 0.9658344432649005
Validation metric decreased (0.260659 --> 0.227536).  Saving model ...
Epoch:34 [0/412], Loss: 0.326
Epoch:34 [10/412], Loss: 0.235
Epoch:34 [20/412], Loss: 0.267
Epoch:34 [30/412], Loss: 0.213
Epoch:34 [40/412], Loss: 0.366
Epoch:34 [50/412], Loss: 0.231
Epoch:34 [60/412], Loss: 0.211
Epoch:34 [70/412], Loss: 0.259
Epoch:34 [80/412], Loss: 0.119
Epoch:34 [90/412], Loss: 0.430
Epoch:34 [100/412], Loss: 0.292
Epoch:34 [110/412], Loss: 0.277
Epoch:34 [120/412], Loss: 0.226
Epoch:34 [130/412], Loss: 0.331
Epoch:34 [140/412], Loss: 0.240
Epoch:34 [150/412], Loss: 0.309
Epoch:34 [160/412], Loss: 0.174
Epoch:34 [170/412], Loss: 0.353
Epoch:34 [180/412], Loss: 0.202
Epoch:34 [190/412], Loss: 0.240
Epoch:34 [200/412], Loss: 0.241
Epoch:34 [210/412], Loss: 0.261
Epoch:34 [220/412], Loss: 0.167
Epoch:34 [230/412], Loss: 0.138
Epoch:34 [240/412], Loss: 0.302
Epoch:34 [250/412], Loss: 0.222
Epoch:34 [260/412], Loss: 0.293
Epoch:34 [270/412], Loss: 0.257
Epoch:34 [280/412], Loss: 0.225
Epoch:34 [290/412], Loss: 0.201
Epoch:34 [300/412], Loss: 0.251
Epoch:34 [310/412], Loss: 0.204
Epoch:34 [320/412], Loss: 0.178
Epoch:34 [330/412], Loss: 0.269
Epoch:34 [340/412], Loss: 0.341
Epoch:34 [350/412], Loss: 0.266
Epoch:34 [360/412], Loss: 0.349
Epoch:34 [370/412], Loss: 0.283
Epoch:34 [380/412], Loss: 0.241
Epoch:34 [390/412], Loss: 0.479
Epoch:34 [400/412], Loss: 0.246
Epoch:34 [410/412], Loss: 0.383
Epoch:34, Train IoU: [0.99278696 0.94552254 0.94735766]
Epoch:34, Valid Loss: 0.229, mIoU: 0.9647759955091506
Validation metric decreased (0.227536 --> 0.228818).  Saving model ...
Epoch:35 [0/412], Loss: 0.261
Epoch:35 [10/412], Loss: 0.235
Epoch:35 [20/412], Loss: 0.247
Epoch:35 [30/412], Loss: 0.210
Epoch:35 [40/412], Loss: 0.305
Epoch:35 [50/412], Loss: 0.351
Epoch:35 [60/412], Loss: 0.244
Epoch:35 [70/412], Loss: 0.255
Epoch:35 [80/412], Loss: 0.196
Epoch:35 [90/412], Loss: 0.161
Epoch:35 [100/412], Loss: 0.374
Epoch:35 [110/412], Loss: 0.195
Epoch:35 [120/412], Loss: 0.203
Epoch:35 [130/412], Loss: 0.296
Epoch:35 [140/412], Loss: 0.445
Epoch:35 [150/412], Loss: 0.292
Epoch:35 [160/412], Loss: 0.281
Epoch:35 [170/412], Loss: 0.284
Epoch:35 [180/412], Loss: 0.208
Epoch:35 [190/412], Loss: 0.240
Epoch:35 [200/412], Loss: 0.337
Epoch:35 [210/412], Loss: 0.171
Epoch:35 [220/412], Loss: 0.251
Epoch:35 [230/412], Loss: 0.333
Epoch:35 [240/412], Loss: 0.182
Epoch:35 [250/412], Loss: 0.252
Epoch:35 [260/412], Loss: 0.203
Epoch:35 [270/412], Loss: 0.352
Epoch:35 [280/412], Loss: 0.333
Epoch:35 [290/412], Loss: 0.250
Epoch:35 [300/412], Loss: 0.300
Epoch:35 [310/412], Loss: 0.213
Epoch:35 [320/412], Loss: 0.232
Epoch:35 [330/412], Loss: 0.265
Epoch:35 [340/412], Loss: 0.182
Epoch:35 [350/412], Loss: 0.165
Epoch:35 [360/412], Loss: 0.231
Epoch:35 [370/412], Loss: 0.404
Epoch:35 [380/412], Loss: 0.482
Epoch:35 [390/412], Loss: 0.295
Epoch:35 [400/412], Loss: 0.263
Epoch:35 [410/412], Loss: 0.183
Epoch:35, Train IoU: [0.99289711 0.94645494 0.94752803]
Epoch:35, Valid Loss: 0.188, mIoU: 0.968730970492683
Validation metric decreased (0.228818 --> 0.188116).  Saving model ...
Epoch:36 [0/412], Loss: 0.229
Epoch:36 [10/412], Loss: 0.214
Epoch:36 [20/412], Loss: 0.296
Epoch:36 [30/412], Loss: 0.185
Epoch:36 [40/412], Loss: 0.187
Epoch:36 [50/412], Loss: 0.283
Epoch:36 [60/412], Loss: 0.233
Epoch:36 [70/412], Loss: 0.516
Epoch:36 [80/412], Loss: 0.302
Epoch:36 [90/412], Loss: 0.324
Epoch:36 [100/412], Loss: 0.275
Epoch:36 [110/412], Loss: 0.224
Epoch:36 [120/412], Loss: 0.191
Epoch:36 [130/412], Loss: 0.267
Epoch:36 [140/412], Loss: 0.258
Epoch:36 [150/412], Loss: 0.240
Epoch:36 [160/412], Loss: 0.180
Epoch:36 [170/412], Loss: 0.105
Epoch:36 [180/412], Loss: 0.176
Epoch:36 [190/412], Loss: 0.334
Epoch:36 [200/412], Loss: 0.348
Epoch:36 [210/412], Loss: 0.334
Epoch:36 [220/412], Loss: 0.237
Epoch:36 [230/412], Loss: 0.292
Epoch:36 [240/412], Loss: 0.203
Epoch:36 [250/412], Loss: 0.259
Epoch:36 [260/412], Loss: 0.473
Epoch:36 [270/412], Loss: 0.468
Epoch:36 [280/412], Loss: 0.232
Epoch:36 [290/412], Loss: 0.284
Epoch:36 [300/412], Loss: 0.109
Epoch:36 [310/412], Loss: 0.372
Epoch:36 [320/412], Loss: 0.339
Epoch:36 [330/412], Loss: 0.274
Epoch:36 [340/412], Loss: 0.237
Epoch:36 [350/412], Loss: 0.202
Epoch:36 [360/412], Loss: 0.427
Epoch:36 [370/412], Loss: 0.158
Epoch:36 [380/412], Loss: 0.199
Epoch:36 [390/412], Loss: 0.159
Epoch:36 [400/412], Loss: 0.232
Epoch:36 [410/412], Loss: 0.174
Epoch:36, Train IoU: [0.99273572 0.94515724 0.94669819]
Epoch:36, Valid Loss: 0.220, mIoU: 0.9656481888932346
EarlyStopping counter: 1 out of 100
Epoch:37 [0/412], Loss: 0.252
Epoch:37 [10/412], Loss: 0.366
Epoch:37 [20/412], Loss: 0.172
Epoch:37 [30/412], Loss: 0.218
Epoch:37 [40/412], Loss: 0.172
Epoch:37 [50/412], Loss: 0.337
Epoch:37 [60/412], Loss: 0.207
Epoch:37 [70/412], Loss: 0.142
Epoch:37 [80/412], Loss: 0.287
Epoch:37 [90/412], Loss: 0.305
Epoch:37 [100/412], Loss: 0.241
Epoch:37 [110/412], Loss: 0.250
Epoch:37 [120/412], Loss: 0.227
Epoch:37 [130/412], Loss: 0.332
Epoch:37 [140/412], Loss: 0.145
Epoch:37 [150/412], Loss: 0.238
Epoch:37 [160/412], Loss: 0.257
Epoch:37 [170/412], Loss: 0.268
Epoch:37 [180/412], Loss: 0.417
Epoch:37 [190/412], Loss: 0.215
Epoch:37 [200/412], Loss: 0.297
Epoch:37 [210/412], Loss: 0.204
Epoch:37 [220/412], Loss: 0.209
Epoch:37 [230/412], Loss: 0.204
Epoch:37 [240/412], Loss: 0.187
Epoch:37 [250/412], Loss: 0.364
Epoch:37 [260/412], Loss: 0.190
Epoch:37 [270/412], Loss: 0.152
Epoch:37 [280/412], Loss: 0.279
Epoch:37 [290/412], Loss: 0.211
Epoch:37 [300/412], Loss: 0.208
Epoch:37 [310/412], Loss: 0.248
Epoch:37 [320/412], Loss: 0.365
Epoch:37 [330/412], Loss: 0.236
Epoch:37 [340/412], Loss: 0.171
Epoch:37 [350/412], Loss: 0.217
Epoch:37 [360/412], Loss: 0.227
Epoch:37 [370/412], Loss: 0.280
Epoch:37 [380/412], Loss: 0.168
Epoch:37 [390/412], Loss: 0.338
Epoch:37 [400/412], Loss: 0.175
Epoch:37 [410/412], Loss: 0.174
Epoch:37, Train IoU: [0.99295726 0.94732916 0.94880949]
Epoch:37, Valid Loss: 0.174, mIoU: 0.9694751573594541
Validation metric decreased (0.188116 --> 0.174144).  Saving model ...
Epoch:38 [0/412], Loss: 0.220
Epoch:38 [10/412], Loss: 0.172
Epoch:38 [20/412], Loss: 0.128
Epoch:38 [30/412], Loss: 0.224
Epoch:38 [40/412], Loss: 0.197
Epoch:38 [50/412], Loss: 0.168
Epoch:38 [60/412], Loss: 0.188
Epoch:38 [70/412], Loss: 0.143
Epoch:38 [80/412], Loss: 0.171
Epoch:38 [90/412], Loss: 0.240
Epoch:38 [100/412], Loss: 0.147
Epoch:38 [110/412], Loss: 0.169
Epoch:38 [120/412], Loss: 0.216
Epoch:38 [130/412], Loss: 0.307
Epoch:38 [140/412], Loss: 0.167
Epoch:38 [150/412], Loss: 0.140
Epoch:38 [160/412], Loss: 0.182
Epoch:38 [170/412], Loss: 0.371
Epoch:38 [180/412], Loss: 0.127
Epoch:38 [190/412], Loss: 0.274
Epoch:38 [200/412], Loss: 0.169
Epoch:38 [210/412], Loss: 0.242
Epoch:38 [220/412], Loss: 0.261
Epoch:38 [230/412], Loss: 0.186
Epoch:38 [240/412], Loss: 0.281
Epoch:38 [250/412], Loss: 0.200
Epoch:38 [260/412], Loss: 0.176
Epoch:38 [270/412], Loss: 0.173
Epoch:38 [280/412], Loss: 0.259
Epoch:38 [290/412], Loss: 0.177
Epoch:38 [300/412], Loss: 0.132
Epoch:38 [310/412], Loss: 0.349
Epoch:38 [320/412], Loss: 0.235
Epoch:38 [330/412], Loss: 0.217
Epoch:38 [340/412], Loss: 0.188
Epoch:38 [350/412], Loss: 0.152
Epoch:38 [360/412], Loss: 0.278
Epoch:38 [370/412], Loss: 0.197
Epoch:38 [380/412], Loss: 0.122
Epoch:38 [390/412], Loss: 0.113
Epoch:38 [400/412], Loss: 0.195
Epoch:38 [410/412], Loss: 0.324
Epoch:38, Train IoU: [0.99299296 0.94813201 0.95010218]
Epoch:38, Valid Loss: 0.171, mIoU: 0.9683159836157581
Validation metric decreased (0.174144 --> 0.171485).  Saving model ...
Epoch:39 [0/412], Loss: 0.195
Epoch:39 [10/412], Loss: 0.343
Epoch:39 [20/412], Loss: 0.115
Epoch:39 [30/412], Loss: 0.188
Epoch:39 [40/412], Loss: 0.155
Epoch:39 [50/412], Loss: 0.176
Epoch:39 [60/412], Loss: 0.300
Epoch:39 [70/412], Loss: 0.130
Epoch:39 [80/412], Loss: 0.253
Epoch:39 [90/412], Loss: 0.112
Epoch:39 [100/412], Loss: 0.259
Epoch:39 [110/412], Loss: 0.207
Epoch:39 [120/412], Loss: 0.213
Epoch:39 [130/412], Loss: 0.166
Epoch:39 [140/412], Loss: 0.106
Epoch:39 [150/412], Loss: 0.213
Epoch:39 [160/412], Loss: 0.160
Epoch:39 [170/412], Loss: 0.149
Epoch:39 [180/412], Loss: 0.394
Epoch:39 [190/412], Loss: 0.189
Epoch:39 [200/412], Loss: 0.243
Epoch:39 [210/412], Loss: 0.201
Epoch:39 [220/412], Loss: 0.147
Epoch:39 [230/412], Loss: 0.167
Epoch:39 [240/412], Loss: 0.146
Epoch:39 [250/412], Loss: 0.166
Epoch:39 [260/412], Loss: 0.172
Epoch:39 [270/412], Loss: 0.298
Epoch:39 [280/412], Loss: 0.283
Epoch:39 [290/412], Loss: 0.199
Epoch:39 [300/412], Loss: 0.254
Epoch:39 [310/412], Loss: 0.249
Epoch:39 [320/412], Loss: 0.222
Epoch:39 [330/412], Loss: 0.123
Epoch:39 [340/412], Loss: 0.157
Epoch:39 [350/412], Loss: 0.206
Epoch:39 [360/412], Loss: 0.300
Epoch:39 [370/412], Loss: 0.161
Epoch:39 [380/412], Loss: 0.249
Epoch:39 [390/412], Loss: 0.163
Epoch:39 [400/412], Loss: 0.207
Epoch:39 [410/412], Loss: 0.245
Epoch:39, Train IoU: [0.99321691 0.95055365 0.95083866]
Epoch:39, Valid Loss: 0.155, mIoU: 0.9689127593539265
Validation metric decreased (0.171485 --> 0.154518).  Saving model ...
Epoch:40 [0/412], Loss: 0.097
Epoch:40 [10/412], Loss: 0.135
Epoch:40 [20/412], Loss: 0.262
Epoch:40 [30/412], Loss: 0.100
Epoch:40 [40/412], Loss: 0.193
Epoch:40 [50/412], Loss: 0.229
Epoch:40 [60/412], Loss: 0.169
Epoch:40 [70/412], Loss: 0.271
Epoch:40 [80/412], Loss: 0.227
Epoch:40 [90/412], Loss: 0.329
Epoch:40 [100/412], Loss: 0.199
Epoch:40 [110/412], Loss: 0.253
Epoch:40 [120/412], Loss: 0.175
Epoch:40 [130/412], Loss: 0.141
Epoch:40 [140/412], Loss: 0.115
Epoch:40 [150/412], Loss: 0.165
Epoch:40 [160/412], Loss: 0.189
Epoch:40 [170/412], Loss: 0.164
Epoch:40 [180/412], Loss: 0.203
Epoch:40 [190/412], Loss: 0.153
Epoch:40 [200/412], Loss: 0.105
Epoch:40 [210/412], Loss: 0.124
Epoch:40 [220/412], Loss: 0.199
Epoch:40 [230/412], Loss: 0.159
Epoch:40 [240/412], Loss: 0.108
Epoch:40 [250/412], Loss: 0.139
Epoch:40 [260/412], Loss: 0.155
Epoch:40 [270/412], Loss: 0.185
Epoch:40 [280/412], Loss: 0.213
Epoch:40 [290/412], Loss: 0.105
Epoch:40 [300/412], Loss: 0.182
Epoch:40 [310/412], Loss: 0.124
Epoch:40 [320/412], Loss: 0.250
Epoch:40 [330/412], Loss: 0.196
Epoch:40 [340/412], Loss: 0.153
Epoch:40 [350/412], Loss: 0.192
Epoch:40 [360/412], Loss: 0.263
Epoch:40 [370/412], Loss: 0.130
Epoch:40 [380/412], Loss: 0.180
Epoch:40 [390/412], Loss: 0.146
Epoch:40 [400/412], Loss: 0.162
Epoch:40 [410/412], Loss: 0.210
Epoch:40, Train IoU: [0.99311686 0.94922244 0.9506409 ]
Epoch:40, Valid Loss: 0.140, mIoU: 0.9689170042575967
Validation metric decreased (0.154518 --> 0.140127).  Saving model ...
Epoch:41 [0/412], Loss: 0.131
Epoch:41 [10/412], Loss: 0.197
Epoch:41 [20/412], Loss: 0.051
Epoch:41 [30/412], Loss: 0.148
Epoch:41 [40/412], Loss: 0.157
Epoch:41 [50/412], Loss: 0.135
Epoch:41 [60/412], Loss: 0.123
Epoch:41 [70/412], Loss: 0.083
Epoch:41 [80/412], Loss: 0.075
Epoch:41 [90/412], Loss: 0.170
Epoch:41 [100/412], Loss: 0.193
Epoch:41 [110/412], Loss: 0.274
Epoch:41 [120/412], Loss: 0.143
Epoch:41 [130/412], Loss: 0.280
Epoch:41 [140/412], Loss: 0.126
Epoch:41 [150/412], Loss: 0.190
Epoch:41 [160/412], Loss: 0.104
Epoch:41 [170/412], Loss: 0.247
Epoch:41 [180/412], Loss: 0.250
Epoch:41 [190/412], Loss: 0.170
Epoch:41 [200/412], Loss: 0.111
Epoch:41 [210/412], Loss: 0.128
Epoch:41 [220/412], Loss: 0.210
Epoch:41 [230/412], Loss: 0.147
Epoch:41 [240/412], Loss: 0.184
Epoch:41 [250/412], Loss: 0.200
Epoch:41 [260/412], Loss: 0.152
Epoch:41 [270/412], Loss: 0.201
Epoch:41 [280/412], Loss: 0.069
Epoch:41 [290/412], Loss: 0.273
Epoch:41 [300/412], Loss: 0.157
Epoch:41 [310/412], Loss: 0.229
Epoch:41 [320/412], Loss: 0.162
Epoch:41 [330/412], Loss: 0.127
Epoch:41 [340/412], Loss: 0.200
Epoch:41 [350/412], Loss: 0.195
Epoch:41 [360/412], Loss: 0.152
Epoch:41 [370/412], Loss: 0.149
Epoch:41 [380/412], Loss: 0.112
Epoch:41 [390/412], Loss: 0.121
Epoch:41 [400/412], Loss: 0.220
Epoch:41 [410/412], Loss: 0.255
Epoch:41, Train IoU: [0.9931477  0.94998932 0.95099907]
Epoch:41, Valid Loss: 0.131, mIoU: 0.9692095907891293
Validation metric decreased (0.140127 --> 0.131332).  Saving model ...
Epoch:42 [0/412], Loss: 0.082
Epoch:42 [10/412], Loss: 0.124
Epoch:42 [20/412], Loss: 0.103
Epoch:42 [30/412], Loss: 0.101
Epoch:42 [40/412], Loss: 0.226
Epoch:42 [50/412], Loss: 0.068
Epoch:42 [60/412], Loss: 0.107
Epoch:42 [70/412], Loss: 0.184
Epoch:42 [80/412], Loss: 0.147
Epoch:42 [90/412], Loss: 0.149
Epoch:42 [100/412], Loss: 0.137
Epoch:42 [110/412], Loss: 0.186
Epoch:42 [120/412], Loss: 0.069
Epoch:42 [130/412], Loss: 0.189
Epoch:42 [140/412], Loss: 0.184
Epoch:42 [150/412], Loss: 0.176
Epoch:42 [160/412], Loss: 0.092
Epoch:42 [170/412], Loss: 0.153
Epoch:42 [180/412], Loss: 0.145
Epoch:42 [190/412], Loss: 0.136
Epoch:42 [200/412], Loss: 0.203
Epoch:42 [210/412], Loss: 0.102
Epoch:42 [220/412], Loss: 0.161
Epoch:42 [230/412], Loss: 0.090
Epoch:42 [240/412], Loss: 0.198
Epoch:42 [250/412], Loss: 0.211
Epoch:42 [260/412], Loss: 0.164
Epoch:42 [270/412], Loss: 0.070
Epoch:42 [280/412], Loss: 0.044
Epoch:42 [290/412], Loss: 0.349
Epoch:42 [300/412], Loss: 0.237
Epoch:42 [310/412], Loss: 0.061
Epoch:42 [320/412], Loss: 0.283
Epoch:42 [330/412], Loss: 0.125
Epoch:42 [340/412], Loss: 0.120
Epoch:42 [350/412], Loss: 0.182
Epoch:42 [360/412], Loss: 0.149
Epoch:42 [370/412], Loss: 0.148
Epoch:42 [380/412], Loss: 0.055
Epoch:42 [390/412], Loss: 0.051
Epoch:42 [400/412], Loss: 0.179
Epoch:42 [410/412], Loss: 0.144
Epoch:42, Train IoU: [0.99335446 0.95138745 0.95210003]
Epoch:42, Valid Loss: 0.147, mIoU: 0.9656559488681169
EarlyStopping counter: 1 out of 100
Epoch:43 [0/412], Loss: 0.132
Epoch:43 [10/412], Loss: 0.153
Epoch:43 [20/412], Loss: 0.138
Epoch:43 [30/412], Loss: 0.111
Epoch:43 [40/412], Loss: 0.210
Epoch:43 [50/412], Loss: 0.100
Epoch:43 [60/412], Loss: 0.083
Epoch:43 [70/412], Loss: 0.071
Epoch:43 [80/412], Loss: 0.204
Epoch:43 [90/412], Loss: 0.182
Epoch:43 [100/412], Loss: 0.080
Epoch:43 [110/412], Loss: 0.075
Epoch:43 [120/412], Loss: 0.163
Epoch:43 [130/412], Loss: 0.193
Epoch:43 [140/412], Loss: 0.118
Epoch:43 [150/412], Loss: 0.150
Epoch:43 [160/412], Loss: 0.107
Epoch:43 [170/412], Loss: 0.141
Epoch:43 [180/412], Loss: 0.156
Epoch:43 [190/412], Loss: 0.102
Epoch:43 [200/412], Loss: 0.189
Epoch:43 [210/412], Loss: 0.170
Epoch:43 [220/412], Loss: 0.133
Epoch:43 [230/412], Loss: 0.295
Epoch:43 [240/412], Loss: 0.242
Epoch:43 [250/412], Loss: 0.127
Epoch:43 [260/412], Loss: 0.096
Epoch:43 [270/412], Loss: 0.184
Epoch:43 [280/412], Loss: 0.164
Epoch:43 [290/412], Loss: 0.143
Epoch:43 [300/412], Loss: 0.140
Epoch:43 [310/412], Loss: 0.096
Epoch:43 [320/412], Loss: 0.162
Epoch:43 [330/412], Loss: 0.141
Epoch:43 [340/412], Loss: 0.217
Epoch:43 [350/412], Loss: 0.060
Epoch:43 [360/412], Loss: 0.104
Epoch:43 [370/412], Loss: 0.240
Epoch:43 [380/412], Loss: 0.095
Epoch:43 [390/412], Loss: 0.353
Epoch:43 [400/412], Loss: 0.135
Epoch:43 [410/412], Loss: 0.081
Epoch:43, Train IoU: [0.99330032 0.95125615 0.95211497]
Epoch:43, Valid Loss: 0.111, mIoU: 0.9696597081823027
Validation metric decreased (0.131332 --> 0.110684).  Saving model ...
Epoch:44 [0/412], Loss: 0.155
Epoch:44 [10/412], Loss: 0.087
Epoch:44 [20/412], Loss: 0.103
Epoch:44 [30/412], Loss: 0.122
Epoch:44 [40/412], Loss: 0.126
Epoch:44 [50/412], Loss: 0.081
Epoch:44 [60/412], Loss: 0.102
Epoch:44 [70/412], Loss: 0.127
Epoch:44 [80/412], Loss: 0.231
Epoch:44 [90/412], Loss: 0.109
Epoch:44 [100/412], Loss: 0.037
Epoch:44 [110/412], Loss: 0.136
Epoch:44 [120/412], Loss: 0.111
Epoch:44 [130/412], Loss: 0.239
Epoch:44 [140/412], Loss: 0.106
Epoch:44 [150/412], Loss: 0.121
Epoch:44 [160/412], Loss: 0.054
Epoch:44 [170/412], Loss: 0.250
Epoch:44 [180/412], Loss: 0.145
Epoch:44 [190/412], Loss: 0.086
Epoch:44 [200/412], Loss: 0.034
Epoch:44 [210/412], Loss: 0.108
Epoch:44 [220/412], Loss: 0.226
Epoch:44 [230/412], Loss: 0.126
Epoch:44 [240/412], Loss: 0.115
Epoch:44 [250/412], Loss: 0.163
Epoch:44 [260/412], Loss: 0.185
Epoch:44 [270/412], Loss: 0.089
Epoch:44 [280/412], Loss: 0.155
Epoch:44 [290/412], Loss: 0.270
Epoch:44 [300/412], Loss: 0.114
Epoch:44 [310/412], Loss: 0.088
Epoch:44 [320/412], Loss: 0.103
Epoch:44 [330/412], Loss: 0.151
Epoch:44 [340/412], Loss: 0.114
Epoch:44 [350/412], Loss: 0.073
Epoch:44 [360/412], Loss: 0.110
Epoch:44 [370/412], Loss: 0.121
Epoch:44 [380/412], Loss: 0.065
Epoch:44 [390/412], Loss: 0.126
Epoch:44 [400/412], Loss: 0.095
Epoch:44 [410/412], Loss: 0.046
Epoch:44, Train IoU: [0.99337983 0.95228499 0.95284884]
Epoch:44, Valid Loss: 0.083, mIoU: 0.9714240292067515
Validation metric decreased (0.110684 --> 0.082987).  Saving model ...
Epoch:45 [0/412], Loss: 0.101
Epoch:45 [10/412], Loss: 0.077
Epoch:45 [20/412], Loss: 0.007
Epoch:45 [30/412], Loss: 0.079
Epoch:45 [40/412], Loss: 0.071
Epoch:45 [50/412], Loss: 0.043
Epoch:45 [60/412], Loss: 0.136
Epoch:45 [70/412], Loss: 0.095
Epoch:45 [80/412], Loss: 0.043
Epoch:45 [90/412], Loss: 0.013
Epoch:45 [100/412], Loss: 0.133
Epoch:45 [110/412], Loss: 0.095
Epoch:45 [120/412], Loss: 0.133
Epoch:45 [130/412], Loss: 0.101
Epoch:45 [140/412], Loss: 0.068
Epoch:45 [150/412], Loss: 0.093
Epoch:45 [160/412], Loss: 0.133
Epoch:45 [170/412], Loss: 0.061
Epoch:45 [180/412], Loss: 0.206
Epoch:45 [190/412], Loss: 0.078
Epoch:45 [200/412], Loss: 0.133
Epoch:45 [210/412], Loss: 0.048
Epoch:45 [220/412], Loss: 0.091
Epoch:45 [230/412], Loss: 0.076
Epoch:45 [240/412], Loss: 0.171
Epoch:45 [250/412], Loss: 0.052
Epoch:45 [260/412], Loss: 0.201
Epoch:45 [270/412], Loss: 0.010
Epoch:45 [280/412], Loss: 0.086
Epoch:45 [290/412], Loss: 0.065
Epoch:45 [300/412], Loss: 0.153
Epoch:45 [310/412], Loss: 0.135
Epoch:45 [320/412], Loss: 0.127
Epoch:45 [330/412], Loss: 0.099
Epoch:45 [340/412], Loss: 0.116
Epoch:45 [350/412], Loss: 0.056
Epoch:45 [360/412], Loss: 0.171
Epoch:45 [370/412], Loss: 0.091
Epoch:45 [380/412], Loss: 0.080
Epoch:45 [390/412], Loss: 0.198
Epoch:45 [400/412], Loss: 0.104
Epoch:45 [410/412], Loss: 0.140
Epoch:45, Train IoU: [0.99346294 0.95289282 0.9529366 ]
Epoch:45, Valid Loss: 0.090, mIoU: 0.9704576328447221
Validation metric decreased (0.082987 --> 0.089855).  Saving model ...
Epoch:46 [0/412], Loss: 0.093
Epoch:46 [10/412], Loss: 0.148
Epoch:46 [20/412], Loss: 0.047
Epoch:46 [30/412], Loss: 0.097
Epoch:46 [40/412], Loss: 0.119
Epoch:46 [50/412], Loss: 0.105
Epoch:46 [60/412], Loss: 0.042
Epoch:46 [70/412], Loss: 0.212
Epoch:46 [80/412], Loss: 0.120
Epoch:46 [90/412], Loss: 0.188
Epoch:46 [100/412], Loss: 0.147
Epoch:46 [110/412], Loss: 0.116
Epoch:46 [120/412], Loss: 0.191
Epoch:46 [130/412], Loss: 0.111
Epoch:46 [140/412], Loss: 0.058
Epoch:46 [150/412], Loss: 0.095
Epoch:46 [160/412], Loss: 0.140
Epoch:46 [170/412], Loss: 0.084
Epoch:46 [180/412], Loss: 0.103
Epoch:46 [190/412], Loss: 0.383
Epoch:46 [200/412], Loss: 0.208
Epoch:46 [210/412], Loss: 0.040
Epoch:46 [220/412], Loss: 0.191
Epoch:46 [230/412], Loss: 0.070
Epoch:46 [240/412], Loss: 0.100
Epoch:46 [250/412], Loss: 0.120
Epoch:46 [260/412], Loss: 0.082
Epoch:46 [270/412], Loss: 0.121
Epoch:46 [280/412], Loss: 0.307
Epoch:46 [290/412], Loss: 0.162
Epoch:46 [300/412], Loss: 0.123
Epoch:46 [310/412], Loss: 0.130
Epoch:46 [320/412], Loss: 0.038
Epoch:46 [330/412], Loss: 0.157
Epoch:46 [340/412], Loss: 0.094
Epoch:46 [350/412], Loss: 0.212
Epoch:46 [360/412], Loss: 0.095
Epoch:46 [370/412], Loss: 0.137
Epoch:46 [380/412], Loss: 0.200
Epoch:46 [390/412], Loss: 0.095
Epoch:46 [400/412], Loss: 0.086
Epoch:46 [410/412], Loss: 0.078
Epoch:46, Train IoU: [0.99337396 0.95204953 0.95304278]
Epoch:46, Valid Loss: 0.078, mIoU: 0.9708977690441006
Validation metric decreased (0.089855 --> 0.078330).  Saving model ...
Epoch:47 [0/412], Loss: 0.102
Epoch:47 [10/412], Loss: 0.074
Epoch:47 [20/412], Loss: 0.041
Epoch:47 [30/412], Loss: 0.079
Epoch:47 [40/412], Loss: 0.010
Epoch:47 [50/412], Loss: 0.031
Epoch:47 [60/412], Loss: 0.090
Epoch:47 [70/412], Loss: 0.152
Epoch:47 [80/412], Loss: 0.114
Epoch:47 [90/412], Loss: 0.032
Epoch:47 [100/412], Loss: 0.127
Epoch:47 [110/412], Loss: 0.145
Epoch:47 [120/412], Loss: 0.168
Epoch:47 [130/412], Loss: 0.037
Epoch:47 [140/412], Loss: 0.031
Epoch:47 [150/412], Loss: 0.076
Epoch:47 [160/412], Loss: 0.115
Epoch:47 [170/412], Loss: 0.009
Epoch:47 [180/412], Loss: 0.050
Epoch:47 [190/412], Loss: 0.119
Epoch:47 [200/412], Loss: 0.051
Epoch:47 [210/412], Loss: 0.278
Epoch:47 [220/412], Loss: 0.088
Epoch:47 [230/412], Loss: 0.017
Epoch:47 [240/412], Loss: 0.123
Epoch:47 [250/412], Loss: 0.113
Epoch:47 [260/412], Loss: 0.173
Epoch:47 [270/412], Loss: 0.108
Epoch:47 [280/412], Loss: 0.198
Epoch:47 [290/412], Loss: 0.054
Epoch:47 [300/412], Loss: 0.181
Epoch:47 [310/412], Loss: 0.122
Epoch:47 [320/412], Loss: 0.138
Epoch:47 [330/412], Loss: 0.056
Epoch:47 [340/412], Loss: 0.014
Epoch:47 [350/412], Loss: 0.171
Epoch:47 [360/412], Loss: 0.110
Epoch:47 [370/412], Loss: 0.200
Epoch:47 [380/412], Loss: 0.097
Epoch:47 [390/412], Loss: 0.034
Epoch:47 [400/412], Loss: 0.103
Epoch:47 [410/412], Loss: 0.079
Epoch:47, Train IoU: [0.99355917 0.95409084 0.95387866]
Epoch:47, Valid Loss: 0.105, mIoU: 0.9653436550603507
EarlyStopping counter: 1 out of 100
Epoch:48 [0/412], Loss: 0.041
Epoch:48 [10/412], Loss: 0.054
Epoch:48 [20/412], Loss: 0.060
Epoch:48 [30/412], Loss: 0.180
Epoch:48 [40/412], Loss: 0.280
Epoch:48 [50/412], Loss: 0.075
Epoch:48 [60/412], Loss: 0.105
Epoch:48 [70/412], Loss: 0.026
Epoch:48 [80/412], Loss: 0.120
Epoch:48 [90/412], Loss: 0.129
Epoch:48 [100/412], Loss: 0.073
Epoch:48 [110/412], Loss: 0.049
Epoch:48 [120/412], Loss: 0.194
Epoch:48 [130/412], Loss: 0.096
Epoch:48 [140/412], Loss: 0.049
Epoch:48 [150/412], Loss: 0.037
Epoch:48 [160/412], Loss: 0.106
Epoch:48 [170/412], Loss: 0.406
Epoch:48 [180/412], Loss: 0.123
Epoch:48 [190/412], Loss: 0.177
Epoch:48 [200/412], Loss: 0.171
Epoch:48 [210/412], Loss: 0.053
Epoch:48 [220/412], Loss: 0.035
Epoch:48 [230/412], Loss: 0.042
Epoch:48 [240/412], Loss: 0.066
Epoch:48 [250/412], Loss: 0.052
Epoch:48 [260/412], Loss: 0.236
Epoch:48 [270/412], Loss: 0.022
Epoch:48 [280/412], Loss: 0.022
Epoch:48 [290/412], Loss: 0.326
Epoch:48 [300/412], Loss: 0.051
Epoch:48 [310/412], Loss: 0.094
Epoch:48 [320/412], Loss: 0.056
Epoch:48 [330/412], Loss: 0.126
Epoch:48 [340/412], Loss: 0.020
Epoch:48 [350/412], Loss: 0.174
Epoch:48 [360/412], Loss: 0.058
Epoch:48 [370/412], Loss: 0.122
Epoch:48 [380/412], Loss: 0.034
Epoch:48 [390/412], Loss: 0.042
Epoch:48 [400/412], Loss: 0.058
Epoch:48 [410/412], Loss: 0.124
Epoch:48, Train IoU: [0.99341366 0.9524244  0.95303881]
Epoch:48, Valid Loss: 0.061, mIoU: 0.9704779961250689
Validation metric decreased (0.078330 --> 0.060873).  Saving model ...
Epoch:49 [0/412], Loss: 0.106
Epoch:49 [10/412], Loss: 0.169
Epoch:49 [20/412], Loss: 0.215
Epoch:49 [30/412], Loss: -0.003
Epoch:49 [40/412], Loss: 0.081
Epoch:49 [50/412], Loss: 0.125
Epoch:49 [60/412], Loss: 0.060
Epoch:49 [70/412], Loss: 0.044
Epoch:49 [80/412], Loss: 0.120
Epoch:49 [90/412], Loss: 0.035
Epoch:49 [100/412], Loss: 0.077
Epoch:49 [110/412], Loss: 0.109
Epoch:49 [120/412], Loss: 0.096
Epoch:49 [130/412], Loss: 0.062
Epoch:49 [140/412], Loss: 0.037
Epoch:49 [150/412], Loss: 0.122
Epoch:49 [160/412], Loss: 0.157
Epoch:49 [170/412], Loss: 0.138
Epoch:49 [180/412], Loss: 0.065
Epoch:49 [190/412], Loss: -0.009
Epoch:49 [200/412], Loss: 0.093
Epoch:49 [210/412], Loss: 0.149
Epoch:49 [220/412], Loss: 0.052
Epoch:49 [230/412], Loss: 0.026
Epoch:49 [240/412], Loss: 0.018
Epoch:49 [250/412], Loss: 0.012
Epoch:49 [260/412], Loss: 0.048
Epoch:49 [270/412], Loss: 0.062
Epoch:49 [280/412], Loss: 0.120
Epoch:49 [290/412], Loss: 0.124
Epoch:49 [300/412], Loss: 0.313
Epoch:49 [310/412], Loss: 0.019
Epoch:49 [320/412], Loss: 0.037
Epoch:49 [330/412], Loss: 0.050
Epoch:49 [340/412], Loss: 0.073
Epoch:49 [350/412], Loss: 0.030
Epoch:49 [360/412], Loss: 0.128
Epoch:49 [370/412], Loss: 0.053
Epoch:49 [380/412], Loss: 0.145
Epoch:49 [390/412], Loss: 0.107
Epoch:49 [400/412], Loss: 0.080
Epoch:49 [410/412], Loss: 0.031
Epoch:49, Train IoU: [0.99355461 0.9539322  0.9540514 ]
Epoch:49, Valid Loss: 0.067, mIoU: 0.9705323817044652
Validation metric decreased (0.060873 --> 0.066524).  Saving model ...
Epoch:50 [0/412], Loss: 0.033
Epoch:50 [10/412], Loss: 0.191
Epoch:50 [20/412], Loss: 0.022
Epoch:50 [30/412], Loss: 0.017
Epoch:50 [40/412], Loss: 0.039
Epoch:50 [50/412], Loss: 0.058
Epoch:50 [60/412], Loss: 0.110
Epoch:50 [70/412], Loss: 0.061
Epoch:50 [80/412], Loss: 0.026
Epoch:50 [90/412], Loss: 0.028
Epoch:50 [100/412], Loss: 0.094
Epoch:50 [110/412], Loss: 0.003
Epoch:50 [120/412], Loss: 0.099
Epoch:50 [130/412], Loss: 0.030
Epoch:50 [140/412], Loss: -0.006
Epoch:50 [150/412], Loss: 0.039
Epoch:50 [160/412], Loss: 0.061
Epoch:50 [170/412], Loss: 0.050
Epoch:50 [180/412], Loss: 0.236
Epoch:50 [190/412], Loss: 0.024
Epoch:50 [200/412], Loss: 0.167
Epoch:50 [210/412], Loss: 0.205
Epoch:50 [220/412], Loss: 0.068
Epoch:50 [230/412], Loss: -0.015
Epoch:50 [240/412], Loss: 0.073
Epoch:50 [250/412], Loss: 0.142
Epoch:50 [260/412], Loss: -0.012
Epoch:50 [270/412], Loss: 0.291
Epoch:50 [280/412], Loss: 0.034
Epoch:50 [290/412], Loss: 0.027
Epoch:50 [300/412], Loss: 0.073
Epoch:50 [310/412], Loss: 0.016
Epoch:50 [320/412], Loss: 0.131
Epoch:50 [330/412], Loss: 0.069
Epoch:50 [340/412], Loss: 0.103
Epoch:50 [350/412], Loss: 0.093
Epoch:50 [360/412], Loss: 0.041
Epoch:50 [370/412], Loss: 0.083
Epoch:50 [380/412], Loss: 0.108
Epoch:50 [390/412], Loss: 0.060
Epoch:50 [400/412], Loss: 0.088
Epoch:50 [410/412], Loss: 0.092
Epoch:50, Train IoU: [0.99368332 0.95504663 0.95473301]
Epoch:50, Valid Loss: 0.040, mIoU: 0.9704441103490423
Validation metric decreased (0.066524 --> 0.040151).  Saving model ...
Epoch:51 [0/412], Loss: 0.043
Epoch:51 [10/412], Loss: 0.041
Epoch:51 [20/412], Loss: 0.054
Epoch:51 [30/412], Loss: -0.008
Epoch:51 [40/412], Loss: 0.067
Epoch:51 [50/412], Loss: 0.016
Epoch:51 [60/412], Loss: 0.007
Epoch:51 [70/412], Loss: 0.086
Epoch:51 [80/412], Loss: -0.025
Epoch:51 [90/412], Loss: 0.103
Epoch:51 [100/412], Loss: 0.076
Epoch:51 [110/412], Loss: 0.066
Epoch:51 [120/412], Loss: 0.061
Epoch:51 [130/412], Loss: 0.007
Epoch:51 [140/412], Loss: -0.019
Epoch:51 [150/412], Loss: 0.063
Epoch:51 [160/412], Loss: 0.024
Epoch:51 [170/412], Loss: 0.057
Epoch:51 [180/412], Loss: 0.102
Epoch:51 [190/412], Loss: 0.054
Epoch:51 [200/412], Loss: 0.074
Epoch:51 [210/412], Loss: 0.276
Epoch:51 [220/412], Loss: 0.005
Epoch:51 [230/412], Loss: 0.054
Epoch:51 [240/412], Loss: 0.072
Epoch:51 [250/412], Loss: 0.027
Epoch:51 [260/412], Loss: 0.063
Epoch:51 [270/412], Loss: 0.108
Epoch:51 [280/412], Loss: 0.034
Epoch:51 [290/412], Loss: 0.273
Epoch:51 [300/412], Loss: -0.021
Epoch:51 [310/412], Loss: 0.013
Epoch:51 [320/412], Loss: 0.037
Epoch:51 [330/412], Loss: 0.057
Epoch:51 [340/412], Loss: 0.010
Epoch:51 [350/412], Loss: 0.150
Epoch:51 [360/412], Loss: 0.047
Epoch:51 [370/412], Loss: -0.008
Epoch:51 [380/412], Loss: 0.046
Epoch:51 [390/412], Loss: 0.062
Epoch:51 [400/412], Loss: 0.045
Epoch:51 [410/412], Loss: 0.058
Epoch:51, Train IoU: [0.9937085  0.95520213 0.95472901]
Epoch:51, Valid Loss: 0.028, mIoU: 0.9721658099044017
Validation metric decreased (0.040151 --> 0.027907).  Saving model ...
Epoch:52 [0/412], Loss: 0.002
Epoch:52 [10/412], Loss: 0.013
Epoch:52 [20/412], Loss: 0.054
Epoch:52 [30/412], Loss: 0.006
Epoch:52 [40/412], Loss: 0.074
Epoch:52 [50/412], Loss: 0.077
Epoch:52 [60/412], Loss: 0.034
Epoch:52 [70/412], Loss: 0.084
Epoch:52 [80/412], Loss: 0.167
Epoch:52 [90/412], Loss: 0.020
Epoch:52 [100/412], Loss: 0.111
Epoch:52 [110/412], Loss: 0.010
Epoch:52 [120/412], Loss: 0.117
Epoch:52 [130/412], Loss: 0.032
Epoch:52 [140/412], Loss: 0.099
Epoch:52 [150/412], Loss: 0.022
Epoch:52 [160/412], Loss: 0.080
Epoch:52 [170/412], Loss: 0.058
Epoch:52 [180/412], Loss: 0.029
Epoch:52 [190/412], Loss: 0.085
Epoch:52 [200/412], Loss: 0.019
Epoch:52 [210/412], Loss: 0.029
Epoch:52 [220/412], Loss: -0.087
Epoch:52 [230/412], Loss: 0.038
Epoch:52 [240/412], Loss: 0.087
Epoch:52 [250/412], Loss: 0.008
Epoch:52 [260/412], Loss: 0.021
Epoch:52 [270/412], Loss: 0.053
Epoch:52 [280/412], Loss: 0.035
Epoch:52 [290/412], Loss: 0.084
Epoch:52 [300/412], Loss: 0.097
Epoch:52 [310/412], Loss: 0.018
Epoch:52 [320/412], Loss: 0.052
Epoch:52 [330/412], Loss: 0.007
Epoch:52 [340/412], Loss: -0.021
Epoch:52 [350/412], Loss: 0.002
Epoch:52 [360/412], Loss: 0.112
Epoch:52 [370/412], Loss: 0.081
Epoch:52 [380/412], Loss: 0.097
Epoch:52 [390/412], Loss: -0.001
Epoch:52 [400/412], Loss: -0.012
Epoch:52 [410/412], Loss: 0.086
Epoch:52, Train IoU: [0.9936321  0.9545361  0.95512327]
Epoch:52, Valid Loss: 0.036, mIoU: 0.9701629407216493
Validation metric decreased (0.027907 --> 0.035947).  Saving model ...
Epoch:53 [0/412], Loss: 0.099
Epoch:53 [10/412], Loss: 0.058
Epoch:53 [20/412], Loss: -0.025
Epoch:53 [30/412], Loss: 0.056
Epoch:53 [40/412], Loss: 0.024
Epoch:53 [50/412], Loss: -0.011
Epoch:53 [60/412], Loss: 0.033
Epoch:53 [70/412], Loss: 0.036
Epoch:53 [80/412], Loss: -0.032
Epoch:53 [90/412], Loss: 0.024
Epoch:53 [100/412], Loss: 0.042
Epoch:53 [110/412], Loss: 0.082
Epoch:53 [120/412], Loss: -0.004
Epoch:53 [130/412], Loss: -0.002
Epoch:53 [140/412], Loss: -0.034
Epoch:53 [150/412], Loss: 0.001
Epoch:53 [160/412], Loss: 0.105
Epoch:53 [170/412], Loss: -0.015
Epoch:53 [180/412], Loss: 0.029
Epoch:53 [190/412], Loss: 0.044
Epoch:53 [200/412], Loss: 0.055
Epoch:53 [210/412], Loss: 0.009
Epoch:53 [220/412], Loss: -0.021
Epoch:53 [230/412], Loss: -0.006
Epoch:53 [240/412], Loss: 0.080
Epoch:53 [250/412], Loss: -0.016
Epoch:53 [260/412], Loss: 0.038
Epoch:53 [270/412], Loss: 0.043
Epoch:53 [280/412], Loss: -0.054
Epoch:53 [290/412], Loss: -0.063
Epoch:53 [300/412], Loss: 0.086
Epoch:53 [310/412], Loss: 0.016
Epoch:53 [320/412], Loss: -0.056
Epoch:53 [330/412], Loss: 0.011
Epoch:53 [340/412], Loss: -0.049
Epoch:53 [350/412], Loss: 0.061
Epoch:53 [360/412], Loss: -0.045
Epoch:53 [370/412], Loss: 0.090
Epoch:53 [380/412], Loss: 0.062
Epoch:53 [390/412], Loss: 0.087
Epoch:53 [400/412], Loss: 0.037
Epoch:53 [410/412], Loss: 0.092
Epoch:53, Train IoU: [0.99380766 0.95658878 0.95589359]
Epoch:53, Valid Loss: 0.031, mIoU: 0.9693291157363069
Validation metric decreased (0.035947 --> 0.030896).  Saving model ...
Epoch:54 [0/412], Loss: 0.005
Epoch:54 [10/412], Loss: 0.085
Epoch:54 [20/412], Loss: -0.063
Epoch:54 [30/412], Loss: 0.061
Epoch:54 [40/412], Loss: 0.040
Epoch:54 [50/412], Loss: 0.194
Epoch:54 [60/412], Loss: 0.040
Epoch:54 [70/412], Loss: 0.065
Epoch:54 [80/412], Loss: 0.000
Epoch:54 [90/412], Loss: 0.006
Epoch:54 [100/412], Loss: 0.003
Epoch:54 [110/412], Loss: 0.074
Epoch:54 [120/412], Loss: 0.004
Epoch:54 [130/412], Loss: 0.093
Epoch:54 [140/412], Loss: 0.046
Epoch:54 [150/412], Loss: 0.001
Epoch:54 [160/412], Loss: 0.039
Epoch:54 [170/412], Loss: 0.034
Epoch:54 [180/412], Loss: 0.078
Epoch:54 [190/412], Loss: -0.038
Epoch:54 [200/412], Loss: 0.062
Epoch:54 [210/412], Loss: -0.009
Epoch:54 [220/412], Loss: 0.022
Epoch:54 [230/412], Loss: -0.047
Epoch:54 [240/412], Loss: 0.037
Epoch:54 [250/412], Loss: 0.061
Epoch:54 [260/412], Loss: 0.070
Epoch:54 [270/412], Loss: 0.220
Epoch:54 [280/412], Loss: 0.081
Epoch:54 [290/412], Loss: -0.036
Epoch:54 [300/412], Loss: 0.028
Epoch:54 [310/412], Loss: -0.132
Epoch:54 [320/412], Loss: -0.015
Epoch:54 [330/412], Loss: 0.057
Epoch:54 [340/412], Loss: -0.013
Epoch:54 [350/412], Loss: 0.027
Epoch:54 [360/412], Loss: -0.026
Epoch:54 [370/412], Loss: 0.008
Epoch:54 [380/412], Loss: 0.054
Epoch:54 [390/412], Loss: 0.061
Epoch:54 [400/412], Loss: 0.091
Epoch:54 [410/412], Loss: 0.105
Epoch:54, Train IoU: [0.99368851 0.95564975 0.95561416]
Epoch:54, Valid Loss: 0.001, mIoU: 0.9726032781689303
Validation metric decreased (0.030896 --> 0.000566).  Saving model ...
Epoch:55 [0/412], Loss: -0.019
Epoch:55 [10/412], Loss: 0.035
Epoch:55 [20/412], Loss: -0.042
Epoch:55 [30/412], Loss: 0.069
Epoch:55 [40/412], Loss: 0.061
Epoch:55 [50/412], Loss: -0.037
Epoch:55 [60/412], Loss: 0.041
Epoch:55 [70/412], Loss: 0.013
Epoch:55 [80/412], Loss: -0.002
Epoch:55 [90/412], Loss: -0.068
Epoch:55 [100/412], Loss: 0.010
Epoch:55 [110/412], Loss: -0.001
Epoch:55 [120/412], Loss: -0.007
Epoch:55 [130/412], Loss: -0.040
Epoch:55 [140/412], Loss: -0.039
Epoch:55 [150/412], Loss: 0.081
Epoch:55 [160/412], Loss: 0.069
Epoch:55 [170/412], Loss: 0.051
Epoch:55 [180/412], Loss: 0.061
Epoch:55 [190/412], Loss: 0.056
Epoch:55 [200/412], Loss: 0.033
Epoch:55 [210/412], Loss: 0.003
Epoch:55 [220/412], Loss: -0.063
Epoch:55 [230/412], Loss: -0.025
Epoch:55 [240/412], Loss: 0.091
Epoch:55 [250/412], Loss: 0.066
Epoch:55 [260/412], Loss: 0.022
Epoch:55 [270/412], Loss: -0.036
Epoch:55 [280/412], Loss: 0.014
Epoch:55 [290/412], Loss: 0.002
Epoch:55 [300/412], Loss: 0.086
Epoch:55 [310/412], Loss: 0.092
Epoch:55 [320/412], Loss: -0.050
Epoch:55 [330/412], Loss: 0.077
Epoch:55 [340/412], Loss: 0.008
Epoch:55 [350/412], Loss: 0.080
Epoch:55 [360/412], Loss: 0.016
Epoch:55 [370/412], Loss: -0.006
Epoch:55 [380/412], Loss: 0.022
Epoch:55 [390/412], Loss: -0.026
Epoch:55 [400/412], Loss: -0.073
Epoch:55 [410/412], Loss: 0.001
Epoch:55, Train IoU: [0.99394996 0.95796333 0.95675078]
Epoch:55, Valid Loss: 0.001, mIoU: 0.9706624310333756
Validation metric decreased (0.000566 --> 0.000815).  Saving model ...
Epoch:56 [0/412], Loss: -0.016
Epoch:56 [10/412], Loss: -0.018
Epoch:56 [20/412], Loss: -0.001
Epoch:56 [30/412], Loss: -0.057
Epoch:56 [40/412], Loss: 0.087
Epoch:56 [50/412], Loss: 0.124
Epoch:56 [60/412], Loss: -0.085
Epoch:56 [70/412], Loss: -0.058
Epoch:56 [80/412], Loss: -0.052
Epoch:56 [90/412], Loss: -0.029
Epoch:56 [100/412], Loss: -0.028
Epoch:56 [110/412], Loss: -0.049
Epoch:56 [120/412], Loss: -0.019
Epoch:56 [130/412], Loss: 0.010
Epoch:56 [140/412], Loss: 0.151
Epoch:56 [150/412], Loss: -0.056
Epoch:56 [160/412], Loss: -0.046
Epoch:56 [170/412], Loss: 0.043
Epoch:56 [180/412], Loss: 0.089
Epoch:56 [190/412], Loss: -0.035
Epoch:56 [200/412], Loss: -0.003
Epoch:56 [210/412], Loss: -0.045
Epoch:56 [220/412], Loss: -0.020
Epoch:56 [230/412], Loss: 0.010
Epoch:56 [240/412], Loss: -0.027
Epoch:56 [250/412], Loss: -0.047
Epoch:56 [260/412], Loss: 0.022
Epoch:56 [270/412], Loss: -0.048
Epoch:56 [280/412], Loss: 0.023
Epoch:56 [290/412], Loss: -0.026
Epoch:56 [300/412], Loss: -0.020
Epoch:56 [310/412], Loss: -0.038
Epoch:56 [320/412], Loss: 0.008
Epoch:56 [330/412], Loss: -0.033
Epoch:56 [340/412], Loss: -0.000
Epoch:56 [350/412], Loss: -0.040
Epoch:56 [360/412], Loss: 0.009
Epoch:56 [370/412], Loss: -0.004
Epoch:56 [380/412], Loss: -0.105
Epoch:56 [390/412], Loss: 0.040
Epoch:56 [400/412], Loss: -0.014
Epoch:56 [410/412], Loss: 0.059
Epoch:56, Train IoU: [0.99397962 0.95804136 0.95732779]
Epoch:56, Valid Loss: -0.013, mIoU: 0.9722463578949423
Validation metric decreased (0.000815 --> -0.013202).  Saving model ...
Epoch:57 [0/412], Loss: -0.128
Epoch:57 [10/412], Loss: -0.010
Epoch:57 [20/412], Loss: 0.026
Epoch:57 [30/412], Loss: -0.078
Epoch:57 [40/412], Loss: -0.047
Epoch:57 [50/412], Loss: -0.045
Epoch:57 [60/412], Loss: 0.021
Epoch:57 [70/412], Loss: -0.005
Epoch:57 [80/412], Loss: -0.010
Epoch:57 [90/412], Loss: 0.007
Epoch:57 [100/412], Loss: -0.031
Epoch:57 [110/412], Loss: -0.005
Epoch:57 [120/412], Loss: -0.077
Epoch:57 [130/412], Loss: -0.070
Epoch:57 [140/412], Loss: 0.034
Epoch:57 [150/412], Loss: 0.017
Epoch:57 [160/412], Loss: -0.000
Epoch:57 [170/412], Loss: -0.051
Epoch:57 [180/412], Loss: -0.009
Epoch:57 [190/412], Loss: -0.055
Epoch:57 [200/412], Loss: -0.006
Epoch:57 [210/412], Loss: 0.040
Epoch:57 [220/412], Loss: 0.116
Epoch:57 [230/412], Loss: 0.093
Epoch:57 [240/412], Loss: -0.064
Epoch:57 [250/412], Loss: -0.002
Epoch:57 [260/412], Loss: -0.023
Epoch:57 [270/412], Loss: -0.017
Epoch:57 [280/412], Loss: -0.045
Epoch:57 [290/412], Loss: -0.027
Epoch:57 [300/412], Loss: 0.021
Epoch:57 [310/412], Loss: -0.041
Epoch:57 [320/412], Loss: 0.146
Epoch:57 [330/412], Loss: -0.056
Epoch:57 [340/412], Loss: 0.030
Epoch:57 [350/412], Loss: -0.017
Epoch:57 [360/412], Loss: -0.018
Epoch:57 [370/412], Loss: 0.030
Epoch:57 [380/412], Loss: 0.013
Epoch:57 [390/412], Loss: -0.055
Epoch:57 [400/412], Loss: -0.062
Epoch:57 [410/412], Loss: 0.066
Epoch:57, Train IoU: [0.99398995 0.95794725 0.95725884]
Epoch:57, Valid Loss: -0.032, mIoU: 0.9736485947559629
Validation metric decreased (-0.013202 --> -0.031903).  Saving model ...
Epoch:58 [0/412], Loss: -0.037
Epoch:58 [10/412], Loss: 0.049
Epoch:58 [20/412], Loss: 0.066
Epoch:58 [30/412], Loss: -0.046
Epoch:58 [40/412], Loss: -0.047
Epoch:58 [50/412], Loss: -0.018
Epoch:58 [60/412], Loss: -0.036
Epoch:58 [70/412], Loss: 0.003
Epoch:58 [80/412], Loss: -0.103
Epoch:58 [90/412], Loss: -0.015
Epoch:58 [100/412], Loss: -0.100
Epoch:58 [110/412], Loss: -0.043
Epoch:58 [120/412], Loss: 0.033
Epoch:58 [130/412], Loss: -0.043
Epoch:58 [140/412], Loss: 0.015
Epoch:58 [150/412], Loss: 0.049
Epoch:58 [160/412], Loss: 0.033
Epoch:58 [170/412], Loss: -0.074
Epoch:58 [180/412], Loss: 0.027
Epoch:58 [190/412], Loss: 0.008
Epoch:58 [200/412], Loss: 0.020
Epoch:58 [210/412], Loss: -0.098
Epoch:58 [220/412], Loss: 0.033
Epoch:58 [230/412], Loss: -0.079
Epoch:58 [240/412], Loss: -0.057
Epoch:58 [250/412], Loss: -0.074
Epoch:58 [260/412], Loss: -0.001
Epoch:58 [270/412], Loss: -0.099
Epoch:58 [280/412], Loss: -0.016
Epoch:58 [290/412], Loss: -0.059
Epoch:58 [300/412], Loss: -0.096
Epoch:58 [310/412], Loss: -0.049
Epoch:58 [320/412], Loss: 0.021
Epoch:58 [330/412], Loss: 0.000
Epoch:58 [340/412], Loss: 0.041
Epoch:58 [350/412], Loss: -0.036
Epoch:58 [360/412], Loss: 0.014
Epoch:58 [370/412], Loss: -0.023
Epoch:58 [380/412], Loss: 0.030
Epoch:58 [390/412], Loss: -0.093
Epoch:58 [400/412], Loss: -0.074
Epoch:58 [410/412], Loss: 0.003
Epoch:58, Train IoU: [0.99395036 0.95773042 0.95772054]
Epoch:58, Valid Loss: -0.029, mIoU: 0.9726155006136378
Validation metric decreased (-0.031903 --> -0.028867).  Saving model ...
Epoch:59 [0/412], Loss: -0.065
Epoch:59 [10/412], Loss: -0.096
Epoch:59 [20/412], Loss: 0.002
Epoch:59 [30/412], Loss: -0.122
Epoch:59 [40/412], Loss: -0.082
Epoch:59 [50/412], Loss: -0.002
Epoch:59 [60/412], Loss: -0.072
Epoch:59 [70/412], Loss: -0.031
Epoch:59 [80/412], Loss: -0.034
Epoch:59 [90/412], Loss: -0.045
Epoch:59 [100/412], Loss: -0.057
Epoch:59 [110/412], Loss: -0.035
Epoch:59 [120/412], Loss: -0.043
Epoch:59 [130/412], Loss: 0.012
Epoch:59 [140/412], Loss: -0.101
Epoch:59 [150/412], Loss: -0.067
Epoch:59 [160/412], Loss: -0.052
Epoch:59 [170/412], Loss: -0.031
Epoch:59 [180/412], Loss: -0.073
Epoch:59 [190/412], Loss: 0.007
Epoch:59 [200/412], Loss: 0.071
Epoch:59 [210/412], Loss: 0.051
Epoch:59 [220/412], Loss: 0.009
Epoch:59 [230/412], Loss: -0.067
Epoch:59 [240/412], Loss: -0.021
Epoch:59 [250/412], Loss: 0.071
Epoch:59 [260/412], Loss: 0.012
Epoch:59 [270/412], Loss: -0.025
Epoch:59 [280/412], Loss: 0.089
Epoch:59 [290/412], Loss: -0.111
Epoch:59 [300/412], Loss: 0.137
Epoch:59 [310/412], Loss: -0.066
Epoch:59 [320/412], Loss: -0.001
Epoch:59 [330/412], Loss: -0.066
Epoch:59 [340/412], Loss: 0.013
Epoch:59 [350/412], Loss: -0.026
Epoch:59 [360/412], Loss: -0.068
Epoch:59 [370/412], Loss: -0.020
Epoch:59 [380/412], Loss: -0.000
Epoch:59 [390/412], Loss: -0.044
Epoch:59 [400/412], Loss: -0.005
Epoch:59 [410/412], Loss: -0.084
Epoch:59, Train IoU: [0.99407053 0.95881491 0.95794653]
Epoch:59, Valid Loss: -0.047, mIoU: 0.972836728041769
Validation metric decreased (-0.028867 --> -0.046938).  Saving model ...
Epoch:60 [0/412], Loss: -0.138
Epoch:60 [10/412], Loss: -0.027
Epoch:60 [20/412], Loss: -0.062
Epoch:60 [30/412], Loss: -0.101
Epoch:60 [40/412], Loss: -0.009
Epoch:60 [50/412], Loss: -0.060
Epoch:60 [60/412], Loss: -0.068
Epoch:60 [70/412], Loss: -0.138
Epoch:60 [80/412], Loss: -0.116
Epoch:60 [90/412], Loss: -0.074
Epoch:60 [100/412], Loss: 0.004
Epoch:60 [110/412], Loss: -0.051
Epoch:60 [120/412], Loss: 0.018
Epoch:60 [130/412], Loss: -0.006
Epoch:60 [140/412], Loss: -0.052
Epoch:60 [150/412], Loss: -0.125
Epoch:60 [160/412], Loss: 0.009
Epoch:60 [170/412], Loss: -0.067
Epoch:60 [180/412], Loss: -0.010
Epoch:60 [190/412], Loss: 0.066
Epoch:60 [200/412], Loss: -0.029
Epoch:60 [210/412], Loss: -0.077
Epoch:60 [220/412], Loss: 0.003
Epoch:60 [230/412], Loss: -0.031
Epoch:60 [240/412], Loss: -0.109
Epoch:60 [250/412], Loss: -0.092
Epoch:60 [260/412], Loss: -0.058
Epoch:60 [270/412], Loss: -0.076
Epoch:60 [280/412], Loss: 0.013
Epoch:60 [290/412], Loss: -0.084
Epoch:60 [300/412], Loss: -0.117
Epoch:60 [310/412], Loss: -0.079
Epoch:60 [320/412], Loss: -0.050
Epoch:60 [330/412], Loss: -0.074
Epoch:60 [340/412], Loss: 0.136
Epoch:60 [350/412], Loss: -0.024
Epoch:60 [360/412], Loss: -0.025
Epoch:60 [370/412], Loss: 0.066
Epoch:60 [380/412], Loss: 0.086
Epoch:60 [390/412], Loss: 0.040
Epoch:60 [400/412], Loss: 0.081
Epoch:60 [410/412], Loss: -0.054
Epoch:60, Train IoU: [0.99393938 0.95754104 0.95720286]
Epoch:60, Valid Loss: -0.019, mIoU: 0.9708392158814356
EarlyStopping counter: 1 out of 100
Epoch:61 [0/412], Loss: -0.076
Epoch:61 [10/412], Loss: 0.009
Epoch:61 [20/412], Loss: 0.018
Epoch:61 [30/412], Loss: 0.005
Epoch:61 [40/412], Loss: -0.023
Epoch:61 [50/412], Loss: -0.122
Epoch:61 [60/412], Loss: -0.060
Epoch:61 [70/412], Loss: -0.067
Epoch:61 [80/412], Loss: -0.011
Epoch:61 [90/412], Loss: 0.054
Epoch:61 [100/412], Loss: -0.142
Epoch:61 [110/412], Loss: -0.057
Epoch:61 [120/412], Loss: -0.025
Epoch:61 [130/412], Loss: -0.034
Epoch:61 [140/412], Loss: -0.095
Epoch:61 [150/412], Loss: -0.021
Epoch:61 [160/412], Loss: 0.000
Epoch:61 [170/412], Loss: -0.061
Epoch:61 [180/412], Loss: -0.091
Epoch:61 [190/412], Loss: -0.076
Epoch:61 [200/412], Loss: 0.013
Epoch:61 [210/412], Loss: -0.065
Epoch:61 [220/412], Loss: -0.037
Epoch:61 [230/412], Loss: -0.005
Epoch:61 [240/412], Loss: 0.002
Epoch:61 [250/412], Loss: -0.086
Epoch:61 [260/412], Loss: -0.077
Epoch:61 [270/412], Loss: -0.038
Epoch:61 [280/412], Loss: -0.013
Epoch:61 [290/412], Loss: -0.077
Epoch:61 [300/412], Loss: -0.075
Epoch:61 [310/412], Loss: 0.038
Epoch:61 [320/412], Loss: -0.038
Epoch:61 [330/412], Loss: -0.027
Epoch:61 [340/412], Loss: -0.078
Epoch:61 [350/412], Loss: -0.038
Epoch:61 [360/412], Loss: -0.057
Epoch:61 [370/412], Loss: -0.095
Epoch:61 [380/412], Loss: -0.037
Epoch:61 [390/412], Loss: -0.053
Epoch:61 [400/412], Loss: -0.026
Epoch:61 [410/412], Loss: -0.024
Epoch:61, Train IoU: [0.99398573 0.95802091 0.9571439 ]
Epoch:61, Valid Loss: -0.049, mIoU: 0.9728886519392326
Validation metric decreased (-0.046938 --> -0.048668).  Saving model ...
Epoch:62 [0/412], Loss: -0.107
Epoch:62 [10/412], Loss: -0.103
Epoch:62 [20/412], Loss: 0.037
Epoch:62 [30/412], Loss: -0.045
Epoch:62 [40/412], Loss: 0.060
Epoch:62 [50/412], Loss: -0.014
Epoch:62 [60/412], Loss: -0.068
Epoch:62 [70/412], Loss: 0.208
Epoch:62 [80/412], Loss: -0.068
Epoch:62 [90/412], Loss: -0.008
Epoch:62 [100/412], Loss: -0.100
Epoch:62 [110/412], Loss: -0.081
Epoch:62 [120/412], Loss: -0.122
Epoch:62 [130/412], Loss: -0.109
Epoch:62 [140/412], Loss: -0.030
Epoch:62 [150/412], Loss: -0.079
Epoch:62 [160/412], Loss: -0.088
Epoch:62 [170/412], Loss: 0.005
Epoch:62 [180/412], Loss: -0.042
Epoch:62 [190/412], Loss: -0.067
Epoch:62 [200/412], Loss: -0.062
Epoch:62 [210/412], Loss: -0.032
Epoch:62 [220/412], Loss: -0.019
Epoch:62 [230/412], Loss: 0.010
Epoch:62 [240/412], Loss: -0.062
Epoch:62 [250/412], Loss: -0.088
Epoch:62 [260/412], Loss: 0.043
Epoch:62 [270/412], Loss: -0.039
Epoch:62 [280/412], Loss: -0.078
Epoch:62 [290/412], Loss: -0.053
Epoch:62 [300/412], Loss: -0.034
Epoch:62 [310/412], Loss: -0.082
Epoch:62 [320/412], Loss: -0.123
Epoch:62 [330/412], Loss: -0.018
Epoch:62 [340/412], Loss: -0.082
Epoch:62 [350/412], Loss: -0.008
Epoch:62 [360/412], Loss: -0.060
Epoch:62 [370/412], Loss: -0.130
Epoch:62 [380/412], Loss: 0.006
Epoch:62 [390/412], Loss: -0.025
Epoch:62 [400/412], Loss: -0.056
Epoch:62 [410/412], Loss: 0.008
Epoch:62, Train IoU: [0.99405805 0.95868024 0.95818391]
Epoch:62, Valid Loss: -0.057, mIoU: 0.9723568045815969
Validation metric decreased (-0.048668 --> -0.056591).  Saving model ...
Epoch:63 [0/412], Loss: -0.111
Epoch:63 [10/412], Loss: -0.077
Epoch:63 [20/412], Loss: -0.189
Epoch:63 [30/412], Loss: -0.085
Epoch:63 [40/412], Loss: -0.014
Epoch:63 [50/412], Loss: -0.103
Epoch:63 [60/412], Loss: -0.103
Epoch:63 [70/412], Loss: -0.063
Epoch:63 [80/412], Loss: -0.061
Epoch:63 [90/412], Loss: -0.085
Epoch:63 [100/412], Loss: -0.113
Epoch:63 [110/412], Loss: -0.079
Epoch:63 [120/412], Loss: -0.018
Epoch:63 [130/412], Loss: -0.130
Epoch:63 [140/412], Loss: -0.005
Epoch:63 [150/412], Loss: -0.007
Epoch:63 [160/412], Loss: 0.023
Epoch:63 [170/412], Loss: 0.011
Epoch:63 [180/412], Loss: -0.133
Epoch:63 [190/412], Loss: -0.090
Epoch:63 [200/412], Loss: -0.004
Epoch:63 [210/412], Loss: -0.056
Epoch:63 [220/412], Loss: -0.125
Epoch:63 [230/412], Loss: 0.049
Epoch:63 [240/412], Loss: -0.070
Epoch:63 [250/412], Loss: 0.053
Epoch:63 [260/412], Loss: -0.086
Epoch:63 [270/412], Loss: -0.185
Epoch:63 [280/412], Loss: -0.078
Epoch:63 [290/412], Loss: -0.051
Epoch:63 [300/412], Loss: -0.021
Epoch:63 [310/412], Loss: -0.125
Epoch:63 [320/412], Loss: -0.116
Epoch:63 [330/412], Loss: 0.023
Epoch:63 [340/412], Loss: -0.077
Epoch:63 [350/412], Loss: -0.133
Epoch:63 [360/412], Loss: -0.060
Epoch:63 [370/412], Loss: -0.124
Epoch:63 [380/412], Loss: -0.048
Epoch:63 [390/412], Loss: -0.050
Epoch:63 [400/412], Loss: -0.032
Epoch:63 [410/412], Loss: 0.006
Epoch:63, Train IoU: [0.99412548 0.95930797 0.95780387]
Epoch:63, Valid Loss: -0.071, mIoU: 0.9730250406660031
Validation metric decreased (-0.056591 --> -0.070752).  Saving model ...
Epoch:64 [0/412], Loss: -0.075
Epoch:64 [10/412], Loss: -0.014
Epoch:64 [20/412], Loss: -0.091
Epoch:64 [30/412], Loss: -0.125
Epoch:64 [40/412], Loss: -0.023
Epoch:64 [50/412], Loss: 0.012
Epoch:64 [60/412], Loss: -0.039
Epoch:64 [70/412], Loss: -0.111
Epoch:64 [80/412], Loss: -0.058
Epoch:64 [90/412], Loss: -0.128
Epoch:64 [100/412], Loss: -0.105
Epoch:64 [110/412], Loss: -0.045
Epoch:64 [120/412], Loss: -0.091
Epoch:64 [130/412], Loss: -0.010
Epoch:64 [140/412], Loss: -0.059
Epoch:64 [150/412], Loss: 0.148
Epoch:64 [160/412], Loss: -0.087
Epoch:64 [170/412], Loss: -0.106
Epoch:64 [180/412], Loss: -0.136
Epoch:64 [190/412], Loss: -0.048
Epoch:64 [200/412], Loss: -0.020
Epoch:64 [210/412], Loss: -0.056
Epoch:64 [220/412], Loss: -0.068
Epoch:64 [230/412], Loss: -0.063
Epoch:64 [240/412], Loss: -0.034
Epoch:64 [250/412], Loss: -0.132
Epoch:64 [260/412], Loss: -0.139
Epoch:64 [270/412], Loss: -0.071
Epoch:64 [280/412], Loss: -0.012
Epoch:64 [290/412], Loss: -0.020
Epoch:64 [300/412], Loss: -0.018
Epoch:64 [310/412], Loss: -0.029
Epoch:64 [320/412], Loss: -0.129
Epoch:64 [330/412], Loss: -0.081
Epoch:64 [340/412], Loss: -0.123
Epoch:64 [350/412], Loss: 0.085
Epoch:64 [360/412], Loss: -0.086
Epoch:64 [370/412], Loss: -0.106
Epoch:64 [380/412], Loss: -0.138
Epoch:64 [390/412], Loss: -0.104
Epoch:64 [400/412], Loss: -0.104
Epoch:64 [410/412], Loss: -0.104
Epoch:64, Train IoU: [0.99417659 0.95977956 0.95854452]
Epoch:64, Valid Loss: -0.089, mIoU: 0.9739802736965432
Validation metric decreased (-0.070752 --> -0.088902).  Saving model ...
Epoch:65 [0/412], Loss: -0.151
Epoch:65 [10/412], Loss: -0.134
Epoch:65 [20/412], Loss: -0.102
Epoch:65 [30/412], Loss: -0.135
Epoch:65 [40/412], Loss: -0.089
Epoch:65 [50/412], Loss: -0.085
Epoch:65 [60/412], Loss: -0.167
Epoch:65 [70/412], Loss: -0.184
Epoch:65 [80/412], Loss: -0.142
Epoch:65 [90/412], Loss: -0.102
Epoch:65 [100/412], Loss: -0.102
Epoch:65 [110/412], Loss: -0.067
Epoch:65 [120/412], Loss: -0.164
Epoch:65 [130/412], Loss: -0.162
Epoch:65 [140/412], Loss: -0.040
Epoch:65 [150/412], Loss: -0.029
Epoch:65 [160/412], Loss: -0.027
Epoch:65 [170/412], Loss: -0.086
Epoch:65 [180/412], Loss: -0.117
Epoch:65 [190/412], Loss: -0.042
Epoch:65 [200/412], Loss: -0.105
Epoch:65 [210/412], Loss: -0.063
Epoch:65 [220/412], Loss: -0.091
Epoch:65 [230/412], Loss: -0.083
Epoch:65 [240/412], Loss: -0.155
Epoch:65 [250/412], Loss: -0.024
Epoch:65 [260/412], Loss: -0.059
Epoch:65 [270/412], Loss: -0.075
Epoch:65 [280/412], Loss: -0.066
Epoch:65 [290/412], Loss: -0.112
Epoch:65 [300/412], Loss: -0.078
Epoch:65 [310/412], Loss: -0.135
Epoch:65 [320/412], Loss: -0.132
Epoch:65 [330/412], Loss: -0.046
Epoch:65 [340/412], Loss: -0.116
Epoch:65 [350/412], Loss: -0.089
Epoch:65 [360/412], Loss: -0.061
Epoch:65 [370/412], Loss: -0.097
Epoch:65 [380/412], Loss: -0.058
Epoch:65 [390/412], Loss: -0.111
Epoch:65 [400/412], Loss: -0.090
Epoch:65 [410/412], Loss: -0.155
Epoch:65, Train IoU: [0.99422516 0.96052438 0.95956266]
Epoch:65, Valid Loss: -0.092, mIoU: 0.9741900234892552
Validation metric decreased (-0.088902 --> -0.091600).  Saving model ...
Epoch:66 [0/412], Loss: -0.062
Epoch:66 [10/412], Loss: -0.126
Epoch:66 [20/412], Loss: -0.106
Epoch:66 [30/412], Loss: -0.068
Epoch:66 [40/412], Loss: -0.083
Epoch:66 [50/412], Loss: -0.062
Epoch:66 [60/412], Loss: -0.085
Epoch:66 [70/412], Loss: -0.126
Epoch:66 [80/412], Loss: -0.094
Epoch:66 [90/412], Loss: -0.070
Epoch:66 [100/412], Loss: -0.116
Epoch:66 [110/412], Loss: -0.005
Epoch:66 [120/412], Loss: -0.084
Epoch:66 [130/412], Loss: -0.112
Epoch:66 [140/412], Loss: -0.098
Epoch:66 [150/412], Loss: -0.110
Epoch:66 [160/412], Loss: -0.086
Epoch:66 [170/412], Loss: -0.096
Epoch:66 [180/412], Loss: -0.151
Epoch:66 [190/412], Loss: -0.023
Epoch:66 [200/412], Loss: -0.083
Epoch:66 [210/412], Loss: -0.095
Epoch:66 [220/412], Loss: -0.152
Epoch:66 [230/412], Loss: -0.056
Epoch:66 [240/412], Loss: -0.058
Epoch:66 [250/412], Loss: -0.074
Epoch:66 [260/412], Loss: -0.125
Epoch:66 [270/412], Loss: -0.079
Epoch:66 [280/412], Loss: -0.017
Epoch:66 [290/412], Loss: -0.088
Epoch:66 [300/412], Loss: -0.069
Epoch:66 [310/412], Loss: -0.154
Epoch:66 [320/412], Loss: -0.137
Epoch:66 [330/412], Loss: -0.083
Epoch:66 [340/412], Loss: -0.060
Epoch:66 [350/412], Loss: -0.107
Epoch:66 [360/412], Loss: 0.056
Epoch:66 [370/412], Loss: -0.118
Epoch:66 [380/412], Loss: 0.014
Epoch:66 [390/412], Loss: -0.059
Epoch:66 [400/412], Loss: -0.112
Epoch:66 [410/412], Loss: -0.071
Epoch:66, Train IoU: [0.99420503 0.96016934 0.95906115]
Epoch:66, Valid Loss: -0.103, mIoU: 0.9742679087908986
Validation metric decreased (-0.091600 --> -0.102646).  Saving model ...
Epoch:67 [0/412], Loss: -0.097
Epoch:67 [10/412], Loss: -0.145
Epoch:67 [20/412], Loss: -0.164
Epoch:67 [30/412], Loss: -0.169
Epoch:67 [40/412], Loss: -0.177
Epoch:67 [50/412], Loss: -0.007
Epoch:67 [60/412], Loss: -0.093
Epoch:67 [70/412], Loss: -0.112
Epoch:67 [80/412], Loss: -0.076
Epoch:67 [90/412], Loss: -0.070
Epoch:67 [100/412], Loss: -0.060
Epoch:67 [110/412], Loss: -0.215
Epoch:67 [120/412], Loss: -0.139
Epoch:67 [130/412], Loss: -0.117
Epoch:67 [140/412], Loss: -0.062
Epoch:67 [150/412], Loss: -0.144
Epoch:67 [160/412], Loss: -0.123
Epoch:67 [170/412], Loss: 0.009
Epoch:67 [180/412], Loss: -0.107
Epoch:67 [190/412], Loss: -0.154
Epoch:67 [200/412], Loss: -0.132
Epoch:67 [210/412], Loss: -0.129
Epoch:67 [220/412], Loss: -0.041
Epoch:67 [230/412], Loss: -0.101
Epoch:67 [240/412], Loss: -0.109
Epoch:67 [250/412], Loss: -0.058
Epoch:67 [260/412], Loss: -0.167
Epoch:67 [270/412], Loss: -0.137
Epoch:67 [280/412], Loss: -0.070
Epoch:67 [290/412], Loss: -0.153
Epoch:67 [300/412], Loss: -0.110
Epoch:67 [310/412], Loss: -0.038
Epoch:67 [320/412], Loss: -0.095
Epoch:67 [330/412], Loss: -0.121
Epoch:67 [340/412], Loss: -0.082
Epoch:67 [350/412], Loss: -0.051
Epoch:67 [360/412], Loss: -0.132
Epoch:67 [370/412], Loss: -0.110
Epoch:67 [380/412], Loss: -0.101
Epoch:67 [390/412], Loss: -0.067
Epoch:67 [400/412], Loss: -0.099
Epoch:67 [410/412], Loss: -0.068
Epoch:67, Train IoU: [0.99431068 0.96103879 0.9596797 ]
Epoch:67, Valid Loss: -0.100, mIoU: 0.9721520670755678
Validation metric decreased (-0.102646 --> -0.099623).  Saving model ...
Epoch:68 [0/412], Loss: -0.134
Epoch:68 [10/412], Loss: -0.062
Epoch:68 [20/412], Loss: -0.145
Epoch:68 [30/412], Loss: -0.150
Epoch:68 [40/412], Loss: -0.060
Epoch:68 [50/412], Loss: -0.130
Epoch:68 [60/412], Loss: -0.189
Epoch:68 [70/412], Loss: -0.121
Epoch:68 [80/412], Loss: -0.170
Epoch:68 [90/412], Loss: -0.018
Epoch:68 [100/412], Loss: -0.108
Epoch:68 [110/412], Loss: -0.032
Epoch:68 [120/412], Loss: -0.084
Epoch:68 [130/412], Loss: -0.115
Epoch:68 [140/412], Loss: -0.149
Epoch:68 [150/412], Loss: -0.062
Epoch:68 [160/412], Loss: -0.148
Epoch:68 [170/412], Loss: -0.137
Epoch:68 [180/412], Loss: -0.086
Epoch:68 [190/412], Loss: -0.180
Epoch:68 [200/412], Loss: -0.126
Epoch:68 [210/412], Loss: -0.091
Epoch:68 [220/412], Loss: -0.132
Epoch:68 [230/412], Loss: -0.043
Epoch:68 [240/412], Loss: -0.085
Epoch:68 [250/412], Loss: -0.135
Epoch:68 [260/412], Loss: -0.107
Epoch:68 [270/412], Loss: -0.126
Epoch:68 [280/412], Loss: -0.105
Epoch:68 [290/412], Loss: -0.150
Epoch:68 [300/412], Loss: -0.117
Epoch:68 [310/412], Loss: -0.134
Epoch:68 [320/412], Loss: -0.049
Epoch:68 [330/412], Loss: -0.077
Epoch:68 [340/412], Loss: -0.075
Epoch:68 [350/412], Loss: -0.131
Epoch:68 [360/412], Loss: -0.101
Epoch:68 [370/412], Loss: -0.133
Epoch:68 [380/412], Loss: -0.157
Epoch:68 [390/412], Loss: -0.093
Epoch:68 [400/412], Loss: -0.142
Epoch:68 [410/412], Loss: -0.121
Epoch:68, Train IoU: [0.99438826 0.96158355 0.96044475]
Epoch:68, Valid Loss: -0.125, mIoU: 0.9742632144814638
Validation metric decreased (-0.099623 --> -0.124658).  Saving model ...
Epoch:69 [0/412], Loss: -0.113
Epoch:69 [10/412], Loss: -0.180
Epoch:69 [20/412], Loss: -0.123
Epoch:69 [30/412], Loss: -0.097
Epoch:69 [40/412], Loss: -0.089
Epoch:69 [50/412], Loss: -0.139
Epoch:69 [60/412], Loss: -0.181
Epoch:69 [70/412], Loss: -0.138
Epoch:69 [80/412], Loss: -0.068
Epoch:69 [90/412], Loss: -0.100
Epoch:69 [100/412], Loss: -0.119
Epoch:69 [110/412], Loss: -0.123
Epoch:69 [120/412], Loss: -0.063
Epoch:69 [130/412], Loss: -0.136
Epoch:69 [140/412], Loss: -0.130
Epoch:69 [150/412], Loss: -0.042
Epoch:69 [160/412], Loss: -0.108
Epoch:69 [170/412], Loss: -0.062
Epoch:69 [180/412], Loss: -0.114
Epoch:69 [190/412], Loss: -0.103
Epoch:69 [200/412], Loss: -0.129
Epoch:69 [210/412], Loss: -0.151
Epoch:69 [220/412], Loss: -0.108
Epoch:69 [230/412], Loss: -0.112
Epoch:69 [240/412], Loss: -0.054
Epoch:69 [250/412], Loss: -0.074
Epoch:69 [260/412], Loss: -0.111
Epoch:69 [270/412], Loss: -0.131
Epoch:69 [280/412], Loss: -0.158
Epoch:69 [290/412], Loss: -0.112
Epoch:69 [300/412], Loss: -0.085
Epoch:69 [310/412], Loss: -0.046
Epoch:69 [320/412], Loss: -0.115
Epoch:69 [330/412], Loss: -0.105
Epoch:69 [340/412], Loss: -0.096
Epoch:69 [350/412], Loss: -0.141
Epoch:69 [360/412], Loss: -0.153
Epoch:69 [370/412], Loss: -0.109
Epoch:69 [380/412], Loss: -0.099
Epoch:69 [390/412], Loss: -0.157
Epoch:69 [400/412], Loss: -0.131
Epoch:69 [410/412], Loss: -0.111
Epoch:69, Train IoU: [0.99429964 0.96092591 0.95968392]
Epoch:69, Valid Loss: -0.116, mIoU: 0.9725697997995931
Validation metric decreased (-0.124658 --> -0.115917).  Saving model ...
Epoch:70 [0/412], Loss: -0.133
Epoch:70 [10/412], Loss: -0.140
Epoch:70 [20/412], Loss: -0.177
Epoch:70 [30/412], Loss: -0.144
Epoch:70 [40/412], Loss: -0.149
Epoch:70 [50/412], Loss: -0.135
Epoch:70 [60/412], Loss: 0.058
Epoch:70 [70/412], Loss: -0.060
Epoch:70 [80/412], Loss: -0.104
Epoch:70 [90/412], Loss: -0.084
Epoch:70 [100/412], Loss: -0.213
Epoch:70 [110/412], Loss: -0.106
Epoch:70 [120/412], Loss: -0.173
Epoch:70 [130/412], Loss: -0.105
Epoch:70 [140/412], Loss: -0.137
Epoch:70 [150/412], Loss: -0.055
Epoch:70 [160/412], Loss: -0.110
Epoch:70 [170/412], Loss: -0.123
Epoch:70 [180/412], Loss: -0.127
Epoch:70 [190/412], Loss: -0.082
Epoch:70 [200/412], Loss: -0.101
Epoch:70 [210/412], Loss: -0.204
Epoch:70 [220/412], Loss: -0.112
Epoch:70 [230/412], Loss: -0.194
Epoch:70 [240/412], Loss: -0.150
Epoch:70 [250/412], Loss: -0.171
Epoch:70 [260/412], Loss: -0.173
Epoch:70 [270/412], Loss: 0.028
Epoch:70 [280/412], Loss: -0.149
Epoch:70 [290/412], Loss: -0.005
Epoch:70 [300/412], Loss: -0.030
Epoch:70 [310/412], Loss: -0.089
Epoch:70 [320/412], Loss: -0.086
Epoch:70 [330/412], Loss: -0.082
Epoch:70 [340/412], Loss: -0.080
Epoch:70 [350/412], Loss: -0.072
Epoch:70 [360/412], Loss: -0.169
Epoch:70 [370/412], Loss: -0.115
Epoch:70 [380/412], Loss: -0.100
Epoch:70 [390/412], Loss: -0.132
Epoch:70 [400/412], Loss: -0.120
Epoch:70 [410/412], Loss: -0.093
Epoch:70, Train IoU: [0.99419352 0.96001051 0.95940167]
Epoch:70, Valid Loss: -0.130, mIoU: 0.9737740371726945
Validation metric decreased (-0.115917 --> -0.130475).  Saving model ...
Epoch:71 [0/412], Loss: -0.129
Epoch:71 [10/412], Loss: -0.116
Epoch:71 [20/412], Loss: -0.185
Epoch:71 [30/412], Loss: 0.004
Epoch:71 [40/412], Loss: -0.123
Epoch:71 [50/412], Loss: -0.182
Epoch:71 [60/412], Loss: -0.065
Epoch:71 [70/412], Loss: -0.097
Epoch:71 [80/412], Loss: -0.124
Epoch:71 [90/412], Loss: -0.076
Epoch:71 [100/412], Loss: -0.142
Epoch:71 [110/412], Loss: -0.146
Epoch:71 [120/412], Loss: -0.158
Epoch:71 [130/412], Loss: -0.139
Epoch:71 [140/412], Loss: -0.126
Epoch:71 [150/412], Loss: -0.167
Epoch:71 [160/412], Loss: -0.074
Epoch:71 [170/412], Loss: -0.124
Epoch:71 [180/412], Loss: -0.197
Epoch:71 [190/412], Loss: -0.136
Epoch:71 [200/412], Loss: -0.180
Epoch:71 [210/412], Loss: -0.192
Epoch:71 [220/412], Loss: -0.082
Epoch:71 [230/412], Loss: -0.180
Epoch:71 [240/412], Loss: -0.248
Epoch:71 [250/412], Loss: -0.130
Epoch:71 [260/412], Loss: -0.208
Epoch:71 [270/412], Loss: -0.117
Epoch:71 [280/412], Loss: -0.138
Epoch:71 [290/412], Loss: -0.137
Epoch:71 [300/412], Loss: -0.128
Epoch:71 [310/412], Loss: -0.149
Epoch:71 [320/412], Loss: -0.118
Epoch:71 [330/412], Loss: -0.160
Epoch:71 [340/412], Loss: -0.188
Epoch:71 [350/412], Loss: -0.158
Epoch:71 [360/412], Loss: -0.158
Epoch:71 [370/412], Loss: -0.107
Epoch:71 [380/412], Loss: -0.064
Epoch:71 [390/412], Loss: -0.151
Epoch:71 [400/412], Loss: -0.157
Epoch:71 [410/412], Loss: -0.110
Epoch:71, Train IoU: [0.99445696 0.96222381 0.96027574]
Epoch:71, Valid Loss: -0.141, mIoU: 0.9736936643776338
Validation metric decreased (-0.130475 --> -0.141319).  Saving model ...
Epoch:72 [0/412], Loss: -0.231
Epoch:72 [10/412], Loss: -0.152
Epoch:72 [20/412], Loss: -0.216
Epoch:72 [30/412], Loss: -0.184
Epoch:72 [40/412], Loss: -0.134
Epoch:72 [50/412], Loss: -0.168
Epoch:72 [60/412], Loss: -0.084
Epoch:72 [70/412], Loss: -0.159
Epoch:72 [80/412], Loss: -0.111
Epoch:72 [90/412], Loss: -0.096
Epoch:72 [100/412], Loss: -0.186
Epoch:72 [110/412], Loss: -0.152
Epoch:72 [120/412], Loss: -0.165
Epoch:72 [130/412], Loss: -0.172
Epoch:72 [140/412], Loss: -0.159
Epoch:72 [150/412], Loss: -0.121
Epoch:72 [160/412], Loss: -0.193
Epoch:72 [170/412], Loss: -0.121
Epoch:72 [180/412], Loss: -0.169
Epoch:72 [190/412], Loss: -0.152
Epoch:72 [200/412], Loss: -0.131
Epoch:72 [210/412], Loss: -0.184
Epoch:72 [220/412], Loss: -0.083
Epoch:72 [230/412], Loss: -0.159
Epoch:72 [240/412], Loss: -0.107
Epoch:72 [250/412], Loss: -0.141
Epoch:72 [260/412], Loss: -0.167
Epoch:72 [270/412], Loss: -0.103
Epoch:72 [280/412], Loss: -0.056
Epoch:72 [290/412], Loss: -0.124
Epoch:72 [300/412], Loss: -0.115
Epoch:72 [310/412], Loss: -0.048
Epoch:72 [320/412], Loss: -0.115
Epoch:72 [330/412], Loss: -0.087
Epoch:72 [340/412], Loss: -0.174
Epoch:72 [350/412], Loss: -0.100
Epoch:72 [360/412], Loss: -0.066
Epoch:72 [370/412], Loss: -0.121
Epoch:72 [380/412], Loss: -0.147
Epoch:72 [390/412], Loss: -0.130
Epoch:72 [400/412], Loss: -0.117
Epoch:72 [410/412], Loss: -0.072
Epoch:72, Train IoU: [0.99435441 0.96130031 0.96001098]
Epoch:72, Valid Loss: -0.142, mIoU: 0.9728974012899854
Validation metric decreased (-0.141319 --> -0.141800).  Saving model ...
Epoch:73 [0/412], Loss: -0.154
Epoch:73 [10/412], Loss: -0.124
Epoch:73 [20/412], Loss: -0.122
Epoch:73 [30/412], Loss: -0.120
Epoch:73 [40/412], Loss: -0.167
Epoch:73 [50/412], Loss: -0.239
Epoch:73 [60/412], Loss: -0.192
Epoch:73 [70/412], Loss: -0.206
Epoch:73 [80/412], Loss: -0.173
Epoch:73 [90/412], Loss: -0.156
Epoch:73 [100/412], Loss: -0.095
Epoch:73 [110/412], Loss: -0.131
Epoch:73 [120/412], Loss: -0.148
Epoch:73 [130/412], Loss: -0.216
Epoch:73 [140/412], Loss: -0.226
Epoch:73 [150/412], Loss: -0.118
Epoch:73 [160/412], Loss: -0.116
Epoch:73 [170/412], Loss: -0.153
Epoch:73 [180/412], Loss: -0.128
Epoch:73 [190/412], Loss: -0.147
Epoch:73 [200/412], Loss: -0.140
Epoch:73 [210/412], Loss: -0.206
Epoch:73 [220/412], Loss: -0.165
Epoch:73 [230/412], Loss: -0.153
Epoch:73 [240/412], Loss: -0.121
Epoch:73 [250/412], Loss: -0.146
Epoch:73 [260/412], Loss: -0.131
Epoch:73 [270/412], Loss: -0.195
Epoch:73 [280/412], Loss: -0.213
Epoch:73 [290/412], Loss: -0.122
Epoch:73 [300/412], Loss: -0.188
Epoch:73 [310/412], Loss: -0.230
Epoch:73 [320/412], Loss: -0.147
Epoch:73 [330/412], Loss: -0.131
Epoch:73 [340/412], Loss: -0.212
Epoch:73 [350/412], Loss: -0.121
Epoch:73 [360/412], Loss: -0.238
Epoch:73 [370/412], Loss: -0.162
Epoch:73 [380/412], Loss: 0.021
Epoch:73 [390/412], Loss: -0.204
Epoch:73 [400/412], Loss: -0.162
Epoch:73 [410/412], Loss: -0.146
Epoch:73, Train IoU: [0.99441047 0.96179114 0.96014443]
Epoch:73, Valid Loss: -0.139, mIoU: 0.971566593237953
Validation metric decreased (-0.141800 --> -0.138887).  Saving model ...
Epoch:74 [0/412], Loss: -0.144
Epoch:74 [10/412], Loss: -0.127
Epoch:74 [20/412], Loss: -0.153
Epoch:74 [30/412], Loss: -0.050
Epoch:74 [40/412], Loss: -0.168
Epoch:74 [50/412], Loss: -0.167
Epoch:74 [60/412], Loss: -0.215
Epoch:74 [70/412], Loss: -0.231
Epoch:74 [80/412], Loss: -0.152
Epoch:74 [90/412], Loss: -0.128
Epoch:74 [100/412], Loss: -0.140
Epoch:74 [110/412], Loss: -0.145
Epoch:74 [120/412], Loss: -0.215
Epoch:74 [130/412], Loss: -0.188
Epoch:74 [140/412], Loss: -0.197
Epoch:74 [150/412], Loss: -0.169
Epoch:74 [160/412], Loss: -0.180
Epoch:74 [170/412], Loss: -0.143
Epoch:74 [180/412], Loss: -0.142
Epoch:74 [190/412], Loss: -0.247
Epoch:74 [200/412], Loss: -0.165
Epoch:74 [210/412], Loss: -0.246
Epoch:74 [220/412], Loss: -0.172
Epoch:74 [230/412], Loss: -0.173
Epoch:74 [240/412], Loss: -0.172
Epoch:74 [250/412], Loss: -0.085
Epoch:74 [260/412], Loss: -0.097
Epoch:74 [270/412], Loss: -0.212
Epoch:74 [280/412], Loss: -0.207
Epoch:74 [290/412], Loss: -0.130
Epoch:74 [300/412], Loss: -0.216
Epoch:74 [310/412], Loss: -0.099
Epoch:74 [320/412], Loss: -0.120
Epoch:74 [330/412], Loss: -0.179
Epoch:74 [340/412], Loss: -0.128
Epoch:74 [350/412], Loss: -0.160
Epoch:74 [360/412], Loss: -0.180
Epoch:74 [370/412], Loss: -0.161
Epoch:74 [380/412], Loss: -0.232
Epoch:74 [390/412], Loss: -0.149
Epoch:74 [400/412], Loss: -0.187
Epoch:74 [410/412], Loss: -0.191
Epoch:74, Train IoU: [0.99436899 0.96123924 0.95992883]
Epoch:74, Valid Loss: -0.162, mIoU: 0.9732210763212078
Validation metric decreased (-0.138887 --> -0.162129).  Saving model ...
Epoch:75 [0/412], Loss: -0.133
Epoch:75 [10/412], Loss: -0.178
Epoch:75 [20/412], Loss: -0.131
Epoch:75 [30/412], Loss: -0.128
Epoch:75 [40/412], Loss: -0.204
Epoch:75 [50/412], Loss: -0.121
Epoch:75 [60/412], Loss: -0.222
Epoch:75 [70/412], Loss: -0.206
Epoch:75 [80/412], Loss: -0.132
Epoch:75 [90/412], Loss: -0.183
Epoch:75 [100/412], Loss: -0.168
Epoch:75 [110/412], Loss: -0.084
Epoch:75 [120/412], Loss: -0.167
Epoch:75 [130/412], Loss: -0.213
Epoch:75 [140/412], Loss: -0.185
Epoch:75 [150/412], Loss: -0.154
Epoch:75 [160/412], Loss: -0.185
Epoch:75 [170/412], Loss: -0.145
Epoch:75 [180/412], Loss: -0.201
Epoch:75 [190/412], Loss: -0.266
Epoch:75 [200/412], Loss: -0.127
Epoch:75 [210/412], Loss: -0.192
Epoch:75 [220/412], Loss: -0.163
Epoch:75 [230/412], Loss: -0.222
Epoch:75 [240/412], Loss: -0.213
Epoch:75 [250/412], Loss: -0.121
Epoch:75 [260/412], Loss: -0.164
Epoch:75 [270/412], Loss: -0.182
Epoch:75 [280/412], Loss: -0.243
Epoch:75 [290/412], Loss: -0.077
Epoch:75 [300/412], Loss: -0.252
Epoch:75 [310/412], Loss: -0.178
Epoch:75 [320/412], Loss: -0.159
Epoch:75 [330/412], Loss: -0.143
Epoch:75 [340/412], Loss: -0.193
Epoch:75 [350/412], Loss: -0.189
Epoch:75 [360/412], Loss: -0.195
Epoch:75 [370/412], Loss: -0.161
Epoch:75 [380/412], Loss: -0.065
Epoch:75 [390/412], Loss: -0.233
Epoch:75 [400/412], Loss: -0.110
Epoch:75 [410/412], Loss: -0.100
Epoch:75, Train IoU: [0.99443414 0.96199586 0.96079433]
Epoch:75, Valid Loss: -0.169, mIoU: 0.9735717250532065
Validation metric decreased (-0.162129 --> -0.168959).  Saving model ...
Epoch:76 [0/412], Loss: -0.200
Epoch:76 [10/412], Loss: -0.246
Epoch:76 [20/412], Loss: -0.228
Epoch:76 [30/412], Loss: -0.216
Epoch:76 [40/412], Loss: -0.169
Epoch:76 [50/412], Loss: -0.146
Epoch:76 [60/412], Loss: -0.214
Epoch:76 [70/412], Loss: -0.229
Epoch:76 [80/412], Loss: -0.227
Epoch:76 [90/412], Loss: -0.193
Epoch:76 [100/412], Loss: -0.154
Epoch:76 [110/412], Loss: -0.262
Epoch:76 [120/412], Loss: -0.223
Epoch:76 [130/412], Loss: -0.116
Epoch:76 [140/412], Loss: -0.192
Epoch:76 [150/412], Loss: -0.225
Epoch:76 [160/412], Loss: -0.285
Epoch:76 [170/412], Loss: -0.165
Epoch:76 [180/412], Loss: -0.221
Epoch:76 [190/412], Loss: -0.221
Epoch:76 [200/412], Loss: -0.224
Epoch:76 [210/412], Loss: -0.217
Epoch:76 [220/412], Loss: -0.244
Epoch:76 [230/412], Loss: -0.201
Epoch:76 [240/412], Loss: -0.139
Epoch:76 [250/412], Loss: -0.174
Epoch:76 [260/412], Loss: -0.189
Epoch:76 [270/412], Loss: -0.191
Epoch:76 [280/412], Loss: -0.250
Epoch:76 [290/412], Loss: -0.200
Epoch:76 [300/412], Loss: -0.130
Epoch:76 [310/412], Loss: -0.159
Epoch:76 [320/412], Loss: -0.163
Epoch:76 [330/412], Loss: -0.157
Epoch:76 [340/412], Loss: -0.173
Epoch:76 [350/412], Loss: -0.183
Epoch:76 [360/412], Loss: -0.179
Epoch:76 [370/412], Loss: -0.187
Epoch:76 [380/412], Loss: -0.106
Epoch:76 [390/412], Loss: -0.238
Epoch:76 [400/412], Loss: -0.121
Epoch:76 [410/412], Loss: -0.225
Epoch:76, Train IoU: [0.99455473 0.96291982 0.96138749]
Epoch:76, Valid Loss: -0.180, mIoU: 0.9744306282646754
Validation metric decreased (-0.168959 --> -0.180483).  Saving model ...
Epoch:77 [0/412], Loss: -0.206
Epoch:77 [10/412], Loss: -0.273
Epoch:77 [20/412], Loss: -0.228
Epoch:77 [30/412], Loss: -0.184
Epoch:77 [40/412], Loss: -0.234
Epoch:77 [50/412], Loss: -0.179
Epoch:77 [60/412], Loss: -0.204
Epoch:77 [70/412], Loss: -0.202
Epoch:77 [80/412], Loss: -0.167
Epoch:77 [90/412], Loss: -0.193
Epoch:77 [100/412], Loss: -0.233
Epoch:77 [110/412], Loss: -0.212
Epoch:77 [120/412], Loss: -0.109
Epoch:77 [130/412], Loss: -0.166
Epoch:77 [140/412], Loss: -0.242
Epoch:77 [150/412], Loss: -0.182
Epoch:77 [160/412], Loss: -0.191
Epoch:77 [170/412], Loss: -0.274
Epoch:77 [180/412], Loss: -0.217
Epoch:77 [190/412], Loss: -0.171
Epoch:77 [200/412], Loss: -0.220
Epoch:77 [210/412], Loss: -0.295
Epoch:77 [220/412], Loss: -0.172
Epoch:77 [230/412], Loss: -0.123
Epoch:77 [240/412], Loss: -0.217
Epoch:77 [250/412], Loss: -0.151
Epoch:77 [260/412], Loss: -0.197
Epoch:77 [270/412], Loss: -0.289
Epoch:77 [280/412], Loss: -0.240
Epoch:77 [290/412], Loss: -0.164
Epoch:77 [300/412], Loss: -0.183
Epoch:77 [310/412], Loss: -0.175
Epoch:77 [320/412], Loss: -0.221
Epoch:77 [330/412], Loss: -0.118
Epoch:77 [340/412], Loss: -0.172
Epoch:77 [350/412], Loss: -0.264
Epoch:77 [360/412], Loss: -0.211
Epoch:77 [370/412], Loss: -0.186
Epoch:77 [380/412], Loss: -0.227
Epoch:77 [390/412], Loss: -0.211
Epoch:77 [400/412], Loss: -0.212
Epoch:77 [410/412], Loss: -0.139
Epoch:77, Train IoU: [0.99465603 0.96384414 0.96208872]
Epoch:77, Valid Loss: -0.187, mIoU: 0.9736026324895466
Validation metric decreased (-0.180483 --> -0.187430).  Saving model ...
Epoch:78 [0/412], Loss: -0.192
Epoch:78 [10/412], Loss: -0.226
Epoch:78 [20/412], Loss: -0.263
Epoch:78 [30/412], Loss: -0.167
Epoch:78 [40/412], Loss: -0.233
Epoch:78 [50/412], Loss: -0.190
Epoch:78 [60/412], Loss: -0.274
Epoch:78 [70/412], Loss: -0.172
Epoch:78 [80/412], Loss: -0.243
Epoch:78 [90/412], Loss: -0.277
Epoch:78 [100/412], Loss: -0.160
Epoch:78 [110/412], Loss: -0.218
Epoch:78 [120/412], Loss: -0.156
Epoch:78 [130/412], Loss: -0.150
Epoch:78 [140/412], Loss: -0.190
Epoch:78 [150/412], Loss: -0.180
Epoch:78 [160/412], Loss: -0.113
Epoch:78 [170/412], Loss: -0.153
Epoch:78 [180/412], Loss: -0.106
Epoch:78 [190/412], Loss: -0.206
Epoch:78 [200/412], Loss: -0.240
Epoch:78 [210/412], Loss: -0.255
Epoch:78 [220/412], Loss: -0.174
Epoch:78 [230/412], Loss: -0.186
Epoch:78 [240/412], Loss: -0.253
Epoch:78 [250/412], Loss: -0.200
Epoch:78 [260/412], Loss: -0.199
Epoch:78 [270/412], Loss: -0.221
Epoch:78 [280/412], Loss: -0.229
Epoch:78 [290/412], Loss: -0.192
Epoch:78 [300/412], Loss: -0.191
Epoch:78 [310/412], Loss: -0.188
Epoch:78 [320/412], Loss: -0.140
Epoch:78 [330/412], Loss: -0.262
Epoch:78 [340/412], Loss: -0.195
Epoch:78 [350/412], Loss: -0.164
Epoch:78 [360/412], Loss: -0.144
Epoch:78 [370/412], Loss: -0.235
Epoch:78 [380/412], Loss: -0.215
Epoch:78 [390/412], Loss: -0.186
Epoch:78 [400/412], Loss: -0.191
Epoch:78 [410/412], Loss: -0.183
Epoch:78, Train IoU: [0.99438326 0.96103019 0.95938626]
Epoch:78, Valid Loss: -0.198, mIoU: 0.9739924966585459
Validation metric decreased (-0.187430 --> -0.197869).  Saving model ...
Epoch:79 [0/412], Loss: -0.247
Epoch:79 [10/412], Loss: -0.232
Epoch:79 [20/412], Loss: -0.244
Epoch:79 [30/412], Loss: -0.218
Epoch:79 [40/412], Loss: -0.232
Epoch:79 [50/412], Loss: -0.204
Epoch:79 [60/412], Loss: -0.224
Epoch:79 [70/412], Loss: -0.154
Epoch:79 [80/412], Loss: -0.171
Epoch:79 [90/412], Loss: -0.185
Epoch:79 [100/412], Loss: -0.272
Epoch:79 [110/412], Loss: -0.254
Epoch:79 [120/412], Loss: -0.244
Epoch:79 [130/412], Loss: -0.280
Epoch:79 [140/412], Loss: -0.231
Epoch:79 [150/412], Loss: -0.244
Epoch:79 [160/412], Loss: -0.185
Epoch:79 [170/412], Loss: -0.216
Epoch:79 [180/412], Loss: -0.250
Epoch:79 [190/412], Loss: -0.139
Epoch:79 [200/412], Loss: -0.195
Epoch:79 [210/412], Loss: -0.236
Epoch:79 [220/412], Loss: -0.226
Epoch:79 [230/412], Loss: -0.182
Epoch:79 [240/412], Loss: -0.248
Epoch:79 [250/412], Loss: -0.218
Epoch:79 [260/412], Loss: -0.223
Epoch:79 [270/412], Loss: -0.260
Epoch:79 [280/412], Loss: -0.232
Epoch:79 [290/412], Loss: -0.204
Epoch:79 [300/412], Loss: -0.187
Epoch:79 [310/412], Loss: -0.181
Epoch:79 [320/412], Loss: -0.195
Epoch:79 [330/412], Loss: -0.100
Epoch:79 [340/412], Loss: -0.124
Epoch:79 [350/412], Loss: -0.150
Epoch:79 [360/412], Loss: -0.165
Epoch:79 [370/412], Loss: -0.178
Epoch:79 [380/412], Loss: -0.211
Epoch:79 [390/412], Loss: -0.244
Epoch:79 [400/412], Loss: -0.183
Epoch:79 [410/412], Loss: -0.208
Epoch:79, Train IoU: [0.99464715 0.96323568 0.96130469]
Epoch:79, Valid Loss: -0.203, mIoU: 0.9748479924890835
Validation metric decreased (-0.197869 --> -0.202546).  Saving model ...
Epoch:80 [0/412], Loss: -0.238
Epoch:80 [10/412], Loss: -0.256
Epoch:80 [20/412], Loss: -0.260
Epoch:80 [30/412], Loss: -0.277
Epoch:80 [40/412], Loss: -0.255
Epoch:80 [50/412], Loss: -0.145
Epoch:80 [60/412], Loss: -0.205
Epoch:80 [70/412], Loss: -0.237
Epoch:80 [80/412], Loss: -0.271
Epoch:80 [90/412], Loss: -0.227
Epoch:80 [100/412], Loss: -0.177
Epoch:80 [110/412], Loss: -0.221
Epoch:80 [120/412], Loss: -0.226
Epoch:80 [130/412], Loss: -0.199
Epoch:80 [140/412], Loss: -0.228
Epoch:80 [150/412], Loss: -0.240
Epoch:80 [160/412], Loss: -0.183
Epoch:80 [170/412], Loss: -0.266
Epoch:80 [180/412], Loss: -0.290
Epoch:80 [190/412], Loss: -0.253
Epoch:80 [200/412], Loss: -0.144
Epoch:80 [210/412], Loss: -0.234
Epoch:80 [220/412], Loss: -0.216
Epoch:80 [230/412], Loss: -0.222
Epoch:80 [240/412], Loss: -0.279
Epoch:80 [250/412], Loss: -0.181
Epoch:80 [260/412], Loss: -0.282
Epoch:80 [270/412], Loss: -0.232
Epoch:80 [280/412], Loss: -0.245
Epoch:80 [290/412], Loss: -0.230
Epoch:80 [300/412], Loss: -0.237
Epoch:80 [310/412], Loss: -0.248
Epoch:80 [320/412], Loss: -0.232
Epoch:80 [330/412], Loss: -0.137
Epoch:80 [340/412], Loss: -0.178
Epoch:80 [350/412], Loss: -0.190
Epoch:80 [360/412], Loss: -0.179
Epoch:80 [370/412], Loss: -0.192
Epoch:80 [380/412], Loss: -0.165
Epoch:80 [390/412], Loss: -0.245
Epoch:80 [400/412], Loss: -0.209
Epoch:80 [410/412], Loss: -0.197
Epoch:80, Train IoU: [0.99468465 0.96379241 0.96159399]
Epoch:80, Valid Loss: -0.207, mIoU: 0.9742276777418009
Validation metric decreased (-0.202546 --> -0.206657).  Saving model ...
Epoch:81 [0/412], Loss: -0.230
Epoch:81 [10/412], Loss: -0.214
Epoch:81 [20/412], Loss: -0.321
Epoch:81 [30/412], Loss: -0.225
Epoch:81 [40/412], Loss: -0.249
Epoch:81 [50/412], Loss: -0.289
Epoch:81 [60/412], Loss: -0.267
Epoch:81 [70/412], Loss: -0.185
Epoch:81 [80/412], Loss: -0.188
Epoch:81 [90/412], Loss: -0.233
Epoch:81 [100/412], Loss: -0.157
Epoch:81 [110/412], Loss: -0.141
Epoch:81 [120/412], Loss: -0.236
Epoch:81 [130/412], Loss: -0.261
Epoch:81 [140/412], Loss: -0.251
Epoch:81 [150/412], Loss: -0.189
Epoch:81 [160/412], Loss: -0.283
Epoch:81 [170/412], Loss: -0.247
Epoch:81 [180/412], Loss: -0.273
Epoch:81 [190/412], Loss: -0.264
Epoch:81 [200/412], Loss: -0.199
Epoch:81 [210/412], Loss: -0.237
Epoch:81 [220/412], Loss: -0.209
Epoch:81 [230/412], Loss: -0.118
Epoch:81 [240/412], Loss: -0.199
Epoch:81 [250/412], Loss: -0.206
Epoch:81 [260/412], Loss: -0.254
Epoch:81 [270/412], Loss: -0.224
Epoch:81 [280/412], Loss: -0.233
Epoch:81 [290/412], Loss: -0.199
Epoch:81 [300/412], Loss: -0.200
Epoch:81 [310/412], Loss: -0.248
Epoch:81 [320/412], Loss: -0.199
Epoch:81 [330/412], Loss: -0.238
Epoch:81 [340/412], Loss: -0.143
Epoch:81 [350/412], Loss: -0.255
Epoch:81 [360/412], Loss: -0.211
Epoch:81 [370/412], Loss: -0.244
Epoch:81 [380/412], Loss: -0.188
Epoch:81 [390/412], Loss: -0.280
Epoch:81 [400/412], Loss: -0.210
Epoch:81 [410/412], Loss: -0.254
Epoch:81, Train IoU: [0.99470855 0.96391631 0.96150495]
Epoch:81, Valid Loss: -0.219, mIoU: 0.9747187336693498
Validation metric decreased (-0.206657 --> -0.219479).  Saving model ...
Epoch:82 [0/412], Loss: -0.273
Epoch:82 [10/412], Loss: -0.236
Epoch:82 [20/412], Loss: -0.314
Epoch:82 [30/412], Loss: -0.311
Epoch:82 [40/412], Loss: -0.219
Epoch:82 [50/412], Loss: -0.135
Epoch:82 [60/412], Loss: -0.274
Epoch:82 [70/412], Loss: -0.241
Epoch:82 [80/412], Loss: -0.263
Epoch:82 [90/412], Loss: -0.233
Epoch:82 [100/412], Loss: -0.249
Epoch:82 [110/412], Loss: -0.257
Epoch:82 [120/412], Loss: -0.259
Epoch:82 [130/412], Loss: -0.272
Epoch:82 [140/412], Loss: -0.160
Epoch:82 [150/412], Loss: -0.237
Epoch:82 [160/412], Loss: -0.194
Epoch:82 [170/412], Loss: -0.239
Epoch:82 [180/412], Loss: -0.191
Epoch:82 [190/412], Loss: -0.221
Epoch:82 [200/412], Loss: -0.236
Epoch:82 [210/412], Loss: -0.222
Epoch:82 [220/412], Loss: -0.245
Epoch:82 [230/412], Loss: -0.221
Epoch:82 [240/412], Loss: -0.232
Epoch:82 [250/412], Loss: -0.228
Epoch:82 [260/412], Loss: -0.266
Epoch:82 [270/412], Loss: -0.214
Epoch:82 [280/412], Loss: -0.245
Epoch:82 [290/412], Loss: -0.225
Epoch:82 [300/412], Loss: -0.321
Epoch:82 [310/412], Loss: -0.156
Epoch:82 [320/412], Loss: -0.260
Epoch:82 [330/412], Loss: -0.271
Epoch:82 [340/412], Loss: -0.167
Epoch:82 [350/412], Loss: -0.219
Epoch:82 [360/412], Loss: -0.204
Epoch:82 [370/412], Loss: -0.238
Epoch:82 [380/412], Loss: -0.266
Epoch:82 [390/412], Loss: -0.269
Epoch:82 [400/412], Loss: -0.220
Epoch:82 [410/412], Loss: -0.215
Epoch:82, Train IoU: [0.99454059 0.96252922 0.96087279]
Epoch:82, Valid Loss: -0.215, mIoU: 0.9734731207578718
Validation metric decreased (-0.219479 --> -0.214751).  Saving model ...
Epoch:83 [0/412], Loss: -0.112
Epoch:83 [10/412], Loss: -0.308
Epoch:83 [20/412], Loss: -0.231
Epoch:83 [30/412], Loss: -0.324
Epoch:83 [40/412], Loss: -0.247
Epoch:83 [50/412], Loss: -0.240
Epoch:83 [60/412], Loss: -0.260
Epoch:83 [70/412], Loss: -0.244
Epoch:83 [80/412], Loss: -0.262
Epoch:83 [90/412], Loss: -0.227
Epoch:83 [100/412], Loss: -0.310
Epoch:83 [110/412], Loss: -0.248
Epoch:83 [120/412], Loss: -0.311
Epoch:83 [130/412], Loss: -0.271
Epoch:83 [140/412], Loss: -0.272
Epoch:83 [150/412], Loss: -0.240
Epoch:83 [160/412], Loss: -0.263
Epoch:83 [170/412], Loss: -0.246
Epoch:83 [180/412], Loss: -0.294
Epoch:83 [190/412], Loss: -0.286
Epoch:83 [200/412], Loss: -0.197
Epoch:83 [210/412], Loss: -0.254
Epoch:83 [220/412], Loss: -0.253
Epoch:83 [230/412], Loss: -0.257
Epoch:83 [240/412], Loss: -0.279
Epoch:83 [250/412], Loss: -0.229
Epoch:83 [260/412], Loss: -0.220
Epoch:83 [270/412], Loss: -0.248
Epoch:83 [280/412], Loss: -0.236
Epoch:83 [290/412], Loss: -0.250
Epoch:83 [300/412], Loss: -0.219
Epoch:83 [310/412], Loss: -0.322
Epoch:83 [320/412], Loss: -0.245
Epoch:83 [330/412], Loss: -0.252
Epoch:83 [340/412], Loss: -0.273
Epoch:83 [350/412], Loss: -0.182
Epoch:83 [360/412], Loss: -0.252
Epoch:83 [370/412], Loss: -0.260
Epoch:83 [380/412], Loss: -0.275
Epoch:83 [390/412], Loss: -0.272
Epoch:83 [400/412], Loss: -0.276
Epoch:83 [410/412], Loss: -0.265
Epoch:83, Train IoU: [0.99478164 0.9645189  0.96176468]
Epoch:83, Valid Loss: -0.231, mIoU: 0.974652609350246
Validation metric decreased (-0.214751 --> -0.230862).  Saving model ...
Epoch:84 [0/412], Loss: -0.288
Epoch:84 [10/412], Loss: -0.283
Epoch:84 [20/412], Loss: -0.301
Epoch:84 [30/412], Loss: -0.307
Epoch:84 [40/412], Loss: -0.275
Epoch:84 [50/412], Loss: -0.316
Epoch:84 [60/412], Loss: -0.255
Epoch:84 [70/412], Loss: -0.244
Epoch:84 [80/412], Loss: -0.225
Epoch:84 [90/412], Loss: -0.310
Epoch:84 [100/412], Loss: -0.336
Epoch:84 [110/412], Loss: -0.297
Epoch:84 [120/412], Loss: -0.242
Epoch:84 [130/412], Loss: -0.298
Epoch:84 [140/412], Loss: -0.242
Epoch:84 [150/412], Loss: -0.226
Epoch:84 [160/412], Loss: -0.252
Epoch:84 [170/412], Loss: -0.235
Epoch:84 [180/412], Loss: -0.272
Epoch:84 [190/412], Loss: -0.261
Epoch:84 [200/412], Loss: -0.244
Epoch:84 [210/412], Loss: -0.265
Epoch:84 [220/412], Loss: -0.287
Epoch:84 [230/412], Loss: -0.285
Epoch:84 [240/412], Loss: -0.274
Epoch:84 [250/412], Loss: -0.169
Epoch:84 [260/412], Loss: -0.242
Epoch:84 [270/412], Loss: -0.245
Epoch:84 [280/412], Loss: -0.248
Epoch:84 [290/412], Loss: -0.231
Epoch:84 [300/412], Loss: -0.296
Epoch:84 [310/412], Loss: -0.297
Epoch:84 [320/412], Loss: -0.320
Epoch:84 [330/412], Loss: -0.223
Epoch:84 [340/412], Loss: -0.238
Epoch:84 [350/412], Loss: -0.222
Epoch:84 [360/412], Loss: -0.320
Epoch:84 [370/412], Loss: -0.162
Epoch:84 [380/412], Loss: -0.244
Epoch:84 [390/412], Loss: -0.234
Epoch:84 [400/412], Loss: -0.255
Epoch:84 [410/412], Loss: -0.297
Epoch:84, Train IoU: [0.99479992 0.96453706 0.96195102]
Epoch:84, Valid Loss: -0.246, mIoU: 0.974794820392079
Validation metric decreased (-0.230862 --> -0.245877).  Saving model ...
Epoch:85 [0/412], Loss: -0.333
Epoch:85 [10/412], Loss: -0.264
Epoch:85 [20/412], Loss: -0.262
Epoch:85 [30/412], Loss: -0.256
Epoch:85 [40/412], Loss: -0.301
Epoch:85 [50/412], Loss: -0.297
Epoch:85 [60/412], Loss: -0.303
Epoch:85 [70/412], Loss: -0.219
Epoch:85 [80/412], Loss: -0.185
Epoch:85 [90/412], Loss: -0.323
Epoch:85 [100/412], Loss: -0.210
Epoch:85 [110/412], Loss: -0.276
Epoch:85 [120/412], Loss: -0.212
Epoch:85 [130/412], Loss: -0.291
Epoch:85 [140/412], Loss: -0.294
Epoch:85 [150/412], Loss: -0.257
Epoch:85 [160/412], Loss: -0.226
Epoch:85 [170/412], Loss: -0.251
Epoch:85 [180/412], Loss: -0.309
Epoch:85 [190/412], Loss: -0.277
Epoch:85 [200/412], Loss: -0.223
Epoch:85 [210/412], Loss: -0.319
Epoch:85 [220/412], Loss: -0.307
Epoch:85 [230/412], Loss: -0.302
Epoch:85 [240/412], Loss: -0.278
Epoch:85 [250/412], Loss: -0.312
Epoch:85 [260/412], Loss: -0.225
Epoch:85 [270/412], Loss: -0.215
Epoch:85 [280/412], Loss: -0.206
Epoch:85 [290/412], Loss: -0.274
Epoch:85 [300/412], Loss: -0.284
Epoch:85 [310/412], Loss: -0.265
Epoch:85 [320/412], Loss: -0.258
Epoch:85 [330/412], Loss: -0.289
Epoch:85 [340/412], Loss: -0.287
Epoch:85 [350/412], Loss: -0.266
Epoch:85 [360/412], Loss: -0.276
Epoch:85 [370/412], Loss: -0.332
Epoch:85 [380/412], Loss: -0.231
Epoch:85 [390/412], Loss: -0.214
Epoch:85 [400/412], Loss: -0.272
Epoch:85 [410/412], Loss: -0.226
Epoch:85, Train IoU: [0.99480352 0.96468465 0.96256372]
Epoch:85, Valid Loss: -0.236, mIoU: 0.9742813951138242
EarlyStopping counter: 1 out of 100
Epoch:86 [0/412], Loss: -0.263
Epoch:86 [10/412], Loss: -0.238
Epoch:86 [20/412], Loss: -0.294
Epoch:86 [30/412], Loss: -0.227
Epoch:86 [40/412], Loss: -0.322
Epoch:86 [50/412], Loss: -0.304
Epoch:86 [60/412], Loss: -0.296
Epoch:86 [70/412], Loss: -0.354
Epoch:86 [80/412], Loss: -0.335
Epoch:86 [90/412], Loss: -0.284
Epoch:86 [100/412], Loss: -0.232
Epoch:86 [110/412], Loss: -0.233
Epoch:86 [120/412], Loss: -0.244
Epoch:86 [130/412], Loss: -0.298
Epoch:86 [140/412], Loss: -0.239
Epoch:86 [150/412], Loss: -0.242
Epoch:86 [160/412], Loss: -0.227
Epoch:86 [170/412], Loss: -0.324
Epoch:86 [180/412], Loss: -0.269
Epoch:86 [190/412], Loss: -0.287
Epoch:86 [200/412], Loss: -0.275
Epoch:86 [210/412], Loss: -0.258
Epoch:86 [220/412], Loss: -0.314
Epoch:86 [230/412], Loss: -0.380
Epoch:86 [240/412], Loss: -0.249
Epoch:86 [250/412], Loss: -0.242
Epoch:86 [260/412], Loss: -0.271
Epoch:86 [270/412], Loss: -0.314
Epoch:86 [280/412], Loss: -0.258
Epoch:86 [290/412], Loss: -0.248
Epoch:86 [300/412], Loss: -0.235
Epoch:86 [310/412], Loss: -0.283
Epoch:86 [320/412], Loss: -0.227
Epoch:86 [330/412], Loss: -0.285
Epoch:86 [340/412], Loss: -0.296
Epoch:86 [350/412], Loss: -0.274
Epoch:86 [360/412], Loss: -0.292
Epoch:86 [370/412], Loss: -0.225
Epoch:86 [380/412], Loss: -0.350
Epoch:86 [390/412], Loss: -0.294
Epoch:86 [400/412], Loss: -0.286
Epoch:86 [410/412], Loss: -0.248
Epoch:86, Train IoU: [0.9948657  0.9650377  0.96227187]
Epoch:86, Valid Loss: -0.258, mIoU: 0.9747895647165792
Validation metric decreased (-0.245877 --> -0.257519).  Saving model ...
Epoch:87 [0/412], Loss: -0.270
Epoch:87 [10/412], Loss: -0.293
Epoch:87 [20/412], Loss: -0.302
Epoch:87 [30/412], Loss: -0.308
Epoch:87 [40/412], Loss: -0.273
Epoch:87 [50/412], Loss: -0.240
Epoch:87 [60/412], Loss: -0.254
Epoch:87 [70/412], Loss: -0.301
Epoch:87 [80/412], Loss: -0.313
Epoch:87 [90/412], Loss: -0.309
Epoch:87 [100/412], Loss: -0.271
Epoch:87 [110/412], Loss: -0.280
Epoch:87 [120/412], Loss: -0.301
Epoch:87 [130/412], Loss: -0.264
Epoch:87 [140/412], Loss: -0.308
Epoch:87 [150/412], Loss: -0.255
Epoch:87 [160/412], Loss: -0.300
Epoch:87 [170/412], Loss: -0.291
Epoch:87 [180/412], Loss: -0.261
Epoch:87 [190/412], Loss: -0.348
Epoch:87 [200/412], Loss: -0.341
Epoch:87 [210/412], Loss: -0.265
Epoch:87 [220/412], Loss: -0.282
Epoch:87 [230/412], Loss: -0.291
Epoch:87 [240/412], Loss: -0.248
Epoch:87 [250/412], Loss: -0.271
Epoch:87 [260/412], Loss: -0.303
Epoch:87 [270/412], Loss: -0.277
Epoch:87 [280/412], Loss: -0.232
Epoch:87 [290/412], Loss: -0.269
Epoch:87 [300/412], Loss: -0.379
Epoch:87 [310/412], Loss: -0.260
Epoch:87 [320/412], Loss: -0.299
Epoch:87 [330/412], Loss: -0.320
Epoch:87 [340/412], Loss: -0.304
Epoch:87 [350/412], Loss: -0.279
Epoch:87 [360/412], Loss: -0.250
Epoch:87 [370/412], Loss: -0.318
Epoch:87 [380/412], Loss: -0.242
Epoch:87 [390/412], Loss: -0.280
Epoch:87 [400/412], Loss: -0.284
Epoch:87 [410/412], Loss: -0.283
Epoch:87, Train IoU: [0.99488283 0.96519797 0.96244308]
Epoch:87, Valid Loss: -0.255, mIoU: 0.9731089389686022
Validation metric decreased (-0.257519 --> -0.255402).  Saving model ...
Epoch:88 [0/412], Loss: -0.258
Epoch:88 [10/412], Loss: -0.316
Epoch:88 [20/412], Loss: -0.285
Epoch:88 [30/412], Loss: -0.286
Epoch:88 [40/412], Loss: -0.228
Epoch:88 [50/412], Loss: -0.308
Epoch:88 [60/412], Loss: -0.302
Epoch:88 [70/412], Loss: -0.317
Epoch:88 [80/412], Loss: -0.256
Epoch:88 [90/412], Loss: -0.292
Epoch:88 [100/412], Loss: -0.256
Epoch:88 [110/412], Loss: -0.333
Epoch:88 [120/412], Loss: -0.277
Epoch:88 [130/412], Loss: -0.342
Epoch:88 [140/412], Loss: -0.321
Epoch:88 [150/412], Loss: -0.306
Epoch:88 [160/412], Loss: -0.299
Epoch:88 [170/412], Loss: -0.250
Epoch:88 [180/412], Loss: -0.313
Epoch:88 [190/412], Loss: -0.276
Epoch:88 [200/412], Loss: -0.225
Epoch:88 [210/412], Loss: -0.320
Epoch:88 [220/412], Loss: -0.282
Epoch:88 [230/412], Loss: -0.272
Epoch:88 [240/412], Loss: -0.307
Epoch:88 [250/412], Loss: -0.342
Epoch:88 [260/412], Loss: -0.301
Epoch:88 [270/412], Loss: -0.208
Epoch:88 [280/412], Loss: -0.183
Epoch:88 [290/412], Loss: -0.224
Epoch:88 [300/412], Loss: -0.358
Epoch:88 [310/412], Loss: -0.313
Epoch:88 [320/412], Loss: -0.314
Epoch:88 [330/412], Loss: -0.248
Epoch:88 [340/412], Loss: -0.259
Epoch:88 [350/412], Loss: -0.314
Epoch:88 [360/412], Loss: -0.311
Epoch:88 [370/412], Loss: -0.323
Epoch:88 [380/412], Loss: -0.326
Epoch:88 [390/412], Loss: -0.298
Epoch:88 [400/412], Loss: -0.266
Epoch:88 [410/412], Loss: -0.343
Epoch:88, Train IoU: [0.9948155  0.96444947 0.96219979]
Epoch:88, Valid Loss: -0.274, mIoU: 0.9748915003536366
Validation metric decreased (-0.255402 --> -0.273860).  Saving model ...
Epoch:89 [0/412], Loss: -0.360
Epoch:89 [10/412], Loss: -0.286
Epoch:89 [20/412], Loss: -0.262
Epoch:89 [30/412], Loss: -0.313
Epoch:89 [40/412], Loss: -0.290
Epoch:89 [50/412], Loss: -0.296
Epoch:89 [60/412], Loss: -0.332
Epoch:89 [70/412], Loss: -0.331
Epoch:89 [80/412], Loss: -0.262
Epoch:89 [90/412], Loss: -0.307
Epoch:89 [100/412], Loss: -0.351
Epoch:89 [110/412], Loss: -0.346
Epoch:89 [120/412], Loss: -0.388
Epoch:89 [130/412], Loss: -0.280
Epoch:89 [140/412], Loss: -0.334
Epoch:89 [150/412], Loss: -0.358
Epoch:89 [160/412], Loss: -0.275
Epoch:89 [170/412], Loss: -0.332
Epoch:89 [180/412], Loss: -0.270
Epoch:89 [190/412], Loss: -0.301
Epoch:89 [200/412], Loss: -0.305
Epoch:89 [210/412], Loss: -0.285
Epoch:89 [220/412], Loss: -0.229
Epoch:89 [230/412], Loss: -0.268
Epoch:89 [240/412], Loss: -0.309
Epoch:89 [250/412], Loss: -0.273
Epoch:89 [260/412], Loss: -0.291
Epoch:89 [270/412], Loss: -0.280
Epoch:89 [280/412], Loss: -0.219
Epoch:89 [290/412], Loss: -0.292
Epoch:89 [300/412], Loss: -0.333
Epoch:89 [310/412], Loss: -0.323
Epoch:89 [320/412], Loss: -0.256
Epoch:89 [330/412], Loss: -0.255
Epoch:89 [340/412], Loss: -0.355
Epoch:89 [350/412], Loss: -0.355
Epoch:89 [360/412], Loss: -0.310
Epoch:89 [370/412], Loss: -0.285
Epoch:89 [380/412], Loss: -0.271
Epoch:89 [390/412], Loss: -0.287
Epoch:89 [400/412], Loss: -0.322
Epoch:89 [410/412], Loss: -0.216
Epoch:89, Train IoU: [0.99477292 0.96409167 0.96204286]
Epoch:89, Valid Loss: -0.238, mIoU: 0.9718347094837313
EarlyStopping counter: 1 out of 100
Epoch:90 [0/412], Loss: -0.242
Epoch:90 [10/412], Loss: -0.297
Epoch:90 [20/412], Loss: -0.327
Epoch:90 [30/412], Loss: -0.310
Epoch:90 [40/412], Loss: -0.346
Epoch:90 [50/412], Loss: -0.326
Epoch:90 [60/412], Loss: -0.363
Epoch:90 [70/412], Loss: -0.209
Epoch:90 [80/412], Loss: -0.288
Epoch:90 [90/412], Loss: -0.293
Epoch:90 [100/412], Loss: -0.260
Epoch:90 [110/412], Loss: -0.318
Epoch:90 [120/412], Loss: -0.282
Epoch:90 [130/412], Loss: -0.338
Epoch:90 [140/412], Loss: -0.247
Epoch:90 [150/412], Loss: -0.345
Epoch:90 [160/412], Loss: -0.332
Epoch:90 [170/412], Loss: -0.332
Epoch:90 [180/412], Loss: -0.257
Epoch:90 [190/412], Loss: -0.305
Epoch:90 [200/412], Loss: -0.290
Epoch:90 [210/412], Loss: -0.316
Epoch:90 [220/412], Loss: -0.263
Epoch:90 [230/412], Loss: -0.346
Epoch:90 [240/412], Loss: -0.279
Epoch:90 [250/412], Loss: -0.284
Epoch:90 [260/412], Loss: -0.330
Epoch:90 [270/412], Loss: -0.310
Epoch:90 [280/412], Loss: -0.256
Epoch:90 [290/412], Loss: -0.320
Epoch:90 [300/412], Loss: -0.303
Epoch:90 [310/412], Loss: -0.332
Epoch:90 [320/412], Loss: -0.366
Epoch:90 [330/412], Loss: -0.344
Epoch:90 [340/412], Loss: -0.278
Epoch:90 [350/412], Loss: -0.301
Epoch:90 [360/412], Loss: -0.267
Epoch:90 [370/412], Loss: -0.308
Epoch:90 [380/412], Loss: -0.311
Epoch:90 [390/412], Loss: -0.310
Epoch:90 [400/412], Loss: -0.282
Epoch:90 [410/412], Loss: -0.339
Epoch:90, Train IoU: [0.99488007 0.96484963 0.96210652]
Epoch:90, Valid Loss: -0.279, mIoU: 0.9734232656916926
Validation metric decreased (-0.273860 --> -0.278771).  Saving model ...
Epoch:91 [0/412], Loss: -0.353
Epoch:91 [10/412], Loss: -0.375
Epoch:91 [20/412], Loss: -0.319
Epoch:91 [30/412], Loss: -0.342
Epoch:91 [40/412], Loss: -0.191
Epoch:91 [50/412], Loss: -0.289
Epoch:91 [60/412], Loss: -0.323
Epoch:91 [70/412], Loss: -0.310
Epoch:91 [80/412], Loss: -0.262
Epoch:91 [90/412], Loss: -0.273
Epoch:91 [100/412], Loss: -0.320
Epoch:91 [110/412], Loss: -0.320
Epoch:91 [120/412], Loss: -0.293
Epoch:91 [130/412], Loss: -0.265
Epoch:91 [140/412], Loss: -0.247
Epoch:91 [150/412], Loss: -0.319
Epoch:91 [160/412], Loss: -0.341
Epoch:91 [170/412], Loss: -0.333
Epoch:91 [180/412], Loss: -0.271
Epoch:91 [190/412], Loss: -0.276
Epoch:91 [200/412], Loss: -0.263
Epoch:91 [210/412], Loss: -0.323
Epoch:91 [220/412], Loss: -0.315
Epoch:91 [230/412], Loss: -0.330
Epoch:91 [240/412], Loss: -0.277
Epoch:91 [250/412], Loss: -0.324
Epoch:91 [260/412], Loss: -0.312
Epoch:91 [270/412], Loss: -0.299
Epoch:91 [280/412], Loss: -0.356
Epoch:91 [290/412], Loss: -0.324
Epoch:91 [300/412], Loss: -0.300
Epoch:91 [310/412], Loss: -0.326
Epoch:91 [320/412], Loss: -0.309
Epoch:91 [330/412], Loss: -0.301
Epoch:91 [340/412], Loss: -0.354
Epoch:91 [350/412], Loss: -0.253
Epoch:91 [360/412], Loss: -0.320
Epoch:91 [370/412], Loss: -0.359
Epoch:91 [380/412], Loss: -0.276
Epoch:91 [390/412], Loss: -0.355
Epoch:91 [400/412], Loss: -0.323
Epoch:91 [410/412], Loss: -0.300
Epoch:91, Train IoU: [0.99488454 0.96507809 0.96239203]
Epoch:91, Valid Loss: -0.295, mIoU: 0.9750240063225362
Validation metric decreased (-0.278771 --> -0.295125).  Saving model ...
Epoch:92 [0/412], Loss: -0.393
Epoch:92 [10/412], Loss: -0.277
Epoch:92 [20/412], Loss: -0.255
Epoch:92 [30/412], Loss: -0.342
Epoch:92 [40/412], Loss: -0.297
Epoch:92 [50/412], Loss: -0.368
Epoch:92 [60/412], Loss: -0.311
Epoch:92 [70/412], Loss: -0.318
Epoch:92 [80/412], Loss: -0.323
Epoch:92 [90/412], Loss: -0.372
Epoch:92 [100/412], Loss: -0.291
Epoch:92 [110/412], Loss: -0.292
Epoch:92 [120/412], Loss: -0.275
Epoch:92 [130/412], Loss: -0.361
Epoch:92 [140/412], Loss: -0.372
Epoch:92 [150/412], Loss: -0.296
Epoch:92 [160/412], Loss: -0.328
Epoch:92 [170/412], Loss: -0.310
Epoch:92 [180/412], Loss: -0.324
Epoch:92 [190/412], Loss: -0.330
Epoch:92 [200/412], Loss: -0.346
Epoch:92 [210/412], Loss: -0.361
Epoch:92 [220/412], Loss: -0.340
Epoch:92 [230/412], Loss: -0.318
Epoch:92 [240/412], Loss: -0.308
Epoch:92 [250/412], Loss: -0.347
Epoch:92 [260/412], Loss: -0.356
Epoch:92 [270/412], Loss: -0.352
Epoch:92 [280/412], Loss: -0.298
Epoch:92 [290/412], Loss: -0.373
Epoch:92 [300/412], Loss: -0.311
Epoch:92 [310/412], Loss: -0.387
Epoch:92 [320/412], Loss: -0.368
Epoch:92 [330/412], Loss: -0.310
Epoch:92 [340/412], Loss: -0.310
Epoch:92 [350/412], Loss: -0.320
Epoch:92 [360/412], Loss: -0.347
Epoch:92 [370/412], Loss: -0.265
Epoch:92 [380/412], Loss: -0.354
Epoch:92 [390/412], Loss: -0.312
Epoch:92 [400/412], Loss: -0.379
Epoch:92 [410/412], Loss: -0.261
Epoch:92, Train IoU: [0.99499946 0.96594385 0.96262042]
Epoch:92, Valid Loss: -0.296, mIoU: 0.9730887000192198
Validation metric decreased (-0.295125 --> -0.295726).  Saving model ...
Epoch:93 [0/412], Loss: -0.374
Epoch:93 [10/412], Loss: -0.350
Epoch:93 [20/412], Loss: -0.321
Epoch:93 [30/412], Loss: -0.398
Epoch:93 [40/412], Loss: -0.347
Epoch:93 [50/412], Loss: -0.342
Epoch:93 [60/412], Loss: -0.357
Epoch:93 [70/412], Loss: -0.375
Epoch:93 [80/412], Loss: -0.430
Epoch:93 [90/412], Loss: -0.372
Epoch:93 [100/412], Loss: -0.307
Epoch:93 [110/412], Loss: -0.312
Epoch:93 [120/412], Loss: -0.390
Epoch:93 [130/412], Loss: -0.371
Epoch:93 [140/412], Loss: -0.315
Epoch:93 [150/412], Loss: -0.387
Epoch:93 [160/412], Loss: -0.341
Epoch:93 [170/412], Loss: -0.288
Epoch:93 [180/412], Loss: -0.334
Epoch:93 [190/412], Loss: -0.295
Epoch:93 [200/412], Loss: -0.356
Epoch:93 [210/412], Loss: -0.358
Epoch:93 [220/412], Loss: -0.376
Epoch:93 [230/412], Loss: -0.319
Epoch:93 [240/412], Loss: -0.338
Epoch:93 [250/412], Loss: -0.285
Epoch:93 [260/412], Loss: -0.325
Epoch:93 [270/412], Loss: -0.329
Epoch:93 [280/412], Loss: -0.352
Epoch:93 [290/412], Loss: -0.325
Epoch:93 [300/412], Loss: -0.193
Epoch:93 [310/412], Loss: -0.335
Epoch:93 [320/412], Loss: -0.357
Epoch:93 [330/412], Loss: -0.397
Epoch:93 [340/412], Loss: -0.311
Epoch:93 [350/412], Loss: -0.383
Epoch:93 [360/412], Loss: -0.326
Epoch:93 [370/412], Loss: -0.308
Epoch:93 [380/412], Loss: -0.376
Epoch:93 [390/412], Loss: -0.439
Epoch:93 [400/412], Loss: -0.259
Epoch:93 [410/412], Loss: -0.323
Epoch:93, Train IoU: [0.99489088 0.96468978 0.96173428]
Epoch:93, Valid Loss: -0.314, mIoU: 0.9747155344278079
Validation metric decreased (-0.295726 --> -0.313870).  Saving model ...
Epoch:94 [0/412], Loss: -0.348
Epoch:94 [10/412], Loss: -0.270
Epoch:94 [20/412], Loss: -0.414
Epoch:94 [30/412], Loss: -0.332
Epoch:94 [40/412], Loss: -0.358
Epoch:94 [50/412], Loss: -0.330
Epoch:94 [60/412], Loss: -0.381
Epoch:94 [70/412], Loss: -0.279
Epoch:94 [80/412], Loss: -0.343
Epoch:94 [90/412], Loss: -0.336
Epoch:94 [100/412], Loss: -0.378
Epoch:94 [110/412], Loss: -0.316
Epoch:94 [120/412], Loss: -0.363
Epoch:94 [130/412], Loss: -0.325
Epoch:94 [140/412], Loss: -0.247
Epoch:94 [150/412], Loss: -0.311
Epoch:94 [160/412], Loss: -0.387
Epoch:94 [170/412], Loss: -0.379
Epoch:94 [180/412], Loss: -0.315
Epoch:94 [190/412], Loss: -0.307
Epoch:94 [200/412], Loss: -0.301
Epoch:94 [210/412], Loss: -0.386
Epoch:94 [220/412], Loss: -0.292
Epoch:94 [230/412], Loss: -0.300
Epoch:94 [240/412], Loss: -0.300
Epoch:94 [250/412], Loss: -0.336
Epoch:94 [260/412], Loss: -0.387
Epoch:94 [270/412], Loss: -0.297
Epoch:94 [280/412], Loss: -0.298
Epoch:94 [290/412], Loss: -0.291
Epoch:94 [300/412], Loss: -0.298
Epoch:94 [310/412], Loss: -0.377
Epoch:94 [320/412], Loss: -0.389
Epoch:94 [330/412], Loss: -0.264
Epoch:94 [340/412], Loss: -0.369
Epoch:94 [350/412], Loss: -0.315
Epoch:94 [360/412], Loss: -0.311
Epoch:94 [370/412], Loss: -0.361
Epoch:94 [380/412], Loss: -0.343
Epoch:94 [390/412], Loss: -0.374
Epoch:94 [400/412], Loss: -0.332
Epoch:94 [410/412], Loss: -0.378
Epoch:94, Train IoU: [0.99507454 0.96617394 0.9627361 ]
Epoch:94, Valid Loss: -0.316, mIoU: 0.9742509526806641
Validation metric decreased (-0.313870 --> -0.316275).  Saving model ...
Epoch:95 [0/412], Loss: -0.288
Epoch:95 [10/412], Loss: -0.438
Epoch:95 [20/412], Loss: -0.398
Epoch:95 [30/412], Loss: -0.281
Epoch:95 [40/412], Loss: -0.336
Epoch:95 [50/412], Loss: -0.366
Epoch:95 [60/412], Loss: -0.370
Epoch:95 [70/412], Loss: -0.315
Epoch:95 [80/412], Loss: -0.394
Epoch:95 [90/412], Loss: -0.394
Epoch:95 [100/412], Loss: -0.364
Epoch:95 [110/412], Loss: -0.336
Epoch:95 [120/412], Loss: -0.338
Epoch:95 [130/412], Loss: -0.356
Epoch:95 [140/412], Loss: -0.325
Epoch:95 [150/412], Loss: -0.422
Epoch:95 [160/412], Loss: -0.376
Epoch:95 [170/412], Loss: -0.290
Epoch:95 [180/412], Loss: -0.323
Epoch:95 [190/412], Loss: -0.325
Epoch:95 [200/412], Loss: -0.294
Epoch:95 [210/412], Loss: -0.381
Epoch:95 [220/412], Loss: -0.308
Epoch:95 [230/412], Loss: -0.317
Epoch:95 [240/412], Loss: -0.355
Epoch:95 [250/412], Loss: -0.360
Epoch:95 [260/412], Loss: -0.364
Epoch:95 [270/412], Loss: -0.326
Epoch:95 [280/412], Loss: -0.446
Epoch:95 [290/412], Loss: -0.320
Epoch:95 [300/412], Loss: -0.384
Epoch:95 [310/412], Loss: -0.378
Epoch:95 [320/412], Loss: -0.342
Epoch:95 [330/412], Loss: -0.317
Epoch:95 [340/412], Loss: -0.414
Epoch:95 [350/412], Loss: -0.381
Epoch:95 [360/412], Loss: -0.324
Epoch:95 [370/412], Loss: -0.284
Epoch:95 [380/412], Loss: -0.423
Epoch:95 [390/412], Loss: -0.406
Epoch:95 [400/412], Loss: -0.329
Epoch:95 [410/412], Loss: -0.338
Epoch:95, Train IoU: [0.99499594 0.96553677 0.96207964]
Epoch:95, Valid Loss: -0.326, mIoU: 0.9751862075219441
Validation metric decreased (-0.316275 --> -0.326398).  Saving model ...
Epoch:96 [0/412], Loss: -0.396
Epoch:96 [10/412], Loss: -0.269
Epoch:96 [20/412], Loss: -0.348
Epoch:96 [30/412], Loss: -0.423
Epoch:96 [40/412], Loss: -0.327
Epoch:96 [50/412], Loss: -0.323
Epoch:96 [60/412], Loss: -0.375
Epoch:96 [70/412], Loss: -0.349
Epoch:96 [80/412], Loss: -0.327
Epoch:96 [90/412], Loss: -0.355
Epoch:96 [100/412], Loss: -0.337
Epoch:96 [110/412], Loss: -0.314
Epoch:96 [120/412], Loss: -0.271
Epoch:96 [130/412], Loss: -0.257
Epoch:96 [140/412], Loss: -0.415
Epoch:96 [150/412], Loss: -0.383
Epoch:96 [160/412], Loss: -0.357
Epoch:96 [170/412], Loss: -0.439
Epoch:96 [180/412], Loss: -0.354
Epoch:96 [190/412], Loss: -0.311
Epoch:96 [200/412], Loss: -0.361
Epoch:96 [210/412], Loss: -0.368
Epoch:96 [220/412], Loss: -0.312
Epoch:96 [230/412], Loss: -0.381
Epoch:96 [240/412], Loss: -0.319
Epoch:96 [250/412], Loss: -0.390
Epoch:96 [260/412], Loss: -0.245
Epoch:96 [270/412], Loss: -0.349
Epoch:96 [280/412], Loss: -0.348
Epoch:96 [290/412], Loss: -0.351
Epoch:96 [300/412], Loss: -0.363
Epoch:96 [310/412], Loss: -0.323
Epoch:96 [320/412], Loss: -0.331
Epoch:96 [330/412], Loss: -0.354
Epoch:96 [340/412], Loss: -0.377
Epoch:96 [350/412], Loss: -0.360
Epoch:96 [360/412], Loss: -0.348
Epoch:96 [370/412], Loss: -0.377
Epoch:96 [380/412], Loss: -0.376
Epoch:96 [390/412], Loss: -0.353
Epoch:96 [400/412], Loss: -0.366
Epoch:96 [410/412], Loss: -0.343
Epoch:96, Train IoU: [0.994779   0.96403316 0.96139732]
Epoch:96, Valid Loss: -0.334, mIoU: 0.9748200333310124
Validation metric decreased (-0.326398 --> -0.333816).  Saving model ...
Epoch:97 [0/412], Loss: -0.375
Epoch:97 [10/412], Loss: -0.393
Epoch:97 [20/412], Loss: -0.344
Epoch:97 [30/412], Loss: -0.372
Epoch:97 [40/412], Loss: -0.336
Epoch:97 [50/412], Loss: -0.371
Epoch:97 [60/412], Loss: -0.431
Epoch:97 [70/412], Loss: -0.374
Epoch:97 [80/412], Loss: -0.349
Epoch:97 [90/412], Loss: -0.369
Epoch:97 [100/412], Loss: -0.363
Epoch:97 [110/412], Loss: -0.361
Epoch:97 [120/412], Loss: -0.327
Epoch:97 [130/412], Loss: -0.268
Epoch:97 [140/412], Loss: -0.400
Epoch:97 [150/412], Loss: -0.359
Epoch:97 [160/412], Loss: -0.429
Epoch:97 [170/412], Loss: -0.379
Epoch:97 [180/412], Loss: -0.329
Epoch:97 [190/412], Loss: -0.369
Epoch:97 [200/412], Loss: -0.388
Epoch:97 [210/412], Loss: -0.330
Epoch:97 [220/412], Loss: -0.341
Epoch:97 [230/412], Loss: -0.381
Epoch:97 [240/412], Loss: -0.394
Epoch:97 [250/412], Loss: -0.330
Epoch:97 [260/412], Loss: -0.406
Epoch:97 [270/412], Loss: -0.371
Epoch:97 [280/412], Loss: -0.392
Epoch:97 [290/412], Loss: -0.348
Epoch:97 [300/412], Loss: -0.305
Epoch:97 [310/412], Loss: -0.356
Epoch:97 [320/412], Loss: -0.354
Epoch:97 [330/412], Loss: -0.362
Epoch:97 [340/412], Loss: -0.438
Epoch:97 [350/412], Loss: -0.366
Epoch:97 [360/412], Loss: -0.371
Epoch:97 [370/412], Loss: -0.390
Epoch:97 [380/412], Loss: -0.372
Epoch:97 [390/412], Loss: -0.347
Epoch:97 [400/412], Loss: -0.371
Epoch:97 [410/412], Loss: -0.391
Epoch:97, Train IoU: [0.99501801 0.96580149 0.96169679]
Epoch:97, Valid Loss: -0.340, mIoU: 0.9752748338050571
Validation metric decreased (-0.333816 --> -0.339718).  Saving model ...
Epoch:98 [0/412], Loss: -0.393
Epoch:98 [10/412], Loss: -0.403
Epoch:98 [20/412], Loss: -0.347
Epoch:98 [30/412], Loss: -0.326
Epoch:98 [40/412], Loss: -0.423
Epoch:98 [50/412], Loss: -0.373
Epoch:98 [60/412], Loss: -0.399
Epoch:98 [70/412], Loss: -0.380
Epoch:98 [80/412], Loss: -0.372
Epoch:98 [90/412], Loss: -0.388
Epoch:98 [100/412], Loss: -0.340
Epoch:98 [110/412], Loss: -0.383
Epoch:98 [120/412], Loss: -0.379
Epoch:98 [130/412], Loss: -0.370
Epoch:98 [140/412], Loss: -0.433
Epoch:98 [150/412], Loss: -0.379
Epoch:98 [160/412], Loss: -0.401
Epoch:98 [170/412], Loss: -0.408
Epoch:98 [180/412], Loss: -0.405
Epoch:98 [190/412], Loss: -0.453
Epoch:98 [200/412], Loss: -0.306
Epoch:98 [210/412], Loss: -0.375
Epoch:98 [220/412], Loss: -0.429
Epoch:98 [230/412], Loss: -0.370
Epoch:98 [240/412], Loss: -0.438
Epoch:98 [250/412], Loss: -0.395
Epoch:98 [260/412], Loss: -0.323
Epoch:98 [270/412], Loss: -0.396
Epoch:98 [280/412], Loss: -0.372
Epoch:98 [290/412], Loss: -0.411
Epoch:98 [300/412], Loss: -0.432
Epoch:98 [310/412], Loss: -0.426
Epoch:98 [320/412], Loss: -0.367
Epoch:98 [330/412], Loss: -0.346
Epoch:98 [340/412], Loss: -0.358
Epoch:98 [350/412], Loss: -0.398
Epoch:98 [360/412], Loss: -0.390
Epoch:98 [370/412], Loss: -0.381
Epoch:98 [380/412], Loss: -0.408
Epoch:98 [390/412], Loss: -0.342
Epoch:98 [400/412], Loss: -0.368
Epoch:98 [410/412], Loss: -0.357
Epoch:98, Train IoU: [0.99507473 0.9661798  0.96213105]
Epoch:98, Valid Loss: -0.341, mIoU: 0.974878524084028
Validation metric decreased (-0.339718 --> -0.340579).  Saving model ...
Epoch:99 [0/412], Loss: -0.393
Epoch:99 [10/412], Loss: -0.433
Epoch:99 [20/412], Loss: -0.445
Epoch:99 [30/412], Loss: -0.367
Epoch:99 [40/412], Loss: -0.412
Epoch:99 [50/412], Loss: -0.375
Epoch:99 [60/412], Loss: -0.339
Epoch:99 [70/412], Loss: -0.271
Epoch:99 [80/412], Loss: -0.390
Epoch:99 [90/412], Loss: -0.340
Epoch:99 [100/412], Loss: -0.412
Epoch:99 [110/412], Loss: -0.403
Epoch:99 [120/412], Loss: -0.400
Epoch:99 [130/412], Loss: -0.460
Epoch:99 [140/412], Loss: -0.389
Epoch:99 [150/412], Loss: -0.440
Epoch:99 [160/412], Loss: -0.343
Epoch:99 [170/412], Loss: -0.387
Epoch:99 [180/412], Loss: -0.478
Epoch:99 [190/412], Loss: -0.381
Epoch:99 [200/412], Loss: -0.332
Epoch:99 [210/412], Loss: -0.385
Epoch:99 [220/412], Loss: -0.312
Epoch:99 [230/412], Loss: -0.402
Epoch:99 [240/412], Loss: -0.443
Epoch:99 [250/412], Loss: -0.354
Epoch:99 [260/412], Loss: -0.360
Epoch:99 [270/412], Loss: -0.350
Epoch:99 [280/412], Loss: -0.418
Epoch:99 [290/412], Loss: -0.357
Epoch:99 [300/412], Loss: -0.389
Epoch:99 [310/412], Loss: -0.370
Epoch:99 [320/412], Loss: -0.404
Epoch:99 [330/412], Loss: -0.382
Epoch:99 [340/412], Loss: -0.377
Epoch:99 [350/412], Loss: -0.395
Epoch:99 [360/412], Loss: -0.405
Epoch:99 [370/412], Loss: -0.322
Epoch:99 [380/412], Loss: -0.395
Epoch:99 [390/412], Loss: -0.400
Epoch:99 [400/412], Loss: -0.294
Epoch:99 [410/412], Loss: -0.311
Epoch:99, Train IoU: [0.99508287 0.96600945 0.96274316]
Epoch:99, Valid Loss: -0.358, mIoU: 0.9753143594699858
Validation metric decreased (-0.340579 --> -0.358156).  Saving model ...
