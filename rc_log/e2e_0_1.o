------
parsed arguments:
{'batchsize': 48,
 'curObj': 0,
 'disp': 0,
 'epochs': 100,
 'expname': 'e2e_0_1',
 'loadfile': '',
 'lr': 0.0005,
 'model': 'ritnet',
 'overfit': 0,
 'path2data': '/home/rsk3900/Datasets/',
 'prec': 32,
 'resume': 0,
 'selfCorr': 1,
 'workers': 8}
Total number of trainable parameters: 1606317

Epoch:0 [0/412], Loss: 7629.354
Epoch:0 [10/412], Loss: 29.918
Epoch:0 [20/412], Loss: 29.427
Epoch:0 [30/412], Loss: 21.871
Epoch:0 [40/412], Loss: 16.570
Epoch:0 [50/412], Loss: 12.499
Epoch:0 [60/412], Loss: 12.038
Epoch:0 [70/412], Loss: 9.398
Epoch:0 [80/412], Loss: 9.712
Epoch:0 [90/412], Loss: 8.753
Epoch:0 [100/412], Loss: 8.818
Epoch:0 [110/412], Loss: 7.435
Epoch:0 [120/412], Loss: 7.262
Epoch:0 [130/412], Loss: 8.010
Epoch:0 [140/412], Loss: 7.706
Epoch:0 [150/412], Loss: 7.929
Epoch:0 [160/412], Loss: 6.419
Epoch:0 [170/412], Loss: 6.447
Epoch:0 [180/412], Loss: 6.827
Epoch:0 [190/412], Loss: 7.010
Epoch:0 [200/412], Loss: 5.715
Epoch:0 [210/412], Loss: 4.571
Epoch:0 [220/412], Loss: 5.764
Epoch:0 [230/412], Loss: 5.873
Epoch:0 [240/412], Loss: 6.374
Epoch:0 [250/412], Loss: 7.157
Epoch:0 [260/412], Loss: 5.644
Epoch:0 [270/412], Loss: 5.401
Epoch:0 [280/412], Loss: 4.695
Epoch:0 [290/412], Loss: 4.344
Epoch:0 [300/412], Loss: 5.262
Epoch:0 [310/412], Loss: 3.982
Epoch:0 [320/412], Loss: 4.699
Epoch:0 [330/412], Loss: 5.010
Epoch:0 [340/412], Loss: 5.959
Epoch:0 [350/412], Loss: 4.072
Epoch:0 [360/412], Loss: 4.247
Epoch:0 [370/412], Loss: 4.825
Epoch:0 [380/412], Loss: 4.189
Epoch:0 [390/412], Loss: 3.035
Epoch:0 [400/412], Loss: 4.113
Epoch:0 [410/412], Loss: 3.840
Epoch:0, Train IoU: [0.91048318 0.45716155 0.59578905]
Epoch:0, Valid Loss: 3.092, mIoU: 0.8305985710145295
Validation metric decreased (inf --> 3.092037).  Saving model ...
Epoch:1 [0/412], Loss: 3.898
Epoch:1 [10/412], Loss: 3.131
Epoch:1 [20/412], Loss: 3.065
Epoch:1 [30/412], Loss: 4.038
Epoch:1 [40/412], Loss: 3.961
Epoch:1 [50/412], Loss: 3.393
Epoch:1 [60/412], Loss: 4.156
Epoch:1 [70/412], Loss: 3.589
Epoch:1 [80/412], Loss: 3.777
Epoch:1 [90/412], Loss: 3.037
Epoch:1 [100/412], Loss: 3.152
Epoch:1 [110/412], Loss: 3.047
Epoch:1 [120/412], Loss: 3.587
Epoch:1 [130/412], Loss: 3.813
Epoch:1 [140/412], Loss: 2.679
Epoch:1 [150/412], Loss: 3.729
Epoch:1 [160/412], Loss: 3.634
Epoch:1 [170/412], Loss: 3.906
Epoch:1 [180/412], Loss: 3.107
Epoch:1 [190/412], Loss: 4.145
Epoch:1 [200/412], Loss: 2.855
Epoch:1 [210/412], Loss: 2.429
Epoch:1 [220/412], Loss: 3.225
Epoch:1 [230/412], Loss: 2.904
Epoch:1 [240/412], Loss: 3.544
Epoch:1 [250/412], Loss: 2.755
Epoch:1 [260/412], Loss: 2.494
Epoch:1 [270/412], Loss: 3.387
Epoch:1 [280/412], Loss: 3.270
Epoch:1 [290/412], Loss: 2.399
Epoch:1 [300/412], Loss: 2.921
Epoch:1 [310/412], Loss: 2.745
Epoch:1 [320/412], Loss: 2.980
Epoch:1 [330/412], Loss: 2.922
Epoch:1 [340/412], Loss: 2.838
Epoch:1 [350/412], Loss: 2.756
Epoch:1 [360/412], Loss: 2.796
Epoch:1 [370/412], Loss: 3.005
Epoch:1 [380/412], Loss: 2.856
Epoch:1 [390/412], Loss: 2.330
Epoch:1 [400/412], Loss: 2.370
Epoch:1 [410/412], Loss: 3.349
Epoch:1, Train IoU: [0.96011701 0.71061294 0.81297206]
Epoch:1, Valid Loss: 2.182, mIoU: 0.8766935051347451
Validation metric decreased (3.092037 --> 2.181736).  Saving model ...
Epoch:2 [0/412], Loss: 2.473
Epoch:2 [10/412], Loss: 2.179
Epoch:2 [20/412], Loss: 2.557
Epoch:2 [30/412], Loss: 2.560
Epoch:2 [40/412], Loss: 2.688
Epoch:2 [50/412], Loss: 2.977
Epoch:2 [60/412], Loss: 2.933
Epoch:2 [70/412], Loss: 2.527
Epoch:2 [80/412], Loss: 2.095
Epoch:2 [90/412], Loss: 2.318
Epoch:2 [100/412], Loss: 1.916
Epoch:2 [110/412], Loss: 1.974
Epoch:2 [120/412], Loss: 3.083
Epoch:2 [130/412], Loss: 2.629
Epoch:2 [140/412], Loss: 2.481
Epoch:2 [150/412], Loss: 2.724
Epoch:2 [160/412], Loss: 2.599
Epoch:2 [170/412], Loss: 2.547
Epoch:2 [180/412], Loss: 2.423
Epoch:2 [190/412], Loss: 2.554
Epoch:2 [200/412], Loss: 2.380
Epoch:2 [210/412], Loss: 2.024
Epoch:2 [220/412], Loss: 2.391
Epoch:2 [230/412], Loss: 2.521
Epoch:2 [240/412], Loss: 2.594
Epoch:2 [250/412], Loss: 1.783
Epoch:2 [260/412], Loss: 2.674
Epoch:2 [270/412], Loss: 1.997
Epoch:2 [280/412], Loss: 2.351
Epoch:2 [290/412], Loss: 2.158
Epoch:2 [300/412], Loss: 2.670
Epoch:2 [310/412], Loss: 2.693
Epoch:2 [320/412], Loss: 2.078
Epoch:2 [330/412], Loss: 2.723
Epoch:2 [340/412], Loss: 2.373
Epoch:2 [350/412], Loss: 2.144
Epoch:2 [360/412], Loss: 2.121
Epoch:2 [370/412], Loss: 2.237
Epoch:2 [380/412], Loss: 2.022
Epoch:2 [390/412], Loss: 2.341
Epoch:2 [400/412], Loss: 2.083
Epoch:2 [410/412], Loss: 2.104
Epoch:2, Train IoU: [0.96926846 0.76999886 0.85193308]
Epoch:2, Valid Loss: 1.786, mIoU: 0.8931913901609198
Validation metric decreased (2.181736 --> 1.785872).  Saving model ...
Epoch:3 [0/412], Loss: 1.814
Epoch:3 [10/412], Loss: 1.813
Epoch:3 [20/412], Loss: 1.961
Epoch:3 [30/412], Loss: 2.062
Epoch:3 [40/412], Loss: 2.032
Epoch:3 [50/412], Loss: 2.512
Epoch:3 [60/412], Loss: 2.047
Epoch:3 [70/412], Loss: 1.935
Epoch:3 [80/412], Loss: 1.906
Epoch:3 [90/412], Loss: 1.939
Epoch:3 [100/412], Loss: 2.566
Epoch:3 [110/412], Loss: 2.379
Epoch:3 [120/412], Loss: 2.797
Epoch:3 [130/412], Loss: 2.291
Epoch:3 [140/412], Loss: 1.854
Epoch:3 [150/412], Loss: 1.748
Epoch:3 [160/412], Loss: 2.277
Epoch:3 [170/412], Loss: 2.099
Epoch:3 [180/412], Loss: 2.321
Epoch:3 [190/412], Loss: 1.968
Epoch:3 [200/412], Loss: 2.170
Epoch:3 [210/412], Loss: 1.863
Epoch:3 [220/412], Loss: 1.654
Epoch:3 [230/412], Loss: 1.901
Epoch:3 [240/412], Loss: 1.557
Epoch:3 [250/412], Loss: 2.090
Epoch:3 [260/412], Loss: 1.776
Epoch:3 [270/412], Loss: 2.053
Epoch:3 [280/412], Loss: 2.190
Epoch:3 [290/412], Loss: 2.092
Epoch:3 [300/412], Loss: 2.321
Epoch:3 [310/412], Loss: 2.147
Epoch:3 [320/412], Loss: 2.140
Epoch:3 [330/412], Loss: 2.144
Epoch:3 [340/412], Loss: 2.203
Epoch:3 [350/412], Loss: 2.071
Epoch:3 [360/412], Loss: 2.186
Epoch:3 [370/412], Loss: 2.126
Epoch:3 [380/412], Loss: 1.997
Epoch:3 [390/412], Loss: 2.185
Epoch:3 [400/412], Loss: 1.744
Epoch:3 [410/412], Loss: 2.045
Epoch:3, Train IoU: [0.97311245 0.79515037 0.86654328]
Epoch:3, Valid Loss: 1.597, mIoU: 0.9075384057937556
Validation metric decreased (1.785872 --> 1.596791).  Saving model ...
Epoch:4 [0/412], Loss: 1.873
Epoch:4 [10/412], Loss: 1.626
Epoch:4 [20/412], Loss: 2.357
Epoch:4 [30/412], Loss: 1.920
Epoch:4 [40/412], Loss: 2.025
Epoch:4 [50/412], Loss: 1.739
Epoch:4 [60/412], Loss: 2.123
Epoch:4 [70/412], Loss: 1.532
Epoch:4 [80/412], Loss: 1.952
Epoch:4 [90/412], Loss: 2.056
Epoch:4 [100/412], Loss: 1.994
Epoch:4 [110/412], Loss: 1.633
Epoch:4 [120/412], Loss: 1.796
Epoch:4 [130/412], Loss: 2.066
Epoch:4 [140/412], Loss: 1.704
Epoch:4 [150/412], Loss: 1.840
Epoch:4 [160/412], Loss: 2.083
Epoch:4 [170/412], Loss: 1.683
Epoch:4 [180/412], Loss: 2.449
Epoch:4 [190/412], Loss: 2.029
Epoch:4 [200/412], Loss: 1.898
Epoch:4 [210/412], Loss: 2.085
Epoch:4 [220/412], Loss: 2.176
Epoch:4 [230/412], Loss: 2.428
Epoch:4 [240/412], Loss: 1.328
Epoch:4 [250/412], Loss: 1.947
Epoch:4 [260/412], Loss: 1.729
Epoch:4 [270/412], Loss: 1.611
Epoch:4 [280/412], Loss: 2.623
Epoch:4 [290/412], Loss: 2.087
Epoch:4 [300/412], Loss: 1.955
Epoch:4 [310/412], Loss: 1.811
Epoch:4 [320/412], Loss: 1.618
Epoch:4 [330/412], Loss: 2.003
Epoch:4 [340/412], Loss: 1.513
Epoch:4 [350/412], Loss: 1.478
Epoch:4 [360/412], Loss: 2.099
Epoch:4 [370/412], Loss: 2.215
Epoch:4 [380/412], Loss: 1.667
Epoch:4 [390/412], Loss: 2.046
Epoch:4 [400/412], Loss: 1.735
Epoch:4 [410/412], Loss: 1.707
Epoch:4, Train IoU: [0.97670889 0.81925014 0.87738611]
Epoch:4, Valid Loss: 1.430, mIoU: 0.9118304153186676
Validation metric decreased (1.596791 --> 1.429998).  Saving model ...
Epoch:5 [0/412], Loss: 2.166
Epoch:5 [10/412], Loss: 1.652
Epoch:5 [20/412], Loss: 1.977
Epoch:5 [30/412], Loss: 1.578
Epoch:5 [40/412], Loss: 2.123
Epoch:5 [50/412], Loss: 1.401
Epoch:5 [60/412], Loss: 2.008
Epoch:5 [70/412], Loss: 1.447
Epoch:5 [80/412], Loss: 1.911
Epoch:5 [90/412], Loss: 1.969
Epoch:5 [100/412], Loss: 1.551
Epoch:5 [110/412], Loss: 1.509
Epoch:5 [120/412], Loss: 1.958
Epoch:5 [130/412], Loss: 2.318
Epoch:5 [140/412], Loss: 1.489
Epoch:5 [150/412], Loss: 1.392
Epoch:5 [160/412], Loss: 1.602
Epoch:5 [170/412], Loss: 1.528
Epoch:5 [180/412], Loss: 1.616
Epoch:5 [190/412], Loss: 1.687
Epoch:5 [200/412], Loss: 1.941
Epoch:5 [210/412], Loss: 1.543
Epoch:5 [220/412], Loss: 1.675
Epoch:5 [230/412], Loss: 1.661
Epoch:5 [240/412], Loss: 1.411
Epoch:5 [250/412], Loss: 1.429
Epoch:5 [260/412], Loss: 1.499
Epoch:5 [270/412], Loss: 1.787
Epoch:5 [280/412], Loss: 1.476
Epoch:5 [290/412], Loss: 1.714
Epoch:5 [300/412], Loss: 1.279
Epoch:5 [310/412], Loss: 1.776
Epoch:5 [320/412], Loss: 1.288
Epoch:5 [330/412], Loss: 2.208
Epoch:5 [340/412], Loss: 1.891
Epoch:5 [350/412], Loss: 1.825
Epoch:5 [360/412], Loss: 1.911
Epoch:5 [370/412], Loss: 1.773
Epoch:5 [380/412], Loss: 1.443
Epoch:5 [390/412], Loss: 1.818
Epoch:5 [400/412], Loss: 1.487
Epoch:5 [410/412], Loss: 1.466
Epoch:5, Train IoU: [0.97972674 0.83825116 0.88468937]
Epoch:5, Valid Loss: 1.386, mIoU: 0.9192064349451288
Validation metric decreased (1.429998 --> 1.386087).  Saving model ...
Epoch:6 [0/412], Loss: 1.398
Epoch:6 [10/412], Loss: 1.786
Epoch:6 [20/412], Loss: 1.420
Epoch:6 [30/412], Loss: 1.642
Epoch:6 [40/412], Loss: 1.567
Epoch:6 [50/412], Loss: 1.293
Epoch:6 [60/412], Loss: 1.693
Epoch:6 [70/412], Loss: 1.507
Epoch:6 [80/412], Loss: 1.497
Epoch:6 [90/412], Loss: 1.513
Epoch:6 [100/412], Loss: 1.322
Epoch:6 [110/412], Loss: 1.330
Epoch:6 [120/412], Loss: 1.555
Epoch:6 [130/412], Loss: 1.535
Epoch:6 [140/412], Loss: 1.296
Epoch:6 [150/412], Loss: 2.074
Epoch:6 [160/412], Loss: 1.601
Epoch:6 [170/412], Loss: 1.387
Epoch:6 [180/412], Loss: 1.405
Epoch:6 [190/412], Loss: 1.639
Epoch:6 [200/412], Loss: 1.376
Epoch:6 [210/412], Loss: 1.730
Epoch:6 [220/412], Loss: 1.395
Epoch:6 [230/412], Loss: 1.573
Epoch:6 [240/412], Loss: 1.391
Epoch:6 [250/412], Loss: 1.288
Epoch:6 [260/412], Loss: 1.131
Epoch:6 [270/412], Loss: 1.283
Epoch:6 [280/412], Loss: 1.655
Epoch:6 [290/412], Loss: 1.361
Epoch:6 [300/412], Loss: 1.453
Epoch:6 [310/412], Loss: 1.562
Epoch:6 [320/412], Loss: 1.476
Epoch:6 [330/412], Loss: 1.293
Epoch:6 [340/412], Loss: 1.583
Epoch:6 [350/412], Loss: 1.379
Epoch:6 [360/412], Loss: 1.436
Epoch:6 [370/412], Loss: 1.404
Epoch:6 [380/412], Loss: 1.586
Epoch:6 [390/412], Loss: 1.453
Epoch:6 [400/412], Loss: 1.456
Epoch:6 [410/412], Loss: 1.346
Epoch:6, Train IoU: [0.98188429 0.85289433 0.89305476]
Epoch:6, Valid Loss: 1.307, mIoU: 0.9219356666609522
Validation metric decreased (1.386087 --> 1.306593).  Saving model ...
Epoch:7 [0/412], Loss: 1.662
Epoch:7 [10/412], Loss: 1.274
Epoch:7 [20/412], Loss: 1.442
Epoch:7 [30/412], Loss: 1.344
Epoch:7 [40/412], Loss: 1.465
Epoch:7 [50/412], Loss: 1.377
Epoch:7 [60/412], Loss: 1.400
Epoch:7 [70/412], Loss: 1.467
Epoch:7 [80/412], Loss: 1.448
Epoch:7 [90/412], Loss: 1.532
Epoch:7 [100/412], Loss: 1.448
Epoch:7 [110/412], Loss: 1.332
Epoch:7 [120/412], Loss: 1.197
Epoch:7 [130/412], Loss: 1.525
Epoch:7 [140/412], Loss: 1.362
Epoch:7 [150/412], Loss: 1.903
Epoch:7 [160/412], Loss: 1.475
Epoch:7 [170/412], Loss: 1.622
Epoch:7 [180/412], Loss: 1.213
Epoch:7 [190/412], Loss: 1.209
Epoch:7 [200/412], Loss: 1.324
Epoch:7 [210/412], Loss: 1.226
Epoch:7 [220/412], Loss: 1.407
Epoch:7 [230/412], Loss: 1.464
Epoch:7 [240/412], Loss: 1.452
Epoch:7 [250/412], Loss: 1.425
Epoch:7 [260/412], Loss: 1.378
Epoch:7 [270/412], Loss: 1.195
Epoch:7 [280/412], Loss: 1.284
Epoch:7 [290/412], Loss: 1.274
Epoch:7 [300/412], Loss: 1.439
Epoch:7 [310/412], Loss: 1.200
Epoch:7 [320/412], Loss: 1.337
Epoch:7 [330/412], Loss: 1.181
Epoch:7 [340/412], Loss: 1.305
Epoch:7 [350/412], Loss: 1.395
Epoch:7 [360/412], Loss: 1.332
Epoch:7 [370/412], Loss: 1.386
Epoch:7 [380/412], Loss: 1.447
Epoch:7 [390/412], Loss: 1.397
Epoch:7 [400/412], Loss: 1.252
Epoch:7 [410/412], Loss: 1.210
Epoch:7, Train IoU: [0.98292608 0.85967009 0.89576119]
Epoch:7, Valid Loss: 1.170, mIoU: 0.9256745972017743
Validation metric decreased (1.306593 --> 1.169804).  Saving model ...
Epoch:8 [0/412], Loss: 1.329
Epoch:8 [10/412], Loss: 1.341
Epoch:8 [20/412], Loss: 1.705
Epoch:8 [30/412], Loss: 1.558
Epoch:8 [40/412], Loss: 2.200
Epoch:8 [50/412], Loss: 1.482
Epoch:8 [60/412], Loss: 1.685
Epoch:8 [70/412], Loss: 1.326
Epoch:8 [80/412], Loss: 1.274
Epoch:8 [90/412], Loss: 1.524
Epoch:8 [100/412], Loss: 1.132
Epoch:8 [110/412], Loss: 1.356
Epoch:8 [120/412], Loss: 1.452
Epoch:8 [130/412], Loss: 1.398
Epoch:8 [140/412], Loss: 1.082
Epoch:8 [150/412], Loss: 1.309
Epoch:8 [160/412], Loss: 1.171
Epoch:8 [170/412], Loss: 1.360
Epoch:8 [180/412], Loss: 1.418
Epoch:8 [190/412], Loss: 1.278
Epoch:8 [200/412], Loss: 1.620
Epoch:8 [210/412], Loss: 1.568
Epoch:8 [220/412], Loss: 1.402
Epoch:8 [230/412], Loss: 1.393
Epoch:8 [240/412], Loss: 1.142
Epoch:8 [250/412], Loss: 1.542
Epoch:8 [260/412], Loss: 1.234
Epoch:8 [270/412], Loss: 1.286
Epoch:8 [280/412], Loss: 1.313
Epoch:8 [290/412], Loss: 1.462
Epoch:8 [300/412], Loss: 1.362
Epoch:8 [310/412], Loss: 1.705
Epoch:8 [320/412], Loss: 1.687
Epoch:8 [330/412], Loss: 1.128
Epoch:8 [340/412], Loss: 1.322
Epoch:8 [350/412], Loss: 1.172
Epoch:8 [360/412], Loss: 1.130
Epoch:8 [370/412], Loss: 1.190
Epoch:8 [380/412], Loss: 1.377
Epoch:8 [390/412], Loss: 1.207
Epoch:8 [400/412], Loss: 1.160
Epoch:8 [410/412], Loss: 1.273
Epoch:8, Train IoU: [0.98424416 0.86887385 0.90134973]
Epoch:8, Valid Loss: 1.071, mIoU: 0.9346981813583164
Validation metric decreased (1.169804 --> 1.071225).  Saving model ...
Epoch:9 [0/412], Loss: 1.150
Epoch:9 [10/412], Loss: 1.247
Epoch:9 [20/412], Loss: 1.475
Epoch:9 [30/412], Loss: 1.207
Epoch:9 [40/412], Loss: 0.995
Epoch:9 [50/412], Loss: 1.472
Epoch:9 [60/412], Loss: 1.635
Epoch:9 [70/412], Loss: 1.615
Epoch:9 [80/412], Loss: 1.233
Epoch:9 [90/412], Loss: 1.145
Epoch:9 [100/412], Loss: 1.237
Epoch:9 [110/412], Loss: 1.506
Epoch:9 [120/412], Loss: 1.134
Epoch:9 [130/412], Loss: 1.373
Epoch:9 [140/412], Loss: 1.252
Epoch:9 [150/412], Loss: 1.241
Epoch:9 [160/412], Loss: 1.559
Epoch:9 [170/412], Loss: 1.467
Epoch:9 [180/412], Loss: 1.398
Epoch:9 [190/412], Loss: 1.598
Epoch:9 [200/412], Loss: 1.692
Epoch:9 [210/412], Loss: 1.081
Epoch:9 [220/412], Loss: 1.021
Epoch:9 [230/412], Loss: 1.507
Epoch:9 [240/412], Loss: 1.661
Epoch:9 [250/412], Loss: 1.583
Epoch:9 [260/412], Loss: 1.154
Epoch:9 [270/412], Loss: 1.176
Epoch:9 [280/412], Loss: 1.401
Epoch:9 [290/412], Loss: 1.080
Epoch:9 [300/412], Loss: 1.133
Epoch:9 [310/412], Loss: 0.969
Epoch:9 [320/412], Loss: 1.043
Epoch:9 [330/412], Loss: 1.107
Epoch:9 [340/412], Loss: 1.047
Epoch:9 [350/412], Loss: 0.995
Epoch:9 [360/412], Loss: 1.460
Epoch:9 [370/412], Loss: 1.352
Epoch:9 [380/412], Loss: 1.411
Epoch:9 [390/412], Loss: 1.090
Epoch:9 [400/412], Loss: 1.134
Epoch:9 [410/412], Loss: 1.057
Epoch:9, Train IoU: [0.98431714 0.86962572 0.90199164]
Epoch:9, Valid Loss: 1.065, mIoU: 0.9313324312234673
Validation metric decreased (1.071225 --> 1.065273).  Saving model ...
Epoch:10 [0/412], Loss: 1.109
Epoch:10 [10/412], Loss: 1.383
Epoch:10 [20/412], Loss: 1.467
Epoch:10 [30/412], Loss: 1.516
Epoch:10 [40/412], Loss: 1.250
Epoch:10 [50/412], Loss: 1.130
Epoch:10 [60/412], Loss: 1.328
Epoch:10 [70/412], Loss: 1.180
Epoch:10 [80/412], Loss: 1.155
Epoch:10 [90/412], Loss: 1.097
Epoch:10 [100/412], Loss: 0.967
Epoch:10 [110/412], Loss: 1.392
Epoch:10 [120/412], Loss: 1.122
Epoch:10 [130/412], Loss: 1.220
Epoch:10 [140/412], Loss: 1.052
Epoch:10 [150/412], Loss: 1.087
Epoch:10 [160/412], Loss: 1.212
Epoch:10 [170/412], Loss: 1.225
Epoch:10 [180/412], Loss: 1.124
Epoch:10 [190/412], Loss: 1.315
Epoch:10 [200/412], Loss: 1.237
Epoch:10 [210/412], Loss: 1.416
Epoch:10 [220/412], Loss: 1.066
Epoch:10 [230/412], Loss: 1.400
Epoch:10 [240/412], Loss: 0.988
Epoch:10 [250/412], Loss: 1.029
Epoch:10 [260/412], Loss: 1.300
Epoch:10 [270/412], Loss: 1.174
Epoch:10 [280/412], Loss: 1.126
Epoch:10 [290/412], Loss: 1.329
Epoch:10 [300/412], Loss: 1.053
Epoch:10 [310/412], Loss: 1.057
Epoch:10 [320/412], Loss: 1.263
Epoch:10 [330/412], Loss: 1.455
Epoch:10 [340/412], Loss: 1.402
Epoch:10 [350/412], Loss: 0.946
Epoch:10 [360/412], Loss: 1.083
Epoch:10 [370/412], Loss: 1.089
Epoch:10 [380/412], Loss: 1.061
Epoch:10 [390/412], Loss: 1.424
Epoch:10 [400/412], Loss: 1.022
Epoch:10 [410/412], Loss: 1.353
Epoch:10, Train IoU: [0.98628428 0.88338737 0.90843396]
Epoch:10, Valid Loss: 1.004, mIoU: 0.9342078206516219
Validation metric decreased (1.065273 --> 1.004433).  Saving model ...
Epoch:11 [0/412], Loss: 1.058
Epoch:11 [10/412], Loss: 1.082
Epoch:11 [20/412], Loss: 1.137
Epoch:11 [30/412], Loss: 1.136
Epoch:11 [40/412], Loss: 1.160
Epoch:11 [50/412], Loss: 1.301
Epoch:11 [60/412], Loss: 1.018
Epoch:11 [70/412], Loss: 1.454
Epoch:11 [80/412], Loss: 1.138
Epoch:11 [90/412], Loss: 1.211
Epoch:11 [100/412], Loss: 1.080
Epoch:11 [110/412], Loss: 1.484
Epoch:11 [120/412], Loss: 1.012
Epoch:11 [130/412], Loss: 1.105
Epoch:11 [140/412], Loss: 1.404
Epoch:11 [150/412], Loss: 1.058
Epoch:11 [160/412], Loss: 1.175
Epoch:11 [170/412], Loss: 1.231
Epoch:11 [180/412], Loss: 1.279
Epoch:11 [190/412], Loss: 0.958
Epoch:11 [200/412], Loss: 1.284
Epoch:11 [210/412], Loss: 1.041
Epoch:11 [220/412], Loss: 1.022
Epoch:11 [230/412], Loss: 1.010
Epoch:11 [240/412], Loss: 1.055
Epoch:11 [250/412], Loss: 1.158
Epoch:11 [260/412], Loss: 1.239
Epoch:11 [270/412], Loss: 1.094
Epoch:11 [280/412], Loss: 1.090
Epoch:11 [290/412], Loss: 1.005
Epoch:11 [300/412], Loss: 1.173
Epoch:11 [310/412], Loss: 1.151
Epoch:11 [320/412], Loss: 1.123
Epoch:11 [330/412], Loss: 1.155
Epoch:11 [340/412], Loss: 1.191
Epoch:11 [350/412], Loss: 1.586
Epoch:11 [360/412], Loss: 1.077
Epoch:11 [370/412], Loss: 1.130
Epoch:11 [380/412], Loss: 1.213
Epoch:11 [390/412], Loss: 1.044
Epoch:11 [400/412], Loss: 1.168
Epoch:11 [410/412], Loss: 0.999
Epoch:11, Train IoU: [0.98672423 0.88746066 0.91082233]
Epoch:11, Valid Loss: 0.912, mIoU: 0.9407041024770146
Validation metric decreased (1.004433 --> 0.912473).  Saving model ...
Epoch:12 [0/412], Loss: 1.195
Epoch:12 [10/412], Loss: 1.001
Epoch:12 [20/412], Loss: 1.153
Epoch:12 [30/412], Loss: 1.074
Epoch:12 [40/412], Loss: 1.063
Epoch:12 [50/412], Loss: 0.938
Epoch:12 [60/412], Loss: 0.959
Epoch:12 [70/412], Loss: 0.932
Epoch:12 [80/412], Loss: 1.239
Epoch:12 [90/412], Loss: 1.148
Epoch:12 [100/412], Loss: 0.957
Epoch:12 [110/412], Loss: 1.019
Epoch:12 [120/412], Loss: 1.226
Epoch:12 [130/412], Loss: 0.929
Epoch:12 [140/412], Loss: 1.084
Epoch:12 [150/412], Loss: 0.932
Epoch:12 [160/412], Loss: 0.989
Epoch:12 [170/412], Loss: 1.244
Epoch:12 [180/412], Loss: 1.076
Epoch:12 [190/412], Loss: 1.180
Epoch:12 [200/412], Loss: 1.137
Epoch:12 [210/412], Loss: 0.989
Epoch:12 [220/412], Loss: 0.897
Epoch:12 [230/412], Loss: 0.979
Epoch:12 [240/412], Loss: 1.244
Epoch:12 [250/412], Loss: 1.252
Epoch:12 [260/412], Loss: 0.974
Epoch:12 [270/412], Loss: 1.007
Epoch:12 [280/412], Loss: 1.246
Epoch:12 [290/412], Loss: 1.192
Epoch:12 [300/412], Loss: 1.088
Epoch:12 [310/412], Loss: 0.902
Epoch:12 [320/412], Loss: 0.903
Epoch:12 [330/412], Loss: 1.041
Epoch:12 [340/412], Loss: 0.883
Epoch:12 [350/412], Loss: 1.453
Epoch:12 [360/412], Loss: 0.947
Epoch:12 [370/412], Loss: 0.898
Epoch:12 [380/412], Loss: 0.909
Epoch:12 [390/412], Loss: 0.862
Epoch:12 [400/412], Loss: 1.154
Epoch:12 [410/412], Loss: 0.958
Epoch:12, Train IoU: [0.98703016 0.88973475 0.91284719]
Epoch:12, Valid Loss: 0.886, mIoU: 0.9410189565837014
Validation metric decreased (0.912473 --> 0.886490).  Saving model ...
Epoch:13 [0/412], Loss: 1.004
Epoch:13 [10/412], Loss: 0.841
Epoch:13 [20/412], Loss: 0.869
Epoch:13 [30/412], Loss: 0.812
Epoch:13 [40/412], Loss: 0.909
Epoch:13 [50/412], Loss: 1.571
Epoch:13 [60/412], Loss: 1.670
Epoch:13 [70/412], Loss: 1.414
Epoch:13 [80/412], Loss: 1.103
Epoch:13 [90/412], Loss: 1.037
Epoch:13 [100/412], Loss: 1.252
Epoch:13 [110/412], Loss: 1.296
Epoch:13 [120/412], Loss: 1.323
Epoch:13 [130/412], Loss: 1.147
Epoch:13 [140/412], Loss: 1.441
Epoch:13 [150/412], Loss: 1.127
Epoch:13 [160/412], Loss: 1.137
Epoch:13 [170/412], Loss: 0.880
Epoch:13 [180/412], Loss: 1.070
Epoch:13 [190/412], Loss: 1.314
Epoch:13 [200/412], Loss: 1.385
Epoch:13 [210/412], Loss: 1.103
Epoch:13 [220/412], Loss: 1.019
Epoch:13 [230/412], Loss: 1.133
Epoch:13 [240/412], Loss: 0.864
Epoch:13 [250/412], Loss: 1.035
Epoch:13 [260/412], Loss: 0.843
Epoch:13 [270/412], Loss: 1.022
Epoch:13 [280/412], Loss: 1.079
Epoch:13 [290/412], Loss: 1.069
Epoch:13 [300/412], Loss: 1.050
Epoch:13 [310/412], Loss: 0.819
Epoch:13 [320/412], Loss: 0.960
Epoch:13 [330/412], Loss: 1.081
Epoch:13 [340/412], Loss: 1.314
Epoch:13 [350/412], Loss: 0.999
Epoch:13 [360/412], Loss: 0.949
Epoch:13 [370/412], Loss: 1.001
Epoch:13 [380/412], Loss: 0.970
Epoch:13 [390/412], Loss: 0.887
Epoch:13 [400/412], Loss: 0.819
Epoch:13 [410/412], Loss: 1.096
Epoch:13, Train IoU: [0.98640803 0.88517151 0.90963879]
Epoch:13, Valid Loss: 0.902, mIoU: 0.9416618986021188
EarlyStopping counter: 1 out of 100
Epoch:14 [0/412], Loss: 0.902
Epoch:14 [10/412], Loss: 1.011
Epoch:14 [20/412], Loss: 0.876
Epoch:14 [30/412], Loss: 1.243
Epoch:14 [40/412], Loss: 0.852
Epoch:14 [50/412], Loss: 0.861
Epoch:14 [60/412], Loss: 0.843
Epoch:14 [70/412], Loss: 0.960
Epoch:14 [80/412], Loss: 1.119
Epoch:14 [90/412], Loss: 0.878
Epoch:14 [100/412], Loss: 1.040
Epoch:14 [110/412], Loss: 1.059
Epoch:14 [120/412], Loss: 1.549
Epoch:14 [130/412], Loss: 0.900
Epoch:14 [140/412], Loss: 0.852
Epoch:14 [150/412], Loss: 1.396
Epoch:14 [160/412], Loss: 0.845
Epoch:14 [170/412], Loss: 1.188
Epoch:14 [180/412], Loss: 0.834
Epoch:14 [190/412], Loss: 1.087
Epoch:14 [200/412], Loss: 0.971
Epoch:14 [210/412], Loss: 0.995
Epoch:14 [220/412], Loss: 0.872
Epoch:14 [230/412], Loss: 0.809
Epoch:14 [240/412], Loss: 0.927
Epoch:14 [250/412], Loss: 1.107
Epoch:14 [260/412], Loss: 1.094
Epoch:14 [270/412], Loss: 0.810
Epoch:14 [280/412], Loss: 1.088
Epoch:14 [290/412], Loss: 0.843
Epoch:14 [300/412], Loss: 0.804
Epoch:14 [310/412], Loss: 0.851
Epoch:14 [320/412], Loss: 1.171
Epoch:14 [330/412], Loss: 0.875
Epoch:14 [340/412], Loss: 0.969
Epoch:14 [350/412], Loss: 0.985
Epoch:14 [360/412], Loss: 1.000
Epoch:14 [370/412], Loss: 1.062
Epoch:14 [380/412], Loss: 0.945
Epoch:14 [390/412], Loss: 0.873
Epoch:14 [400/412], Loss: 0.789
Epoch:14 [410/412], Loss: 1.146
Epoch:14, Train IoU: [0.98808018 0.89856086 0.91766177]
Epoch:14, Valid Loss: 0.779, mIoU: 0.9461366099597011
Validation metric decreased (0.886490 --> 0.779409).  Saving model ...
Epoch:15 [0/412], Loss: 0.970
Epoch:15 [10/412], Loss: 0.937
Epoch:15 [20/412], Loss: 1.064
Epoch:15 [30/412], Loss: 0.778
Epoch:15 [40/412], Loss: 0.743
Epoch:15 [50/412], Loss: 0.852
Epoch:15 [60/412], Loss: 1.383
Epoch:15 [70/412], Loss: 1.172
Epoch:15 [80/412], Loss: 1.092
Epoch:15 [90/412], Loss: 0.946
Epoch:15 [100/412], Loss: 1.750
Epoch:15 [110/412], Loss: 1.518
Epoch:15 [120/412], Loss: 1.087
Epoch:15 [130/412], Loss: 0.885
Epoch:15 [140/412], Loss: 1.003
Epoch:15 [150/412], Loss: 0.958
Epoch:15 [160/412], Loss: 1.218
Epoch:15 [170/412], Loss: 0.927
Epoch:15 [180/412], Loss: 1.186
Epoch:15 [190/412], Loss: 0.873
Epoch:15 [200/412], Loss: 0.946
Epoch:15 [210/412], Loss: 1.364
Epoch:15 [220/412], Loss: 0.958
Epoch:15 [230/412], Loss: 0.857
Epoch:15 [240/412], Loss: 0.877
Epoch:15 [250/412], Loss: 0.810
Epoch:15 [260/412], Loss: 0.768
Epoch:15 [270/412], Loss: 0.895
Epoch:15 [280/412], Loss: 0.864
Epoch:15 [290/412], Loss: 0.791
Epoch:15 [300/412], Loss: 1.024
Epoch:15 [310/412], Loss: 1.357
Epoch:15 [320/412], Loss: 0.925
Epoch:15 [330/412], Loss: 0.923
Epoch:15 [340/412], Loss: 0.875
Epoch:15 [350/412], Loss: 0.949
Epoch:15 [360/412], Loss: 0.830
Epoch:15 [370/412], Loss: 0.809
Epoch:15 [380/412], Loss: 0.888
Epoch:15 [390/412], Loss: 0.970
Epoch:15 [400/412], Loss: 0.770
Epoch:15 [410/412], Loss: 0.921
Epoch:15, Train IoU: [0.98767547 0.89576884 0.91604038]
Epoch:15, Valid Loss: 0.725, mIoU: 0.9497014207948512
Validation metric decreased (0.779409 --> 0.725270).  Saving model ...
Epoch:16 [0/412], Loss: 0.712
Epoch:16 [10/412], Loss: 1.016
Epoch:16 [20/412], Loss: 1.008
Epoch:16 [30/412], Loss: 0.834
Epoch:16 [40/412], Loss: 0.753
Epoch:16 [50/412], Loss: 0.951
Epoch:16 [60/412], Loss: 0.801
Epoch:16 [70/412], Loss: 0.910
Epoch:16 [80/412], Loss: 1.003
Epoch:16 [90/412], Loss: 1.204
Epoch:16 [100/412], Loss: 0.734
Epoch:16 [110/412], Loss: 0.825
Epoch:16 [120/412], Loss: 0.802
Epoch:16 [130/412], Loss: 1.159
Epoch:16 [140/412], Loss: 0.681
Epoch:16 [150/412], Loss: 0.802
Epoch:16 [160/412], Loss: 0.861
Epoch:16 [170/412], Loss: 0.839
Epoch:16 [180/412], Loss: 0.816
Epoch:16 [190/412], Loss: 0.740
Epoch:16 [200/412], Loss: 0.977
Epoch:16 [210/412], Loss: 0.890
Epoch:16 [220/412], Loss: 0.729
Epoch:16 [230/412], Loss: 0.915
Epoch:16 [240/412], Loss: 1.197
Epoch:16 [250/412], Loss: 0.786
Epoch:16 [260/412], Loss: 2.162
Epoch:16 [270/412], Loss: 0.983
Epoch:16 [280/412], Loss: 1.123
Epoch:16 [290/412], Loss: 1.230
Epoch:16 [300/412], Loss: 0.914
Epoch:16 [310/412], Loss: 0.961
Epoch:16 [320/412], Loss: 0.898
Epoch:16 [330/412], Loss: 0.937
Epoch:16 [340/412], Loss: 1.201
Epoch:16 [350/412], Loss: 0.819
Epoch:16 [360/412], Loss: 0.811
Epoch:16 [370/412], Loss: 0.778
Epoch:16 [380/412], Loss: 0.919
Epoch:16 [390/412], Loss: 0.960
Epoch:16 [400/412], Loss: 1.033
Epoch:16 [410/412], Loss: 0.893
Epoch:16, Train IoU: [0.98872    0.90479718 0.92260202]
Epoch:16, Valid Loss: 0.719, mIoU: 0.9495884563154249
Validation metric decreased (0.725270 --> 0.718917).  Saving model ...
Epoch:17 [0/412], Loss: 1.066
Epoch:17 [10/412], Loss: 1.048
Epoch:17 [20/412], Loss: 0.792
Epoch:17 [30/412], Loss: 0.662
Epoch:17 [40/412], Loss: 0.828
Epoch:17 [50/412], Loss: 0.659
Epoch:17 [60/412], Loss: 0.934
Epoch:17 [70/412], Loss: 0.694
Epoch:17 [80/412], Loss: 0.709
Epoch:17 [90/412], Loss: 0.746
Epoch:17 [100/412], Loss: 0.864
Epoch:17 [110/412], Loss: 0.968
Epoch:17 [120/412], Loss: 0.774
Epoch:17 [130/412], Loss: 0.732
Epoch:17 [140/412], Loss: 0.884
Epoch:17 [150/412], Loss: 0.909
Epoch:17 [160/412], Loss: 0.710
Epoch:17 [170/412], Loss: 0.874
Epoch:17 [180/412], Loss: 0.720
Epoch:17 [190/412], Loss: 0.883
Epoch:17 [200/412], Loss: 0.858
Epoch:17 [210/412], Loss: 0.741
Epoch:17 [220/412], Loss: 0.735
Epoch:17 [230/412], Loss: 1.384
Epoch:17 [240/412], Loss: 0.959
Epoch:17 [250/412], Loss: 0.938
Epoch:17 [260/412], Loss: 0.728
Epoch:17 [270/412], Loss: 0.970
Epoch:17 [280/412], Loss: 0.665
Epoch:17 [290/412], Loss: 0.767
Epoch:17 [300/412], Loss: 0.762
Epoch:17 [310/412], Loss: 0.774
Epoch:17 [320/412], Loss: 0.785
Epoch:17 [330/412], Loss: 0.747
Epoch:17 [340/412], Loss: 0.737
Epoch:17 [350/412], Loss: 0.721
Epoch:17 [360/412], Loss: 0.713
Epoch:17 [370/412], Loss: 0.816
Epoch:17 [380/412], Loss: 0.750
Epoch:17 [390/412], Loss: 0.975
Epoch:17 [400/412], Loss: 0.827
Epoch:17 [410/412], Loss: 0.886
Epoch:17, Train IoU: [0.9892404  0.9094924  0.92470216]
Epoch:17, Valid Loss: 0.820, mIoU: 0.9408189314846478
EarlyStopping counter: 1 out of 100
Epoch:18 [0/412], Loss: 0.876
Epoch:18 [10/412], Loss: 0.921
Epoch:18 [20/412], Loss: 0.684
Epoch:18 [30/412], Loss: 0.875
Epoch:18 [40/412], Loss: 0.800
Epoch:18 [50/412], Loss: 0.783
Epoch:18 [60/412], Loss: 0.690
Epoch:18 [70/412], Loss: 0.875
Epoch:18 [80/412], Loss: 0.764
Epoch:18 [90/412], Loss: 0.714
Epoch:18 [100/412], Loss: 0.677
Epoch:18 [110/412], Loss: 0.836
Epoch:18 [120/412], Loss: 0.791
Epoch:18 [130/412], Loss: 0.941
Epoch:18 [140/412], Loss: 1.096
Epoch:18 [150/412], Loss: 0.723
Epoch:18 [160/412], Loss: 0.736
Epoch:18 [170/412], Loss: 0.688
Epoch:18 [180/412], Loss: 0.847
Epoch:18 [190/412], Loss: 0.790
Epoch:18 [200/412], Loss: 0.879
Epoch:18 [210/412], Loss: 0.844
Epoch:18 [220/412], Loss: 1.015
Epoch:18 [230/412], Loss: 0.824
Epoch:18 [240/412], Loss: 0.760
Epoch:18 [250/412], Loss: 0.928
Epoch:18 [260/412], Loss: 0.645
Epoch:18 [270/412], Loss: 0.646
Epoch:18 [280/412], Loss: 0.689
Epoch:18 [290/412], Loss: 0.860
Epoch:18 [300/412], Loss: 0.614
Epoch:18 [310/412], Loss: 0.826
Epoch:18 [320/412], Loss: 0.767
Epoch:18 [330/412], Loss: 0.829
Epoch:18 [340/412], Loss: 0.782
Epoch:18 [350/412], Loss: 0.708
Epoch:18 [360/412], Loss: 0.680
Epoch:18 [370/412], Loss: 0.681
Epoch:18 [380/412], Loss: 0.809
Epoch:18 [390/412], Loss: 0.644
Epoch:18 [400/412], Loss: 0.701
Epoch:18 [410/412], Loss: 0.876
Epoch:18, Train IoU: [0.98967117 0.9134768  0.92682119]
Epoch:18, Valid Loss: 0.674, mIoU: 0.950434104153457
Validation metric decreased (0.718917 --> 0.674371).  Saving model ...
Epoch:19 [0/412], Loss: 0.896
Epoch:19 [10/412], Loss: 0.796
Epoch:19 [20/412], Loss: 0.843
Epoch:19 [30/412], Loss: 0.911
Epoch:19 [40/412], Loss: 0.683
Epoch:19 [50/412], Loss: 0.879
Epoch:19 [60/412], Loss: 0.753
Epoch:19 [70/412], Loss: 0.642
Epoch:19 [80/412], Loss: 0.690
Epoch:19 [90/412], Loss: 0.809
Epoch:19 [100/412], Loss: 0.572
Epoch:19 [110/412], Loss: 0.776
Epoch:19 [120/412], Loss: 0.729
Epoch:19 [130/412], Loss: 0.869
Epoch:19 [140/412], Loss: 1.135
Epoch:19 [150/412], Loss: 0.577
Epoch:19 [160/412], Loss: 0.750
Epoch:19 [170/412], Loss: 0.774
Epoch:19 [180/412], Loss: 0.597
Epoch:19 [190/412], Loss: 0.627
Epoch:19 [200/412], Loss: 0.779
Epoch:19 [210/412], Loss: 0.672
Epoch:19 [220/412], Loss: 0.579
Epoch:19 [230/412], Loss: 0.644
Epoch:19 [240/412], Loss: 0.768
Epoch:19 [250/412], Loss: 0.717
Epoch:19 [260/412], Loss: 0.644
Epoch:19 [270/412], Loss: 0.595
Epoch:19 [280/412], Loss: 0.741
Epoch:19 [290/412], Loss: 0.618
Epoch:19 [300/412], Loss: 0.629
Epoch:19 [310/412], Loss: 0.589
Epoch:19 [320/412], Loss: 0.541
Epoch:19 [330/412], Loss: 0.684
Epoch:19 [340/412], Loss: 0.725
Epoch:19 [350/412], Loss: 0.774
Epoch:19 [360/412], Loss: 0.677
Epoch:19 [370/412], Loss: 0.593
Epoch:19 [380/412], Loss: 0.894
Epoch:19 [390/412], Loss: 0.841
Epoch:19 [400/412], Loss: 0.697
Epoch:19 [410/412], Loss: 0.628
Epoch:19, Train IoU: [0.99013899 0.91783244 0.92927358]
Epoch:19, Valid Loss: 0.570, mIoU: 0.9550666041558036
Validation metric decreased (0.674371 --> 0.570134).  Saving model ...
Epoch:20 [0/412], Loss: 0.718
Epoch:20 [10/412], Loss: 0.530
Epoch:20 [20/412], Loss: 0.630
Epoch:20 [30/412], Loss: 0.618
Epoch:20 [40/412], Loss: 0.708
Epoch:20 [50/412], Loss: 0.660
Epoch:20 [60/412], Loss: 0.782
Epoch:20 [70/412], Loss: 0.621
Epoch:20 [80/412], Loss: 0.852
Epoch:20 [90/412], Loss: 1.079
Epoch:20 [100/412], Loss: 1.054
Epoch:20 [110/412], Loss: 0.827
Epoch:20 [120/412], Loss: 0.899
Epoch:20 [130/412], Loss: 0.910
Epoch:20 [140/412], Loss: 0.728
Epoch:20 [150/412], Loss: 0.695
Epoch:20 [160/412], Loss: 0.729
Epoch:20 [170/412], Loss: 0.806
Epoch:20 [180/412], Loss: 0.667
Epoch:20 [190/412], Loss: 0.711
Epoch:20 [200/412], Loss: 0.634
Epoch:20 [210/412], Loss: 0.680
Epoch:20 [220/412], Loss: 0.775
Epoch:20 [230/412], Loss: 0.850
Epoch:20 [240/412], Loss: 0.809
Epoch:20 [250/412], Loss: 0.800
Epoch:20 [260/412], Loss: 0.820
Epoch:20 [270/412], Loss: 0.980
Epoch:20 [280/412], Loss: 0.802
Epoch:20 [290/412], Loss: 0.659
Epoch:20 [300/412], Loss: 0.733
Epoch:20 [310/412], Loss: 1.333
Epoch:20 [320/412], Loss: 0.721
Epoch:20 [330/412], Loss: 0.743
Epoch:20 [340/412], Loss: 0.585
Epoch:20 [350/412], Loss: 0.622
Epoch:20 [360/412], Loss: 0.591
Epoch:20 [370/412], Loss: 0.688
Epoch:20 [380/412], Loss: 0.576
Epoch:20 [390/412], Loss: 0.762
Epoch:20 [400/412], Loss: 0.712
Epoch:20 [410/412], Loss: 0.680
Epoch:20, Train IoU: [0.98989204 0.91629005 0.92977287]
Epoch:20, Valid Loss: 0.550, mIoU: 0.9570554289890442
Validation metric decreased (0.570134 --> 0.549983).  Saving model ...
Epoch:21 [0/412], Loss: 0.674
Epoch:21 [10/412], Loss: 0.695
Epoch:21 [20/412], Loss: 0.648
Epoch:21 [30/412], Loss: 0.636
Epoch:21 [40/412], Loss: 0.653
Epoch:21 [50/412], Loss: 0.728
Epoch:21 [60/412], Loss: 0.621
Epoch:21 [70/412], Loss: 0.740
Epoch:21 [80/412], Loss: 0.586
Epoch:21 [90/412], Loss: 0.875
Epoch:21 [100/412], Loss: 0.793
Epoch:21 [110/412], Loss: 0.730
Epoch:21 [120/412], Loss: 0.578
Epoch:21 [130/412], Loss: 0.603
Epoch:21 [140/412], Loss: 1.113
Epoch:21 [150/412], Loss: 0.840
Epoch:21 [160/412], Loss: 0.663
Epoch:21 [170/412], Loss: 0.679
Epoch:21 [180/412], Loss: 0.744
Epoch:21 [190/412], Loss: 0.549
Epoch:21 [200/412], Loss: 0.721
Epoch:21 [210/412], Loss: 0.780
Epoch:21 [220/412], Loss: 0.725
Epoch:21 [230/412], Loss: 0.636
Epoch:21 [240/412], Loss: 0.889
Epoch:21 [250/412], Loss: 0.676
Epoch:21 [260/412], Loss: 0.913
Epoch:21 [270/412], Loss: 0.646
Epoch:21 [280/412], Loss: 0.552
Epoch:21 [290/412], Loss: 0.796
Epoch:21 [300/412], Loss: 0.849
Epoch:21 [310/412], Loss: 0.877
Epoch:21 [320/412], Loss: 0.708
Epoch:21 [330/412], Loss: 0.591
Epoch:21 [340/412], Loss: 0.686
Epoch:21 [350/412], Loss: 0.727
Epoch:21 [360/412], Loss: 0.695
Epoch:21 [370/412], Loss: 0.700
Epoch:21 [380/412], Loss: 0.679
Epoch:21 [390/412], Loss: 0.759
Epoch:21 [400/412], Loss: 0.673
Epoch:21 [410/412], Loss: 0.567
Epoch:21, Train IoU: [0.9902711  0.91969517 0.93060143]
Epoch:21, Valid Loss: 0.591, mIoU: 0.9522961587767345
EarlyStopping counter: 1 out of 100
Epoch:22 [0/412], Loss: 0.686
Epoch:22 [10/412], Loss: 0.669
Epoch:22 [20/412], Loss: 0.853
Epoch:22 [30/412], Loss: 0.552
Epoch:22 [40/412], Loss: 0.639
Epoch:22 [50/412], Loss: 0.630
Epoch:22 [60/412], Loss: 0.681
Epoch:22 [70/412], Loss: 0.668
Epoch:22 [80/412], Loss: 0.746
Epoch:22 [90/412], Loss: 0.679
Epoch:22 [100/412], Loss: 0.640
Epoch:22 [110/412], Loss: 0.549
Epoch:22 [120/412], Loss: 0.637
Epoch:22 [130/412], Loss: 0.548
Epoch:22 [140/412], Loss: 0.827
Epoch:22 [150/412], Loss: 0.728
Epoch:22 [160/412], Loss: 0.777
Epoch:22 [170/412], Loss: 0.571
Epoch:22 [180/412], Loss: 0.677
Epoch:22 [190/412], Loss: 0.613
Epoch:22 [200/412], Loss: 0.935
Epoch:22 [210/412], Loss: 0.654
Epoch:22 [220/412], Loss: 0.517
Epoch:22 [230/412], Loss: 0.785
Epoch:22 [240/412], Loss: 0.731
Epoch:22 [250/412], Loss: 0.514
Epoch:22 [260/412], Loss: 0.556
Epoch:22 [270/412], Loss: 0.640
Epoch:22 [280/412], Loss: 0.683
Epoch:22 [290/412], Loss: 0.520
Epoch:22 [300/412], Loss: 0.530
Epoch:22 [310/412], Loss: 0.577
Epoch:22 [320/412], Loss: 0.580
Epoch:22 [330/412], Loss: 0.654
Epoch:22 [340/412], Loss: 0.658
Epoch:22 [350/412], Loss: 0.658
Epoch:22 [360/412], Loss: 0.496
Epoch:22 [370/412], Loss: 0.542
Epoch:22 [380/412], Loss: 0.608
Epoch:22 [390/412], Loss: 0.475
Epoch:22 [400/412], Loss: 0.568
Epoch:22 [410/412], Loss: 0.525
Epoch:22, Train IoU: [0.99071652 0.9239909  0.93340835]
Epoch:22, Valid Loss: 0.496, mIoU: 0.9579285397349865
Validation metric decreased (0.549983 --> 0.496000).  Saving model ...
Epoch:23 [0/412], Loss: 0.547
Epoch:23 [10/412], Loss: 0.527
Epoch:23 [20/412], Loss: 0.627
Epoch:23 [30/412], Loss: 0.913
Epoch:23 [40/412], Loss: 0.598
Epoch:23 [50/412], Loss: 0.492
Epoch:23 [60/412], Loss: 0.580
Epoch:23 [70/412], Loss: 0.625
Epoch:23 [80/412], Loss: 0.811
Epoch:23 [90/412], Loss: 0.892
Epoch:23 [100/412], Loss: 0.757
Epoch:23 [110/412], Loss: 0.652
Epoch:23 [120/412], Loss: 0.543
Epoch:23 [130/412], Loss: 0.466
Epoch:23 [140/412], Loss: 0.476
Epoch:23 [150/412], Loss: 0.617
Epoch:23 [160/412], Loss: 0.585
Epoch:23 [170/412], Loss: 0.530
Epoch:23 [180/412], Loss: 0.568
Epoch:23 [190/412], Loss: 0.703
Epoch:23 [200/412], Loss: 0.657
Epoch:23 [210/412], Loss: 0.565
Epoch:23 [220/412], Loss: 0.653
Epoch:23 [230/412], Loss: 0.584
Epoch:23 [240/412], Loss: 0.623
Epoch:23 [250/412], Loss: 0.558
Epoch:23 [260/412], Loss: 0.555
Epoch:23 [270/412], Loss: 0.513
Epoch:23 [280/412], Loss: 0.561
Epoch:23 [290/412], Loss: 0.563
Epoch:23 [300/412], Loss: 0.565
Epoch:23 [310/412], Loss: 0.488
Epoch:23 [320/412], Loss: 0.643
Epoch:23 [330/412], Loss: 0.610
Epoch:23 [340/412], Loss: 0.468
Epoch:23 [350/412], Loss: 0.487
Epoch:23 [360/412], Loss: 0.674
Epoch:23 [370/412], Loss: 0.798
Epoch:23 [380/412], Loss: 0.566
Epoch:23 [390/412], Loss: 0.535
Epoch:23 [400/412], Loss: 0.502
Epoch:23 [410/412], Loss: 0.531
Epoch:23, Train IoU: [0.99088828 0.92611912 0.93547059]
Epoch:23, Valid Loss: 0.532, mIoU: 0.9531953329634707
EarlyStopping counter: 1 out of 100
Epoch:24 [0/412], Loss: 0.592
Epoch:24 [10/412], Loss: 0.577
Epoch:24 [20/412], Loss: 0.826
Epoch:24 [30/412], Loss: 0.589
Epoch:24 [40/412], Loss: 0.546
Epoch:24 [50/412], Loss: 0.592
Epoch:24 [60/412], Loss: 0.652
Epoch:24 [70/412], Loss: 0.533
Epoch:24 [80/412], Loss: 0.499
Epoch:24 [90/412], Loss: 0.618
Epoch:24 [100/412], Loss: 0.583
Epoch:24 [110/412], Loss: 0.502
Epoch:24 [120/412], Loss: 0.557
Epoch:24 [130/412], Loss: 0.451
Epoch:24 [140/412], Loss: 0.585
Epoch:24 [150/412], Loss: 0.816
Epoch:24 [160/412], Loss: 0.477
Epoch:24 [170/412], Loss: 0.759
Epoch:24 [180/412], Loss: 0.806
Epoch:24 [190/412], Loss: 0.623
Epoch:24 [200/412], Loss: 0.566
Epoch:24 [210/412], Loss: 0.560
Epoch:24 [220/412], Loss: 0.562
Epoch:24 [230/412], Loss: 0.482
Epoch:24 [240/412], Loss: 0.642
Epoch:24 [250/412], Loss: 0.599
Epoch:24 [260/412], Loss: 0.630
Epoch:24 [270/412], Loss: 0.516
Epoch:24 [280/412], Loss: 0.873
Epoch:24 [290/412], Loss: 0.825
Epoch:24 [300/412], Loss: 0.580
Epoch:24 [310/412], Loss: 0.571
Epoch:24 [320/412], Loss: 0.552
Epoch:24 [330/412], Loss: 0.494
Epoch:24 [340/412], Loss: 0.517
Epoch:24 [350/412], Loss: 0.606
Epoch:24 [360/412], Loss: 0.423
Epoch:24 [370/412], Loss: 0.491
Epoch:24 [380/412], Loss: 0.572
Epoch:24 [390/412], Loss: 0.649
Epoch:24 [400/412], Loss: 0.536
Epoch:24 [410/412], Loss: 0.602
Epoch:24, Train IoU: [0.99088239 0.92609668 0.93487033]
Epoch:24, Valid Loss: 0.450, mIoU: 0.9593995103879162
Validation metric decreased (0.496000 --> 0.450378).  Saving model ...
Epoch:25 [0/412], Loss: 0.562
Epoch:25 [10/412], Loss: 0.517
Epoch:25 [20/412], Loss: 0.568
Epoch:25 [30/412], Loss: 0.609
Epoch:25 [40/412], Loss: 0.485
Epoch:25 [50/412], Loss: 0.433
Epoch:25 [60/412], Loss: 0.553
Epoch:25 [70/412], Loss: 0.664
Epoch:25 [80/412], Loss: 0.463
Epoch:25 [90/412], Loss: 0.513
Epoch:25 [100/412], Loss: 0.515
Epoch:25 [110/412], Loss: 0.571
Epoch:25 [120/412], Loss: 0.400
Epoch:25 [130/412], Loss: 0.523
Epoch:25 [140/412], Loss: 0.648
Epoch:25 [150/412], Loss: 0.534
Epoch:25 [160/412], Loss: 0.590
Epoch:25 [170/412], Loss: 0.453
Epoch:25 [180/412], Loss: 0.493
Epoch:25 [190/412], Loss: 0.438
Epoch:25 [200/412], Loss: 0.537
Epoch:25 [210/412], Loss: 0.437
Epoch:25 [220/412], Loss: 0.758
Epoch:25 [230/412], Loss: 0.527
Epoch:25 [240/412], Loss: 0.672
Epoch:25 [250/412], Loss: 0.493
Epoch:25 [260/412], Loss: 0.447
Epoch:25 [270/412], Loss: 0.434
Epoch:25 [280/412], Loss: 0.579
Epoch:25 [290/412], Loss: 0.543
Epoch:25 [300/412], Loss: 0.541
Epoch:25 [310/412], Loss: 1.338
Epoch:25 [320/412], Loss: 0.595
Epoch:25 [330/412], Loss: 0.547
Epoch:25 [340/412], Loss: 0.462
Epoch:25 [350/412], Loss: 0.455
Epoch:25 [360/412], Loss: 0.498
Epoch:25 [370/412], Loss: 0.744
Epoch:25 [380/412], Loss: 0.758
Epoch:25 [390/412], Loss: 0.535
Epoch:25 [400/412], Loss: 0.482
Epoch:25 [410/412], Loss: 0.341
Epoch:25, Train IoU: [0.99122683 0.92931919 0.9364039 ]
Epoch:25, Valid Loss: 0.494, mIoU: 0.9560885507675997
EarlyStopping counter: 1 out of 100
Epoch:26 [0/412], Loss: 0.465
Epoch:26 [10/412], Loss: 0.514
Epoch:26 [20/412], Loss: 0.478
Epoch:26 [30/412], Loss: 0.525
Epoch:26 [40/412], Loss: 0.549
Epoch:26 [50/412], Loss: 0.458
Epoch:26 [60/412], Loss: 0.434
Epoch:26 [70/412], Loss: 0.364
Epoch:26 [80/412], Loss: 0.448
Epoch:26 [90/412], Loss: 0.610
Epoch:26 [100/412], Loss: 0.435
Epoch:26 [110/412], Loss: 0.528
Epoch:26 [120/412], Loss: 0.500
Epoch:26 [130/412], Loss: 0.394
Epoch:26 [140/412], Loss: 0.536
Epoch:26 [150/412], Loss: 0.495
Epoch:26 [160/412], Loss: 0.463
Epoch:26 [170/412], Loss: 0.621
Epoch:26 [180/412], Loss: 0.590
Epoch:26 [190/412], Loss: 0.492
Epoch:26 [200/412], Loss: 0.429
Epoch:26 [210/412], Loss: 0.436
Epoch:26 [220/412], Loss: 0.411
Epoch:26 [230/412], Loss: 0.507
Epoch:26 [240/412], Loss: 0.539
Epoch:26 [250/412], Loss: 0.500
Epoch:26 [260/412], Loss: 0.468
Epoch:26 [270/412], Loss: 0.481
Epoch:26 [280/412], Loss: 0.516
Epoch:26 [290/412], Loss: 0.604
Epoch:26 [300/412], Loss: 0.532
Epoch:26 [310/412], Loss: 0.463
Epoch:26 [320/412], Loss: 0.508
Epoch:26 [330/412], Loss: 0.424
Epoch:26 [340/412], Loss: 0.471
Epoch:26 [350/412], Loss: 0.571
Epoch:26 [360/412], Loss: 0.660
Epoch:26 [370/412], Loss: 0.449
Epoch:26 [380/412], Loss: 0.647
Epoch:26 [390/412], Loss: 0.395
Epoch:26 [400/412], Loss: 0.540
Epoch:26 [410/412], Loss: 0.869
Epoch:26, Train IoU: [0.99151321 0.93252555 0.93823352]
Epoch:26, Valid Loss: 0.468, mIoU: 0.9614755794529858
EarlyStopping counter: 2 out of 100
Epoch:27 [0/412], Loss: 0.590
Epoch:27 [10/412], Loss: 0.568
Epoch:27 [20/412], Loss: 0.536
Epoch:27 [30/412], Loss: 0.414
Epoch:27 [40/412], Loss: 0.506
Epoch:27 [50/412], Loss: 0.486
Epoch:27 [60/412], Loss: 0.418
Epoch:27 [70/412], Loss: 0.358
Epoch:27 [80/412], Loss: 0.371
Epoch:27 [90/412], Loss: 0.488
Epoch:27 [100/412], Loss: 0.450
Epoch:27 [110/412], Loss: 0.653
Epoch:27 [120/412], Loss: 0.602
Epoch:27 [130/412], Loss: 0.497
Epoch:27 [140/412], Loss: 0.720
Epoch:27 [150/412], Loss: 0.624
Epoch:27 [160/412], Loss: 0.476
Epoch:27 [170/412], Loss: 0.658
Epoch:27 [180/412], Loss: 0.764
Epoch:27 [190/412], Loss: 0.524
Epoch:27 [200/412], Loss: 0.580
Epoch:27 [210/412], Loss: 0.825
Epoch:27 [220/412], Loss: 0.445
Epoch:27 [230/412], Loss: 0.494
Epoch:27 [240/412], Loss: 0.767
Epoch:27 [250/412], Loss: 0.454
Epoch:27 [260/412], Loss: 0.613
Epoch:27 [270/412], Loss: 0.493
Epoch:27 [280/412], Loss: 0.408
Epoch:27 [290/412], Loss: 0.794
Epoch:27 [300/412], Loss: 0.406
Epoch:27 [310/412], Loss: 0.443
Epoch:27 [320/412], Loss: 0.450
Epoch:27 [330/412], Loss: 0.663
Epoch:27 [340/412], Loss: 0.487
Epoch:27 [350/412], Loss: 0.584
Epoch:27 [360/412], Loss: 0.616
Epoch:27 [370/412], Loss: 0.469
Epoch:27 [380/412], Loss: 0.431
Epoch:27 [390/412], Loss: 0.717
Epoch:27 [400/412], Loss: 0.439
Epoch:27 [410/412], Loss: 0.542
Epoch:27, Train IoU: [0.99111009 0.92827923 0.9341198 ]
Epoch:27, Valid Loss: 0.389, mIoU: 0.9593149906870049
Validation metric decreased (0.450378 --> 0.389297).  Saving model ...
Epoch:28 [0/412], Loss: 0.463
Epoch:28 [10/412], Loss: 0.356
Epoch:28 [20/412], Loss: 0.437
Epoch:28 [30/412], Loss: 0.476
Epoch:28 [40/412], Loss: 0.341
Epoch:28 [50/412], Loss: 0.437
Epoch:28 [60/412], Loss: 0.441
Epoch:28 [70/412], Loss: 0.472
Epoch:28 [80/412], Loss: 0.409
Epoch:28 [90/412], Loss: 0.365
Epoch:28 [100/412], Loss: 0.501
Epoch:28 [110/412], Loss: 0.426
Epoch:28 [120/412], Loss: 0.392
Epoch:28 [130/412], Loss: 0.643
Epoch:28 [140/412], Loss: 0.429
Epoch:28 [150/412], Loss: 0.513
Epoch:28 [160/412], Loss: 0.553
Epoch:28 [170/412], Loss: 0.391
Epoch:28 [180/412], Loss: 0.398
Epoch:28 [190/412], Loss: 0.434
Epoch:28 [200/412], Loss: 0.420
Epoch:28 [210/412], Loss: 0.399
Epoch:28 [220/412], Loss: 0.537
Epoch:28 [230/412], Loss: 0.344
Epoch:28 [240/412], Loss: 0.422
Epoch:28 [250/412], Loss: 0.569
Epoch:28 [260/412], Loss: 0.498
Epoch:28 [270/412], Loss: 0.561
Epoch:28 [280/412], Loss: 0.415
Epoch:28 [290/412], Loss: 0.708
Epoch:28 [300/412], Loss: 0.407
Epoch:28 [310/412], Loss: 0.486
Epoch:28 [320/412], Loss: 0.350
Epoch:28 [330/412], Loss: 0.420
Epoch:28 [340/412], Loss: 0.305
Epoch:28 [350/412], Loss: 0.915
Epoch:28 [360/412], Loss: 0.419
Epoch:28 [370/412], Loss: 0.378
Epoch:28 [380/412], Loss: 0.419
Epoch:28 [390/412], Loss: 0.452
Epoch:28 [400/412], Loss: 0.476
Epoch:28 [410/412], Loss: 0.409
Epoch:28, Train IoU: [0.99149318 0.93223394 0.93708569]
Epoch:28, Valid Loss: 0.416, mIoU: 0.9578955582159668
EarlyStopping counter: 1 out of 100
Epoch:29 [0/412], Loss: 0.476
Epoch:29 [10/412], Loss: 0.360
Epoch:29 [20/412], Loss: 0.431
Epoch:29 [30/412], Loss: 0.485
Epoch:29 [40/412], Loss: 0.400
Epoch:29 [50/412], Loss: 0.442
Epoch:29 [60/412], Loss: 0.504
Epoch:29 [70/412], Loss: 0.466
Epoch:29 [80/412], Loss: 0.414
Epoch:29 [90/412], Loss: 0.437
Epoch:29 [100/412], Loss: 0.315
Epoch:29 [110/412], Loss: 0.453
Epoch:29 [120/412], Loss: 0.581
Epoch:29 [130/412], Loss: 0.331
Epoch:29 [140/412], Loss: 0.446
Epoch:29 [150/412], Loss: 0.339
Epoch:29 [160/412], Loss: 0.316
Epoch:29 [170/412], Loss: 0.411
Epoch:29 [180/412], Loss: 0.475
Epoch:29 [190/412], Loss: 0.485
Epoch:29 [200/412], Loss: 0.388
Epoch:29 [210/412], Loss: 0.384
Epoch:29 [220/412], Loss: 0.347
Epoch:29 [230/412], Loss: 0.379
Epoch:29 [240/412], Loss: 0.433
Epoch:29 [250/412], Loss: 0.591
Epoch:29 [260/412], Loss: 0.379
Epoch:29 [270/412], Loss: 0.797
Epoch:29 [280/412], Loss: 0.364
Epoch:29 [290/412], Loss: 0.484
Epoch:29 [300/412], Loss: 0.388
Epoch:29 [310/412], Loss: 0.476
Epoch:29 [320/412], Loss: 0.435
Epoch:29 [330/412], Loss: 0.756
Epoch:29 [340/412], Loss: 0.340
Epoch:29 [350/412], Loss: 0.458
Epoch:29 [360/412], Loss: 0.525
Epoch:29 [370/412], Loss: 0.382
Epoch:29 [380/412], Loss: 0.436
Epoch:29 [390/412], Loss: 0.484
Epoch:29 [400/412], Loss: 0.461
Epoch:29 [410/412], Loss: 0.487
Epoch:29, Train IoU: [0.99186396 0.93605093 0.94086601]
Epoch:29, Valid Loss: 0.354, mIoU: 0.9627112695350339
Validation metric decreased (0.389297 --> 0.353553).  Saving model ...
Epoch:30 [0/412], Loss: 0.460
Epoch:30 [10/412], Loss: 0.551
Epoch:30 [20/412], Loss: 0.343
Epoch:30 [30/412], Loss: 0.527
Epoch:30 [40/412], Loss: 0.387
Epoch:30 [50/412], Loss: 0.473
Epoch:30 [60/412], Loss: 0.372
Epoch:30 [70/412], Loss: 0.472
Epoch:30 [80/412], Loss: 0.526
Epoch:30 [90/412], Loss: 0.485
Epoch:30 [100/412], Loss: 0.416
Epoch:30 [110/412], Loss: 0.591
Epoch:30 [120/412], Loss: 0.377
Epoch:30 [130/412], Loss: 0.488
Epoch:30 [140/412], Loss: 0.552
Epoch:30 [150/412], Loss: 0.279
Epoch:30 [160/412], Loss: 0.351
Epoch:30 [170/412], Loss: 0.377
Epoch:30 [180/412], Loss: 0.402
Epoch:30 [190/412], Loss: 0.400
Epoch:30 [200/412], Loss: 0.550
Epoch:30 [210/412], Loss: 0.345
Epoch:30 [220/412], Loss: 0.360
Epoch:30 [230/412], Loss: 0.414
Epoch:30 [240/412], Loss: 0.358
Epoch:30 [250/412], Loss: 0.390
Epoch:30 [260/412], Loss: 0.338
Epoch:30 [270/412], Loss: 0.380
Epoch:30 [280/412], Loss: 0.350
Epoch:30 [290/412], Loss: 0.300
Epoch:30 [300/412], Loss: 0.374
Epoch:30 [310/412], Loss: 0.285
Epoch:30 [320/412], Loss: 0.591
Epoch:30 [330/412], Loss: 0.490
Epoch:30 [340/412], Loss: 0.280
Epoch:30 [350/412], Loss: 0.383
Epoch:30 [360/412], Loss: 0.409
Epoch:30 [370/412], Loss: 0.752
Epoch:30 [380/412], Loss: 0.480
Epoch:30 [390/412], Loss: 0.422
Epoch:30 [400/412], Loss: 0.445
Epoch:30 [410/412], Loss: 0.341
Epoch:30, Train IoU: [0.99197588 0.93703482 0.9405978 ]
Epoch:30, Valid Loss: 0.355, mIoU: 0.9631435853675078
Validation metric decreased (0.353553 --> 0.355483).  Saving model ...
Epoch:31 [0/412], Loss: 0.462
Epoch:31 [10/412], Loss: 0.526
Epoch:31 [20/412], Loss: 0.476
Epoch:31 [30/412], Loss: 0.370
Epoch:31 [40/412], Loss: 0.367
Epoch:31 [50/412], Loss: 0.334
Epoch:31 [60/412], Loss: 0.357
Epoch:31 [70/412], Loss: 0.375
Epoch:31 [80/412], Loss: 0.464
Epoch:31 [90/412], Loss: 0.357
Epoch:31 [100/412], Loss: 0.354
Epoch:31 [110/412], Loss: 0.488
Epoch:31 [120/412], Loss: 0.383
Epoch:31 [130/412], Loss: 0.317
Epoch:31 [140/412], Loss: 0.429
Epoch:31 [150/412], Loss: 0.304
Epoch:31 [160/412], Loss: 0.299
Epoch:31 [170/412], Loss: 0.442
Epoch:31 [180/412], Loss: 0.398
Epoch:31 [190/412], Loss: 0.357
Epoch:31 [200/412], Loss: 0.451
Epoch:31 [210/412], Loss: 0.333
Epoch:31 [220/412], Loss: 0.259
Epoch:31 [230/412], Loss: 0.402
Epoch:31 [240/412], Loss: 0.408
Epoch:31 [250/412], Loss: 0.459
Epoch:31 [260/412], Loss: 0.414
Epoch:31 [270/412], Loss: 0.299
Epoch:31 [280/412], Loss: 0.294
Epoch:31 [290/412], Loss: 0.390
Epoch:31 [300/412], Loss: 0.299
Epoch:31 [310/412], Loss: 0.439
Epoch:31 [320/412], Loss: 0.327
Epoch:31 [330/412], Loss: 0.350
Epoch:31 [340/412], Loss: 0.441
Epoch:31 [350/412], Loss: 0.464
Epoch:31 [360/412], Loss: 0.388
Epoch:31 [370/412], Loss: 0.390
Epoch:31 [380/412], Loss: 0.299
Epoch:31 [390/412], Loss: 0.277
Epoch:31 [400/412], Loss: 0.329
Epoch:31 [410/412], Loss: 0.613
Epoch:31, Train IoU: [0.99213173 0.93853904 0.94221717]
Epoch:31, Valid Loss: 0.301, mIoU: 0.9640361613854703
Validation metric decreased (0.355483 --> 0.301438).  Saving model ...
Epoch:32 [0/412], Loss: 0.375
Epoch:32 [10/412], Loss: 0.342
Epoch:32 [20/412], Loss: 0.330
Epoch:32 [30/412], Loss: 0.277
Epoch:32 [40/412], Loss: 0.445
Epoch:32 [50/412], Loss: 0.391
Epoch:32 [60/412], Loss: 0.347
Epoch:32 [70/412], Loss: 0.418
Epoch:32 [80/412], Loss: 0.322
Epoch:32 [90/412], Loss: 0.421
Epoch:32 [100/412], Loss: 0.346
Epoch:32 [110/412], Loss: 0.431
Epoch:32 [120/412], Loss: 0.196
Epoch:32 [130/412], Loss: 0.604
Epoch:32 [140/412], Loss: 0.466
Epoch:32 [150/412], Loss: 0.278
Epoch:32 [160/412], Loss: 0.338
Epoch:32 [170/412], Loss: 0.299
Epoch:32 [180/412], Loss: 0.245
Epoch:32 [190/412], Loss: 0.401
Epoch:32 [200/412], Loss: 0.348
Epoch:32 [210/412], Loss: 0.326
Epoch:32 [220/412], Loss: 0.460
Epoch:32 [230/412], Loss: 0.429
Epoch:32 [240/412], Loss: 0.378
Epoch:32 [250/412], Loss: 0.601
Epoch:32 [260/412], Loss: 0.483
Epoch:32 [270/412], Loss: 0.332
Epoch:32 [280/412], Loss: 0.412
Epoch:32 [290/412], Loss: 0.291
Epoch:32 [300/412], Loss: 0.340
Epoch:32 [310/412], Loss: 0.384
Epoch:32 [320/412], Loss: 0.357
Epoch:32 [330/412], Loss: 0.359
Epoch:32 [340/412], Loss: 0.295
Epoch:32 [350/412], Loss: 0.250
Epoch:32 [360/412], Loss: 0.331
Epoch:32 [370/412], Loss: 0.379
Epoch:32 [380/412], Loss: 0.320
Epoch:32 [390/412], Loss: 0.283
Epoch:32 [400/412], Loss: 0.320
Epoch:32 [410/412], Loss: 0.272
Epoch:32, Train IoU: [0.99210675 0.93837983 0.94189807]
Epoch:32, Valid Loss: 0.293, mIoU: 0.9641409061616746
Validation metric decreased (0.301438 --> 0.293249).  Saving model ...
Epoch:33 [0/412], Loss: 0.384
Epoch:33 [10/412], Loss: 0.360
Epoch:33 [20/412], Loss: 0.449
Epoch:33 [30/412], Loss: 0.336
Epoch:33 [40/412], Loss: 0.296
Epoch:33 [50/412], Loss: 0.326
Epoch:33 [60/412], Loss: 0.341
Epoch:33 [70/412], Loss: 0.278
Epoch:33 [80/412], Loss: 0.265
Epoch:33 [90/412], Loss: 0.299
Epoch:33 [100/412], Loss: 0.475
Epoch:33 [110/412], Loss: 0.328
Epoch:33 [120/412], Loss: 0.228
Epoch:33 [130/412], Loss: 0.237
Epoch:33 [140/412], Loss: 0.314
Epoch:33 [150/412], Loss: 0.248
Epoch:33 [160/412], Loss: 0.393
Epoch:33 [170/412], Loss: 0.382
Epoch:33 [180/412], Loss: 0.316
Epoch:33 [190/412], Loss: 0.259
Epoch:33 [200/412], Loss: 0.403
Epoch:33 [210/412], Loss: 0.461
Epoch:33 [220/412], Loss: 0.380
Epoch:33 [230/412], Loss: 0.306
Epoch:33 [240/412], Loss: 0.353
Epoch:33 [250/412], Loss: 0.363
Epoch:33 [260/412], Loss: 0.386
Epoch:33 [270/412], Loss: 0.253
Epoch:33 [280/412], Loss: 0.317
Epoch:33 [290/412], Loss: 0.294
Epoch:33 [300/412], Loss: 0.328
Epoch:33 [310/412], Loss: 0.349
Epoch:33 [320/412], Loss: 0.508
Epoch:33 [330/412], Loss: 0.307
Epoch:33 [340/412], Loss: 0.275
Epoch:33 [350/412], Loss: 0.315
Epoch:33 [360/412], Loss: 0.510
Epoch:33 [370/412], Loss: 0.340
Epoch:33 [380/412], Loss: 0.290
Epoch:33 [390/412], Loss: 0.291
Epoch:33 [400/412], Loss: 0.405
Epoch:33 [410/412], Loss: 0.329
Epoch:33, Train IoU: [0.99239792 0.94139216 0.94504081]
Epoch:33, Valid Loss: 0.261, mIoU: 0.9654602209292934
Validation metric decreased (0.293249 --> 0.261360).  Saving model ...
Epoch:34 [0/412], Loss: 0.450
Epoch:34 [10/412], Loss: 0.333
Epoch:34 [20/412], Loss: 0.405
Epoch:34 [30/412], Loss: 0.358
Epoch:34 [40/412], Loss: 0.321
Epoch:34 [50/412], Loss: 0.263
Epoch:34 [60/412], Loss: 0.347
Epoch:34 [70/412], Loss: 0.259
Epoch:34 [80/412], Loss: 0.330
Epoch:34 [90/412], Loss: 0.246
Epoch:34 [100/412], Loss: 0.373
Epoch:34 [110/412], Loss: 0.567
Epoch:34 [120/412], Loss: 0.251
Epoch:34 [130/412], Loss: 0.319
Epoch:34 [140/412], Loss: 0.472
Epoch:34 [150/412], Loss: 0.300
Epoch:34 [160/412], Loss: 0.272
Epoch:34 [170/412], Loss: 0.231
Epoch:34 [180/412], Loss: 0.379
Epoch:34 [190/412], Loss: 0.277
Epoch:34 [200/412], Loss: 0.279
Epoch:34 [210/412], Loss: 0.353
Epoch:34 [220/412], Loss: 0.255
Epoch:34 [230/412], Loss: 0.306
Epoch:34 [240/412], Loss: 0.310
Epoch:34 [250/412], Loss: 0.249
Epoch:34 [260/412], Loss: 0.241
Epoch:34 [270/412], Loss: 0.434
Epoch:34 [280/412], Loss: 0.315
Epoch:34 [290/412], Loss: 0.304
Epoch:34 [300/412], Loss: 0.371
Epoch:34 [310/412], Loss: 0.234
Epoch:34 [320/412], Loss: 0.367
Epoch:34 [330/412], Loss: 0.452
Epoch:34 [340/412], Loss: 0.216
Epoch:34 [350/412], Loss: 0.333
Epoch:34 [360/412], Loss: 0.321
Epoch:34 [370/412], Loss: 0.276
Epoch:34 [380/412], Loss: 0.331
Epoch:34 [390/412], Loss: 0.268
Epoch:34 [400/412], Loss: 0.290
Epoch:34 [410/412], Loss: 0.347
Epoch:34, Train IoU: [0.99242101 0.94186865 0.94424501]
Epoch:34, Valid Loss: 0.264, mIoU: 0.9650008469079352
Validation metric decreased (0.261360 --> 0.264443).  Saving model ...
Epoch:35 [0/412], Loss: 0.264
Epoch:35 [10/412], Loss: 0.306
Epoch:35 [20/412], Loss: 0.352
Epoch:35 [30/412], Loss: 0.385
Epoch:35 [40/412], Loss: 0.445
Epoch:35 [50/412], Loss: 0.338
Epoch:35 [60/412], Loss: 0.339
Epoch:35 [70/412], Loss: 0.329
Epoch:35 [80/412], Loss: 0.353
Epoch:35 [90/412], Loss: 0.202
Epoch:35 [100/412], Loss: 0.508
Epoch:35 [110/412], Loss: 0.255
Epoch:35 [120/412], Loss: 0.252
Epoch:35 [130/412], Loss: 0.513
Epoch:35 [140/412], Loss: 0.322
Epoch:35 [150/412], Loss: 0.313
Epoch:35 [160/412], Loss: 0.283
Epoch:35 [170/412], Loss: 0.256
Epoch:35 [180/412], Loss: 0.394
Epoch:35 [190/412], Loss: 0.424
Epoch:35 [200/412], Loss: 0.221
Epoch:35 [210/412], Loss: 0.268
Epoch:35 [220/412], Loss: 0.303
Epoch:35 [230/412], Loss: 0.342
Epoch:35 [240/412], Loss: 0.421
Epoch:35 [250/412], Loss: 0.303
Epoch:35 [260/412], Loss: 0.651
Epoch:35 [270/412], Loss: 0.320
Epoch:35 [280/412], Loss: 0.294
Epoch:35 [290/412], Loss: 0.408
Epoch:35 [300/412], Loss: 0.238
Epoch:35 [310/412], Loss: 0.316
Epoch:35 [320/412], Loss: 0.362
Epoch:35 [330/412], Loss: 0.332
Epoch:35 [340/412], Loss: 0.348
Epoch:35 [350/412], Loss: 0.279
Epoch:35 [360/412], Loss: 0.308
Epoch:35 [370/412], Loss: 0.251
Epoch:35 [380/412], Loss: 0.341
Epoch:35 [390/412], Loss: 0.252
Epoch:35 [400/412], Loss: 0.294
Epoch:35 [410/412], Loss: 0.263
Epoch:35, Train IoU: [0.99232838 0.94062359 0.94196333]
Epoch:35, Valid Loss: 0.335, mIoU: 0.9592115933003429
EarlyStopping counter: 1 out of 100
Epoch:36 [0/412], Loss: 0.382
Epoch:36 [10/412], Loss: 0.392
Epoch:36 [20/412], Loss: 0.206
Epoch:36 [30/412], Loss: 0.227
Epoch:36 [40/412], Loss: 0.283
Epoch:36 [50/412], Loss: 0.271
Epoch:36 [60/412], Loss: 0.251
Epoch:36 [70/412], Loss: 0.347
Epoch:36 [80/412], Loss: 0.320
Epoch:36 [90/412], Loss: 0.390
Epoch:36 [100/412], Loss: 0.312
Epoch:36 [110/412], Loss: 0.237
Epoch:36 [120/412], Loss: 0.311
Epoch:36 [130/412], Loss: 0.345
Epoch:36 [140/412], Loss: 0.280
Epoch:36 [150/412], Loss: 0.296
Epoch:36 [160/412], Loss: 0.211
Epoch:36 [170/412], Loss: 0.360
Epoch:36 [180/412], Loss: 0.364
Epoch:36 [190/412], Loss: 0.419
Epoch:36 [200/412], Loss: 0.210
Epoch:36 [210/412], Loss: 0.391
Epoch:36 [220/412], Loss: 0.554
Epoch:36 [230/412], Loss: 3.522
Epoch:36 [240/412], Loss: 21.405
Epoch:36 [250/412], Loss: 22.042
Epoch:36 [260/412], Loss: 214.793
Epoch:36 [270/412], Loss: 136.472
Epoch:36 [280/412], Loss: 36.115
Epoch:36 [290/412], Loss: 12.450
Epoch:36 [300/412], Loss: 9.338
Epoch:36 [310/412], Loss: 7.324
Epoch:36 [320/412], Loss: 7.045
Epoch:36 [330/412], Loss: 5.676
Epoch:36 [340/412], Loss: 5.602
Epoch:36 [350/412], Loss: 5.214
Epoch:36 [360/412], Loss: 4.926
Epoch:36 [370/412], Loss: 3.669
Epoch:36 [380/412], Loss: 3.872
Epoch:36 [390/412], Loss: 3.840
Epoch:36 [400/412], Loss: 3.627
Epoch:36 [410/412], Loss: 3.836
Epoch:36, Train IoU: [0.94032033 0.63240522 0.69794481]
Epoch:36, Valid Loss: 2.990, mIoU: 0.7740321298217306
EarlyStopping counter: 2 out of 100
Epoch:37 [0/412], Loss: 3.636
Epoch:37 [10/412], Loss: 2.921
Epoch:37 [20/412], Loss: 2.971
Epoch:37 [30/412], Loss: 3.263
Epoch:37 [40/412], Loss: 3.591
Epoch:37 [50/412], Loss: 2.726
Epoch:37 [60/412], Loss: 2.918
Epoch:37 [70/412], Loss: 2.492
Epoch:37 [80/412], Loss: 2.870
Epoch:37 [90/412], Loss: 2.512
Epoch:37 [100/412], Loss: 2.606
Epoch:37 [110/412], Loss: 2.971
Epoch:37 [120/412], Loss: 2.318
Epoch:37 [130/412], Loss: 2.358
Epoch:37 [140/412], Loss: 2.244
Epoch:37 [150/412], Loss: 2.198
Epoch:37 [160/412], Loss: 2.115
Epoch:37 [170/412], Loss: 1.721
Epoch:37 [180/412], Loss: 2.139
Epoch:37 [190/412], Loss: 2.500
Epoch:37 [200/412], Loss: 2.488
Epoch:37 [210/412], Loss: 3.174
Epoch:37 [220/412], Loss: 2.002
Epoch:37 [230/412], Loss: 2.041
Epoch:37 [240/412], Loss: 2.107
Epoch:37 [250/412], Loss: 2.220
Epoch:37 [260/412], Loss: 2.260
Epoch:37 [270/412], Loss: 2.294
Epoch:37 [280/412], Loss: 2.463
Epoch:37 [290/412], Loss: 1.653
Epoch:37 [300/412], Loss: 2.254
Epoch:37 [310/412], Loss: 2.265
Epoch:37 [320/412], Loss: 2.334
Epoch:37 [330/412], Loss: 1.811
Epoch:37 [340/412], Loss: 1.947
Epoch:37 [350/412], Loss: 2.080
Epoch:37 [360/412], Loss: 1.991
Epoch:37 [370/412], Loss: 2.089
Epoch:37 [380/412], Loss: 1.566
Epoch:37 [390/412], Loss: 1.923
Epoch:37 [400/412], Loss: 1.885
Epoch:37 [410/412], Loss: 1.569
Epoch:37, Train IoU: [0.95996232 0.70970833 0.78325494]
Epoch:37, Valid Loss: 1.413, mIoU: 0.8835693682030251
EarlyStopping counter: 3 out of 100
Epoch:38 [0/412], Loss: 1.492
Epoch:38 [10/412], Loss: 1.693
Epoch:38 [20/412], Loss: 1.956
Epoch:38 [30/412], Loss: 1.794
Epoch:38 [40/412], Loss: 1.907
Epoch:38 [50/412], Loss: 1.597
Epoch:38 [60/412], Loss: 1.792
Epoch:38 [70/412], Loss: 1.636
Epoch:38 [80/412], Loss: 1.721
Epoch:38 [90/412], Loss: 1.942
Epoch:38 [100/412], Loss: 1.911
Epoch:38 [110/412], Loss: 1.676
Epoch:38 [120/412], Loss: 1.990
Epoch:38 [130/412], Loss: 1.561
Epoch:38 [140/412], Loss: 1.417
Epoch:38 [150/412], Loss: 1.699
Epoch:38 [160/412], Loss: 1.888
Epoch:38 [170/412], Loss: 1.485
Epoch:38 [180/412], Loss: 1.345
Epoch:38 [190/412], Loss: 1.881
Epoch:38 [200/412], Loss: 1.636
Epoch:38 [210/412], Loss: 1.575
Epoch:38 [220/412], Loss: 1.501
Epoch:38 [230/412], Loss: 1.840
Epoch:38 [240/412], Loss: 1.240
Epoch:38 [250/412], Loss: 1.367
Epoch:38 [260/412], Loss: 1.585
Epoch:38 [270/412], Loss: 1.157
Epoch:38 [280/412], Loss: 1.395
Epoch:38 [290/412], Loss: 1.139
Epoch:38 [300/412], Loss: 1.460
Epoch:38 [310/412], Loss: 1.218
Epoch:38 [320/412], Loss: 1.261
Epoch:38 [330/412], Loss: 1.307
Epoch:38 [340/412], Loss: 1.247
Epoch:38 [350/412], Loss: 1.615
Epoch:38 [360/412], Loss: 1.589
Epoch:38 [370/412], Loss: 1.233
Epoch:38 [380/412], Loss: 1.726
Epoch:38 [390/412], Loss: 1.436
Epoch:38 [400/412], Loss: 1.583
Epoch:38 [410/412], Loss: 1.144
Epoch:38, Train IoU: [0.97325203 0.79588131 0.84551844]
Epoch:38, Valid Loss: 1.095, mIoU: 0.9070989154635717
EarlyStopping counter: 4 out of 100
Epoch:39 [0/412], Loss: 1.297
Epoch:39 [10/412], Loss: 1.004
Epoch:39 [20/412], Loss: 1.905
Epoch:39 [30/412], Loss: 1.223
Epoch:39 [40/412], Loss: 1.545
Epoch:39 [50/412], Loss: 1.293
Epoch:39 [60/412], Loss: 1.524
Epoch:39 [70/412], Loss: 1.610
Epoch:39 [80/412], Loss: 1.541
Epoch:39 [90/412], Loss: 1.643
Epoch:39 [100/412], Loss: 1.227
Epoch:39 [110/412], Loss: 1.320
Epoch:39 [120/412], Loss: 1.522
Epoch:39 [130/412], Loss: 1.443
Epoch:39 [140/412], Loss: 1.579
Epoch:39 [150/412], Loss: 0.948
Epoch:39 [160/412], Loss: 1.132
Epoch:39 [170/412], Loss: 1.082
Epoch:39 [180/412], Loss: 1.224
Epoch:39 [190/412], Loss: 1.188
Epoch:39 [200/412], Loss: 1.058
Epoch:39 [210/412], Loss: 1.384
Epoch:39 [220/412], Loss: 1.256
Epoch:39 [230/412], Loss: 1.100
Epoch:39 [240/412], Loss: 1.186
Epoch:39 [250/412], Loss: 0.887
Epoch:39 [260/412], Loss: 1.030
Epoch:39 [270/412], Loss: 1.269
Epoch:39 [280/412], Loss: 1.205
Epoch:39 [290/412], Loss: 0.983
Epoch:39 [300/412], Loss: 0.916
Epoch:39 [310/412], Loss: 1.278
Epoch:39 [320/412], Loss: 1.267
Epoch:39 [330/412], Loss: 1.077
Epoch:39 [340/412], Loss: 1.340
Epoch:39 [350/412], Loss: 1.195
Epoch:39 [360/412], Loss: 1.119
Epoch:39 [370/412], Loss: 1.215
Epoch:39 [380/412], Loss: 1.461
Epoch:39 [390/412], Loss: 1.112
Epoch:39 [400/412], Loss: 1.145
Epoch:39 [410/412], Loss: 1.135
Epoch:39, Train IoU: [0.97862866 0.829796   0.86684453]
Epoch:39, Valid Loss: 0.875, mIoU: 0.9185835069503808
EarlyStopping counter: 5 out of 100
Epoch:40 [0/412], Loss: 1.010
Epoch:40 [10/412], Loss: 0.968
Epoch:40 [20/412], Loss: 1.021
Epoch:40 [30/412], Loss: 1.005
Epoch:40 [40/412], Loss: 0.895
Epoch:40 [50/412], Loss: 0.960
Epoch:40 [60/412], Loss: 1.056
Epoch:40 [70/412], Loss: 0.800
Epoch:40 [80/412], Loss: 0.994
Epoch:40 [90/412], Loss: 0.846
Epoch:40 [100/412], Loss: 0.967
Epoch:40 [110/412], Loss: 0.980
Epoch:40 [120/412], Loss: 1.210
Epoch:40 [130/412], Loss: 1.042
Epoch:40 [140/412], Loss: 1.177
Epoch:40 [150/412], Loss: 1.075
Epoch:40 [160/412], Loss: 0.907
Epoch:40 [170/412], Loss: 1.024
Epoch:40 [180/412], Loss: 0.988
Epoch:40 [190/412], Loss: 1.233
Epoch:40 [200/412], Loss: 0.880
Epoch:40 [210/412], Loss: 0.965
Epoch:40 [220/412], Loss: 0.990
Epoch:40 [230/412], Loss: 1.073
Epoch:40 [240/412], Loss: 0.941
Epoch:40 [250/412], Loss: 1.186
Epoch:40 [260/412], Loss: 0.934
Epoch:40 [270/412], Loss: 1.032
Epoch:40 [280/412], Loss: 1.019
Epoch:40 [290/412], Loss: 1.032
Epoch:40 [300/412], Loss: 0.889
Epoch:40 [310/412], Loss: 0.901
Epoch:40 [320/412], Loss: 1.102
Epoch:40 [330/412], Loss: 0.981
Epoch:40 [340/412], Loss: 1.050
Epoch:40 [350/412], Loss: 0.996
Epoch:40 [360/412], Loss: 0.967
Epoch:40 [370/412], Loss: 0.757
Epoch:40 [380/412], Loss: 0.798
Epoch:40 [390/412], Loss: 0.962
Epoch:40 [400/412], Loss: 1.215
Epoch:40 [410/412], Loss: 1.145
Epoch:40, Train IoU: [0.98211878 0.85377887 0.8840458 ]
Epoch:40, Valid Loss: 0.797, mIoU: 0.9229140656656168
EarlyStopping counter: 6 out of 100
Epoch:41 [0/412], Loss: 0.893
Epoch:41 [10/412], Loss: 0.904
Epoch:41 [20/412], Loss: 0.910
Epoch:41 [30/412], Loss: 1.167
Epoch:41 [40/412], Loss: 0.653
Epoch:41 [50/412], Loss: 0.859
Epoch:41 [60/412], Loss: 0.971
Epoch:41 [70/412], Loss: 1.063
Epoch:41 [80/412], Loss: 1.311
Epoch:41 [90/412], Loss: 0.954
Epoch:41 [100/412], Loss: 0.894
Epoch:41 [110/412], Loss: 1.034
Epoch:41 [120/412], Loss: 1.045
Epoch:41 [130/412], Loss: 1.023
Epoch:41 [140/412], Loss: 1.260
Epoch:41 [150/412], Loss: 1.064
Epoch:41 [160/412], Loss: 0.982
Epoch:41 [170/412], Loss: 0.791
Epoch:41 [180/412], Loss: 0.978
Epoch:41 [190/412], Loss: 0.878
Epoch:41 [200/412], Loss: 1.209
Epoch:41 [210/412], Loss: 1.035
Epoch:41 [220/412], Loss: 0.898
Epoch:41 [230/412], Loss: 1.080
Epoch:41 [240/412], Loss: 0.749
Epoch:41 [250/412], Loss: 1.099
Epoch:41 [260/412], Loss: 0.856
Epoch:41 [270/412], Loss: 0.914
Epoch:41 [280/412], Loss: 1.064
Epoch:41 [290/412], Loss: 0.812
Epoch:41 [300/412], Loss: 0.940
Epoch:41 [310/412], Loss: 0.826
Epoch:41 [320/412], Loss: 0.891
Epoch:41 [330/412], Loss: 0.957
Epoch:41 [340/412], Loss: 0.911
Epoch:41 [350/412], Loss: 0.953
Epoch:41 [360/412], Loss: 1.486
Epoch:41 [370/412], Loss: 0.872
Epoch:41 [380/412], Loss: 1.140
Epoch:41 [390/412], Loss: 1.011
Epoch:41 [400/412], Loss: 0.917
Epoch:41 [410/412], Loss: 0.802
Epoch:41, Train IoU: [0.98255524 0.85690123 0.88509077]
Epoch:41, Valid Loss: 0.779, mIoU: 0.9229523344971368
EarlyStopping counter: 7 out of 100
Epoch:42 [0/412], Loss: 1.072
Epoch:42 [10/412], Loss: 0.911
Epoch:42 [20/412], Loss: 0.874
Epoch:42 [30/412], Loss: 0.843
Epoch:42 [40/412], Loss: 1.114
Epoch:42 [50/412], Loss: 0.822
Epoch:42 [60/412], Loss: 1.338
Epoch:42 [70/412], Loss: 0.822
Epoch:42 [80/412], Loss: 0.830
Epoch:42 [90/412], Loss: 1.193
Epoch:42 [100/412], Loss: 0.995
Epoch:42 [110/412], Loss: 0.924
Epoch:42 [120/412], Loss: 0.797
Epoch:42 [130/412], Loss: 0.835
Epoch:42 [140/412], Loss: 1.434
Epoch:42 [150/412], Loss: 0.980
Epoch:42 [160/412], Loss: 1.073
Epoch:42 [170/412], Loss: 1.006
Epoch:42 [180/412], Loss: 0.711
Epoch:42 [190/412], Loss: 0.866
Epoch:42 [200/412], Loss: 1.456
Epoch:42 [210/412], Loss: 1.093
Epoch:42 [220/412], Loss: 0.913
Epoch:42 [230/412], Loss: 1.271
Epoch:42 [240/412], Loss: 0.954
Epoch:42 [250/412], Loss: 1.088
Epoch:42 [260/412], Loss: 0.891
Epoch:42 [270/412], Loss: 1.036
Epoch:42 [280/412], Loss: 0.855
Epoch:42 [290/412], Loss: 0.936
Epoch:42 [300/412], Loss: 0.728
Epoch:42 [310/412], Loss: 0.775
Epoch:42 [320/412], Loss: 1.053
Epoch:42 [330/412], Loss: 0.844
Epoch:42 [340/412], Loss: 0.969
Epoch:42 [350/412], Loss: 0.726
Epoch:42 [360/412], Loss: 1.112
Epoch:42 [370/412], Loss: 1.285
Epoch:42 [380/412], Loss: 1.226
Epoch:42 [390/412], Loss: 0.891
Epoch:42 [400/412], Loss: 0.933
Epoch:42 [410/412], Loss: 1.204
Epoch:42, Train IoU: [0.98272994 0.85882586 0.88662318]
Epoch:42, Valid Loss: 0.744, mIoU: 0.925634847447539
EarlyStopping counter: 8 out of 100
Epoch:43 [0/412], Loss: 0.753
Epoch:43 [10/412], Loss: 0.949
Epoch:43 [20/412], Loss: 1.033
Epoch:43 [30/412], Loss: 0.900
Epoch:43 [40/412], Loss: 0.899
Epoch:43 [50/412], Loss: 0.843
Epoch:43 [60/412], Loss: 1.076
Epoch:43 [70/412], Loss: 1.026
Epoch:43 [80/412], Loss: 0.860
Epoch:43 [90/412], Loss: 1.028
Epoch:43 [100/412], Loss: 0.892
Epoch:43 [110/412], Loss: 0.967
Epoch:43 [120/412], Loss: 0.746
Epoch:43 [130/412], Loss: 0.738
Epoch:43 [140/412], Loss: 0.942
Epoch:43 [150/412], Loss: 1.010
Epoch:43 [160/412], Loss: 0.827
Epoch:43 [170/412], Loss: 0.991
Epoch:43 [180/412], Loss: 0.688
Epoch:43 [190/412], Loss: 1.081
Epoch:43 [200/412], Loss: 0.999
Epoch:43 [210/412], Loss: 1.144
Epoch:43 [220/412], Loss: 0.797
Epoch:43 [230/412], Loss: 0.790
Epoch:43 [240/412], Loss: 0.885
Epoch:43 [250/412], Loss: 1.058
Epoch:43 [260/412], Loss: 1.069
Epoch:43 [270/412], Loss: 0.648
Epoch:43 [280/412], Loss: 1.036
Epoch:43 [290/412], Loss: 0.855
Epoch:43 [300/412], Loss: 0.845
Epoch:43 [310/412], Loss: 0.909
Epoch:43 [320/412], Loss: 0.824
Epoch:43 [330/412], Loss: 0.848
Epoch:43 [340/412], Loss: 1.068
Epoch:43 [350/412], Loss: 0.752
Epoch:43 [360/412], Loss: 0.740
Epoch:43 [370/412], Loss: 1.022
Epoch:43 [380/412], Loss: 0.728
Epoch:43 [390/412], Loss: 1.026
Epoch:43 [400/412], Loss: 0.933
Epoch:43 [410/412], Loss: 0.844
Epoch:43, Train IoU: [0.98300992 0.86073411 0.88799703]
Epoch:43, Valid Loss: 0.713, mIoU: 0.9269417248040591
EarlyStopping counter: 9 out of 100
Epoch:44 [0/412], Loss: 0.906
Epoch:44 [10/412], Loss: 0.947
Epoch:44 [20/412], Loss: 0.728
Epoch:44 [30/412], Loss: 1.111
Epoch:44 [40/412], Loss: 1.059
Epoch:44 [50/412], Loss: 0.676
Epoch:44 [60/412], Loss: 0.858
Epoch:44 [70/412], Loss: 0.749
Epoch:44 [80/412], Loss: 0.689
Epoch:44 [90/412], Loss: 1.156
Epoch:44 [100/412], Loss: 0.871
Epoch:44 [110/412], Loss: 0.817
Epoch:44 [120/412], Loss: 0.849
Epoch:44 [130/412], Loss: 0.748
Epoch:44 [140/412], Loss: 1.077
Epoch:44 [150/412], Loss: 0.817
Epoch:44 [160/412], Loss: 0.860
Epoch:44 [170/412], Loss: 0.803
Epoch:44 [180/412], Loss: 0.838
Epoch:44 [190/412], Loss: 1.028
Epoch:44 [200/412], Loss: 0.980
Epoch:44 [210/412], Loss: 0.841
Epoch:44 [220/412], Loss: 0.809
Epoch:44 [230/412], Loss: 0.724
Epoch:44 [240/412], Loss: 1.198
Epoch:44 [250/412], Loss: 0.853
Epoch:44 [260/412], Loss: 1.006
Epoch:44 [270/412], Loss: 0.906
Epoch:44 [280/412], Loss: 0.832
Epoch:44 [290/412], Loss: 0.729
Epoch:44 [300/412], Loss: 0.721
Epoch:44 [310/412], Loss: 1.142
Epoch:44 [320/412], Loss: 0.546
Epoch:44 [330/412], Loss: 0.799
Epoch:44 [340/412], Loss: 0.821
Epoch:44 [350/412], Loss: 0.857
Epoch:44 [360/412], Loss: 0.875
Epoch:44 [370/412], Loss: 0.899
Epoch:44 [380/412], Loss: 1.038
Epoch:44 [390/412], Loss: 0.853
Epoch:44 [400/412], Loss: 0.714
Epoch:44 [410/412], Loss: 0.651
Epoch:44, Train IoU: [0.98339484 0.86336702 0.88984719]
Epoch:44, Valid Loss: 0.665, mIoU: 0.9279519842446722
EarlyStopping counter: 10 out of 100
Epoch:45 [0/412], Loss: 0.850
Epoch:45 [10/412], Loss: 0.898
Epoch:45 [20/412], Loss: 0.659
Epoch:45 [30/412], Loss: 0.954
Epoch:45 [40/412], Loss: 0.758
Epoch:45 [50/412], Loss: 0.723
Epoch:45 [60/412], Loss: 0.742
Epoch:45 [70/412], Loss: 0.862
Epoch:45 [80/412], Loss: 1.052
Epoch:45 [90/412], Loss: 0.948
Epoch:45 [100/412], Loss: 0.757
Epoch:45 [110/412], Loss: 0.757
Epoch:45 [120/412], Loss: 0.765
Epoch:45 [130/412], Loss: 0.831
Epoch:45 [140/412], Loss: 0.800
Epoch:45 [150/412], Loss: 1.052
Epoch:45 [160/412], Loss: 0.715
Epoch:45 [170/412], Loss: 0.978
Epoch:45 [180/412], Loss: 0.985
Epoch:45 [190/412], Loss: 0.676
Epoch:45 [200/412], Loss: 0.647
Epoch:45 [210/412], Loss: 0.600
Epoch:45 [220/412], Loss: 0.783
Epoch:45 [230/412], Loss: 0.743
Epoch:45 [240/412], Loss: 0.706
Epoch:45 [250/412], Loss: 0.940
Epoch:45 [260/412], Loss: 0.675
Epoch:45 [270/412], Loss: 0.694
Epoch:45 [280/412], Loss: 0.856
Epoch:45 [290/412], Loss: 0.791
Epoch:45 [300/412], Loss: 0.822
Epoch:45 [310/412], Loss: 0.910
Epoch:45 [320/412], Loss: 0.681
Epoch:45 [330/412], Loss: 0.797
Epoch:45 [340/412], Loss: 1.023
Epoch:45 [350/412], Loss: 0.771
Epoch:45 [360/412], Loss: 0.802
Epoch:45 [370/412], Loss: 0.726
Epoch:45 [380/412], Loss: 0.645
Epoch:45 [390/412], Loss: 0.697
Epoch:45 [400/412], Loss: 0.735
Epoch:45 [410/412], Loss: 0.838
Epoch:45, Train IoU: [0.98374696 0.86568065 0.89135763]
Epoch:45, Valid Loss: 0.658, mIoU: 0.9250908319067705
EarlyStopping counter: 11 out of 100
Epoch:46 [0/412], Loss: 0.747
Epoch:46 [10/412], Loss: 1.046
Epoch:46 [20/412], Loss: 0.734
Epoch:46 [30/412], Loss: 0.787
Epoch:46 [40/412], Loss: 0.836
Epoch:46 [50/412], Loss: 0.864
Epoch:46 [60/412], Loss: 0.850
Epoch:46 [70/412], Loss: 0.623
Epoch:46 [80/412], Loss: 0.766
Epoch:46 [90/412], Loss: 0.932
Epoch:46 [100/412], Loss: 0.660
Epoch:46 [110/412], Loss: 0.772
Epoch:46 [120/412], Loss: 0.765
Epoch:46 [130/412], Loss: 0.836
Epoch:46 [140/412], Loss: 0.767
Epoch:46 [150/412], Loss: 0.662
Epoch:46 [160/412], Loss: 0.675
Epoch:46 [170/412], Loss: 0.867
Epoch:46 [180/412], Loss: 0.791
Epoch:46 [190/412], Loss: 0.737
Epoch:46 [200/412], Loss: 0.756
Epoch:46 [210/412], Loss: 1.001
Epoch:46 [220/412], Loss: 0.991
Epoch:46 [230/412], Loss: 0.773
Epoch:46 [240/412], Loss: 0.720
Epoch:46 [250/412], Loss: 0.669
Epoch:46 [260/412], Loss: 0.685
Epoch:46 [270/412], Loss: 0.774
Epoch:46 [280/412], Loss: 0.611
Epoch:46 [290/412], Loss: 0.870
Epoch:46 [300/412], Loss: 0.567
Epoch:46 [310/412], Loss: 0.731
Epoch:46 [320/412], Loss: 0.671
Epoch:46 [330/412], Loss: 0.563
Epoch:46 [340/412], Loss: 0.800
Epoch:46 [350/412], Loss: 0.765
Epoch:46 [360/412], Loss: 0.925
Epoch:46 [370/412], Loss: 0.664
Epoch:46 [380/412], Loss: 0.801
Epoch:46 [390/412], Loss: 1.046
Epoch:46 [400/412], Loss: 0.924
Epoch:46 [410/412], Loss: 0.623
Epoch:46, Train IoU: [0.98433563 0.86949391 0.89291194]
Epoch:46, Valid Loss: 0.605, mIoU: 0.9296851157865483
EarlyStopping counter: 12 out of 100
Epoch:47 [0/412], Loss: 0.715
Epoch:47 [10/412], Loss: 0.765
Epoch:47 [20/412], Loss: 0.886
Epoch:47 [30/412], Loss: 0.986
Epoch:47 [40/412], Loss: 0.656
Epoch:47 [50/412], Loss: 0.675
Epoch:47 [60/412], Loss: 0.731
Epoch:47 [70/412], Loss: 0.777
Epoch:47 [80/412], Loss: 0.558
Epoch:47 [90/412], Loss: 0.631
Epoch:47 [100/412], Loss: 0.932
Epoch:47 [110/412], Loss: 0.703
Epoch:47 [120/412], Loss: 0.909
Epoch:47 [130/412], Loss: 0.708
Epoch:47 [140/412], Loss: 0.633
Epoch:47 [150/412], Loss: 0.968
Epoch:47 [160/412], Loss: 0.574
Epoch:47 [170/412], Loss: 0.788
Epoch:47 [180/412], Loss: 0.655
Epoch:47 [190/412], Loss: 0.680
Epoch:47 [200/412], Loss: 0.777
Epoch:47 [210/412], Loss: 0.565
Epoch:47 [220/412], Loss: 0.601
Epoch:47 [230/412], Loss: 0.635
Epoch:47 [240/412], Loss: 0.663
Epoch:47 [250/412], Loss: 0.739
Epoch:47 [260/412], Loss: 0.608
Epoch:47 [270/412], Loss: 0.787
Epoch:47 [280/412], Loss: 0.762
Epoch:47 [290/412], Loss: 0.841
Epoch:47 [300/412], Loss: 0.963
Epoch:47 [310/412], Loss: 0.767
Epoch:47 [320/412], Loss: 0.904
Epoch:47 [330/412], Loss: 0.744
Epoch:47 [340/412], Loss: 0.644
Epoch:47 [350/412], Loss: 0.797
Epoch:47 [360/412], Loss: 0.803
Epoch:47 [370/412], Loss: 0.789
Epoch:47 [380/412], Loss: 0.955
Epoch:47 [390/412], Loss: 1.010
Epoch:47 [400/412], Loss: 0.838
Epoch:47 [410/412], Loss: 0.878
Epoch:47, Train IoU: [0.98443702 0.87037647 0.89420455]
Epoch:47, Valid Loss: 0.592, mIoU: 0.9292509561612241
EarlyStopping counter: 13 out of 100
Epoch:48 [0/412], Loss: 0.806
Epoch:48 [10/412], Loss: 1.050
Epoch:48 [20/412], Loss: 0.824
Epoch:48 [30/412], Loss: 0.821
Epoch:48 [40/412], Loss: 0.948
Epoch:48 [50/412], Loss: 0.835
Epoch:48 [60/412], Loss: 0.750
Epoch:48 [70/412], Loss: 0.864
Epoch:48 [80/412], Loss: 0.588
Epoch:48 [90/412], Loss: 0.774
Epoch:48 [100/412], Loss: 0.999
Epoch:48 [110/412], Loss: 1.021
Epoch:48 [120/412], Loss: 0.784
Epoch:48 [130/412], Loss: 0.636
Epoch:48 [140/412], Loss: 0.675
Epoch:48 [150/412], Loss: 0.552
Epoch:48 [160/412], Loss: 0.803
Epoch:48 [170/412], Loss: 0.666
Epoch:48 [180/412], Loss: 0.709
Epoch:48 [190/412], Loss: 0.776
Epoch:48 [200/412], Loss: 0.771
Epoch:48 [210/412], Loss: 0.869
Epoch:48 [220/412], Loss: 0.841
Epoch:48 [230/412], Loss: 0.760
Epoch:48 [240/412], Loss: 0.701
Epoch:48 [250/412], Loss: 0.806
Epoch:48 [260/412], Loss: 0.747
Epoch:48 [270/412], Loss: 0.708
Epoch:48 [280/412], Loss: 0.933
Epoch:48 [290/412], Loss: 0.810
Epoch:48 [300/412], Loss: 0.609
Epoch:48 [310/412], Loss: 0.810
Epoch:48 [320/412], Loss: 0.750
Epoch:48 [330/412], Loss: 0.557
Epoch:48 [340/412], Loss: 0.553
Epoch:48 [350/412], Loss: 0.600
Epoch:48 [360/412], Loss: 0.683
Epoch:48 [370/412], Loss: 0.465
Epoch:48 [380/412], Loss: 0.921
Epoch:48 [390/412], Loss: 0.793
Epoch:48 [400/412], Loss: 0.656
Epoch:48 [410/412], Loss: 0.757
Epoch:48, Train IoU: [0.98438172 0.8702554  0.89446864]
Epoch:48, Valid Loss: 0.575, mIoU: 0.9302857600554516
EarlyStopping counter: 14 out of 100
Epoch:49 [0/412], Loss: 0.865
Epoch:49 [10/412], Loss: 0.499
Epoch:49 [20/412], Loss: 0.730
Epoch:49 [30/412], Loss: 0.717
Epoch:49 [40/412], Loss: 1.092
Epoch:49 [50/412], Loss: 0.622
Epoch:49 [60/412], Loss: 0.945
Epoch:49 [70/412], Loss: 0.922
Epoch:49 [80/412], Loss: 0.762
Epoch:49 [90/412], Loss: 0.817
Epoch:49 [100/412], Loss: 0.937
Epoch:49 [110/412], Loss: 0.933
Epoch:49 [120/412], Loss: 0.708
Epoch:49 [130/412], Loss: 0.550
Epoch:49 [140/412], Loss: 0.633
Epoch:49 [150/412], Loss: 0.735
Epoch:49 [160/412], Loss: 0.636
Epoch:49 [170/412], Loss: 0.565
Epoch:49 [180/412], Loss: 0.811
Epoch:49 [190/412], Loss: 0.707
Epoch:49 [200/412], Loss: 0.645
Epoch:49 [210/412], Loss: 0.674
Epoch:49 [220/412], Loss: 0.752
Epoch:49 [230/412], Loss: 0.642
Epoch:49 [240/412], Loss: 0.588
Epoch:49 [250/412], Loss: 0.718
Epoch:49 [260/412], Loss: 0.663
Epoch:49 [270/412], Loss: 0.731
Epoch:49 [280/412], Loss: 0.619
Epoch:49 [290/412], Loss: 0.807
Epoch:49 [300/412], Loss: 0.664
Epoch:49 [310/412], Loss: 0.609
Epoch:49 [320/412], Loss: 0.747
Epoch:49 [330/412], Loss: 0.561
Epoch:49 [340/412], Loss: 0.568
Epoch:49 [350/412], Loss: 0.498
Epoch:49 [360/412], Loss: 0.557
Epoch:49 [370/412], Loss: 0.796
Epoch:49 [380/412], Loss: 0.708
Epoch:49 [390/412], Loss: 0.525
Epoch:49 [400/412], Loss: 0.497
Epoch:49 [410/412], Loss: 0.939
Epoch:49, Train IoU: [0.98454011 0.87090704 0.89515043]
Epoch:49, Valid Loss: 0.559, mIoU: 0.9306995573859482
EarlyStopping counter: 15 out of 100
Epoch:50 [0/412], Loss: 0.798
Epoch:50 [10/412], Loss: 0.911
Epoch:50 [20/412], Loss: 0.631
Epoch:50 [30/412], Loss: 0.655
Epoch:50 [40/412], Loss: 0.730
Epoch:50 [50/412], Loss: 0.807
Epoch:50 [60/412], Loss: 0.670
Epoch:50 [70/412], Loss: 1.067
Epoch:50 [80/412], Loss: 0.661
Epoch:50 [90/412], Loss: 0.597
Epoch:50 [100/412], Loss: 0.668
Epoch:50 [110/412], Loss: 0.593
Epoch:50 [120/412], Loss: 0.757
Epoch:50 [130/412], Loss: 0.583
Epoch:50 [140/412], Loss: 0.730
Epoch:50 [150/412], Loss: 0.601
Epoch:50 [160/412], Loss: 0.729
Epoch:50 [170/412], Loss: 0.671
Epoch:50 [180/412], Loss: 0.835
Epoch:50 [190/412], Loss: 0.969
Epoch:50 [200/412], Loss: 0.573
Epoch:50 [210/412], Loss: 0.767
Epoch:50 [220/412], Loss: 0.543
Epoch:50 [230/412], Loss: 0.698
Epoch:50 [240/412], Loss: 0.549
Epoch:50 [250/412], Loss: 0.811
Epoch:50 [260/412], Loss: 0.500
Epoch:50 [270/412], Loss: 0.960
Epoch:50 [280/412], Loss: 0.773
Epoch:50 [290/412], Loss: 0.787
Epoch:50 [300/412], Loss: 0.572
Epoch:50 [310/412], Loss: 1.060
Epoch:50 [320/412], Loss: 0.777
Epoch:50 [330/412], Loss: 0.817
Epoch:50 [340/412], Loss: 0.475
Epoch:50 [350/412], Loss: 0.662
Epoch:50 [360/412], Loss: 0.670
Epoch:50 [370/412], Loss: 0.579
Epoch:50 [380/412], Loss: 0.815
Epoch:50 [390/412], Loss: 0.832
Epoch:50 [400/412], Loss: 0.530
Epoch:50 [410/412], Loss: 0.761
Epoch:50, Train IoU: [0.98455075 0.87144007 0.89543418]
Epoch:50, Valid Loss: 0.546, mIoU: 0.9301478665912185
EarlyStopping counter: 16 out of 100
Epoch:51 [0/412], Loss: 0.617
Epoch:51 [10/412], Loss: 0.587
Epoch:51 [20/412], Loss: 0.569
Epoch:51 [30/412], Loss: 0.710
Epoch:51 [40/412], Loss: 0.923
Epoch:51 [50/412], Loss: 0.657
Epoch:51 [60/412], Loss: 0.606
Epoch:51 [70/412], Loss: 0.610
Epoch:51 [80/412], Loss: 0.626
Epoch:51 [90/412], Loss: 0.547
Epoch:51 [100/412], Loss: 0.520
Epoch:51 [110/412], Loss: 0.609
Epoch:51 [120/412], Loss: 0.630
Epoch:51 [130/412], Loss: 0.512
Epoch:51 [140/412], Loss: 0.666
Epoch:51 [150/412], Loss: 0.670
Epoch:51 [160/412], Loss: 0.646
Epoch:51 [170/412], Loss: 0.849
Epoch:51 [180/412], Loss: 0.468
Epoch:51 [190/412], Loss: 1.436
Epoch:51 [200/412], Loss: 0.637
Epoch:51 [210/412], Loss: 0.610
Epoch:51 [220/412], Loss: 0.541
Epoch:51 [230/412], Loss: 0.697
Epoch:51 [240/412], Loss: 0.729
Epoch:51 [250/412], Loss: 0.621
Epoch:51 [260/412], Loss: 0.597
Epoch:51 [270/412], Loss: 0.617
Epoch:51 [280/412], Loss: 0.688
Epoch:51 [290/412], Loss: 0.655
Epoch:51 [300/412], Loss: 0.604
Epoch:51 [310/412], Loss: 0.506
Epoch:51 [320/412], Loss: 0.756
Epoch:51 [330/412], Loss: 0.732
Epoch:51 [340/412], Loss: 0.775
Epoch:51 [350/412], Loss: 0.779
Epoch:51 [360/412], Loss: 0.705
Epoch:51 [370/412], Loss: 0.614
Epoch:51 [380/412], Loss: 0.489
Epoch:51 [390/412], Loss: 0.687
Epoch:51 [400/412], Loss: 0.621
Epoch:51 [410/412], Loss: 0.732
Epoch:51, Train IoU: [0.9845776  0.87149399 0.89523586]
Epoch:51, Valid Loss: 0.535, mIoU: 0.9302622542304416
EarlyStopping counter: 17 out of 100
Epoch:52 [0/412], Loss: 0.610
Epoch:52 [10/412], Loss: 0.771
Epoch:52 [20/412], Loss: 0.714
Epoch:52 [30/412], Loss: 0.639
Epoch:52 [40/412], Loss: 0.616
Epoch:52 [50/412], Loss: 0.675
Epoch:52 [60/412], Loss: 0.626
Epoch:52 [70/412], Loss: 0.668
Epoch:52 [80/412], Loss: 0.535
Epoch:52 [90/412], Loss: 0.845
Epoch:52 [100/412], Loss: 0.678
Epoch:52 [110/412], Loss: 0.532
Epoch:52 [120/412], Loss: 0.629
Epoch:52 [130/412], Loss: 0.719
Epoch:52 [140/412], Loss: 0.740
Epoch:52 [150/412], Loss: 0.654
Epoch:52 [160/412], Loss: 0.785
Epoch:52 [170/412], Loss: 0.705
Epoch:52 [180/412], Loss: 0.782
Epoch:52 [190/412], Loss: 0.774
Epoch:52 [200/412], Loss: 0.534
Epoch:52 [210/412], Loss: 0.620
Epoch:52 [220/412], Loss: 0.693
Epoch:52 [230/412], Loss: 0.714
Epoch:52 [240/412], Loss: 0.590
Epoch:52 [250/412], Loss: 0.721
Epoch:52 [260/412], Loss: 0.742
Epoch:52 [270/412], Loss: 0.603
Epoch:52 [280/412], Loss: 0.482
Epoch:52 [290/412], Loss: 0.629
Epoch:52 [300/412], Loss: 0.500
Epoch:52 [310/412], Loss: 0.478
Epoch:52 [320/412], Loss: 0.620
Epoch:52 [330/412], Loss: 0.438
Epoch:52 [340/412], Loss: 0.659
Epoch:52 [350/412], Loss: 0.637
Epoch:52 [360/412], Loss: 0.682
Epoch:52 [370/412], Loss: 0.651
Epoch:52 [380/412], Loss: 0.570
Epoch:52 [390/412], Loss: 0.655
Epoch:52 [400/412], Loss: 0.757
Epoch:52 [410/412], Loss: 0.884
Epoch:52, Train IoU: [0.9846594  0.87185582 0.8957494 ]
Epoch:52, Valid Loss: 0.517, mIoU: 0.9308785143316252
EarlyStopping counter: 18 out of 100
Epoch:53 [0/412], Loss: 0.628
Epoch:53 [10/412], Loss: 0.554
Epoch:53 [20/412], Loss: 0.601
Epoch:53 [30/412], Loss: 1.052
Epoch:53 [40/412], Loss: 0.912
Epoch:53 [50/412], Loss: 0.446
Epoch:53 [60/412], Loss: 0.510
Epoch:53 [70/412], Loss: 0.942
Epoch:53 [80/412], Loss: 0.811
Epoch:53 [90/412], Loss: 0.617
Epoch:53 [100/412], Loss: 0.648
Epoch:53 [110/412], Loss: 0.850
Epoch:53 [120/412], Loss: 0.488
Epoch:53 [130/412], Loss: 0.534
Epoch:53 [140/412], Loss: 0.694
Epoch:53 [150/412], Loss: 0.613
Epoch:53 [160/412], Loss: 0.784
Epoch:53 [170/412], Loss: 0.772
Epoch:53 [180/412], Loss: 0.838
Epoch:53 [190/412], Loss: 0.806
Epoch:53 [200/412], Loss: 0.848
Epoch:53 [210/412], Loss: 0.698
Epoch:53 [220/412], Loss: 0.726
Epoch:53 [230/412], Loss: 0.719
Epoch:53 [240/412], Loss: 0.949
Epoch:53 [250/412], Loss: 0.600
Epoch:53 [260/412], Loss: 0.794
Epoch:53 [270/412], Loss: 0.985
Epoch:53 [280/412], Loss: 0.494
Epoch:53 [290/412], Loss: 0.496
Epoch:53 [300/412], Loss: 0.530
Epoch:53 [310/412], Loss: 0.666
Epoch:53 [320/412], Loss: 0.688
Epoch:53 [330/412], Loss: 0.828
Epoch:53 [340/412], Loss: 0.544
Epoch:53 [350/412], Loss: 0.843
Epoch:53 [360/412], Loss: 0.682
Epoch:53 [370/412], Loss: 0.581
Epoch:53 [380/412], Loss: 0.537
Epoch:53 [390/412], Loss: 0.637
Epoch:53 [400/412], Loss: 0.670
Epoch:53 [410/412], Loss: 0.647
Epoch:53, Train IoU: [0.98472859 0.8726489  0.89626613]
Epoch:53, Valid Loss: 0.506, mIoU: 0.9309642052631176
EarlyStopping counter: 19 out of 100
Epoch:54 [0/412], Loss: 1.047
Epoch:54 [10/412], Loss: 0.848
Epoch:54 [20/412], Loss: 0.780
Epoch:54 [30/412], Loss: 0.572
Epoch:54 [40/412], Loss: 0.868
Epoch:54 [50/412], Loss: 0.538
Epoch:54 [60/412], Loss: 0.652
Epoch:54 [70/412], Loss: 0.649
Epoch:54 [80/412], Loss: 0.694
Epoch:54 [90/412], Loss: 0.750
Epoch:54 [100/412], Loss: 0.841
Epoch:54 [110/412], Loss: 0.671
Epoch:54 [120/412], Loss: 0.461
Epoch:54 [130/412], Loss: 0.582
Epoch:54 [140/412], Loss: 0.633
Epoch:54 [150/412], Loss: 0.572
Epoch:54 [160/412], Loss: 0.669
Epoch:54 [170/412], Loss: 0.861
Epoch:54 [180/412], Loss: 0.436
Epoch:54 [190/412], Loss: 0.670
Epoch:54 [200/412], Loss: 0.595
Epoch:54 [210/412], Loss: 0.610
Epoch:54 [220/412], Loss: 0.766
Epoch:54 [230/412], Loss: 0.546
Epoch:54 [240/412], Loss: 0.927
Epoch:54 [250/412], Loss: 0.620
Epoch:54 [260/412], Loss: 0.656
Epoch:54 [270/412], Loss: 0.741
Epoch:54 [280/412], Loss: 0.684
Epoch:54 [290/412], Loss: 0.772
Epoch:54 [300/412], Loss: 0.490
Epoch:54 [310/412], Loss: 0.812
Epoch:54 [320/412], Loss: 0.489
Epoch:54 [330/412], Loss: 0.584
Epoch:54 [340/412], Loss: 0.536
Epoch:54 [350/412], Loss: 0.709
Epoch:54 [360/412], Loss: 0.658
Epoch:54 [370/412], Loss: 0.741
Epoch:54 [380/412], Loss: 0.631
Epoch:54 [390/412], Loss: 0.738
Epoch:54 [400/412], Loss: 0.779
Epoch:54 [410/412], Loss: 0.556
Epoch:54, Train IoU: [0.98473021 0.87277979 0.8966439 ]
Epoch:54, Valid Loss: 0.494, mIoU: 0.9309457521454622
EarlyStopping counter: 20 out of 100
Epoch:55 [0/412], Loss: 0.893
Epoch:55 [10/412], Loss: 0.661
Epoch:55 [20/412], Loss: 0.625
Epoch:55 [30/412], Loss: 0.808
Epoch:55 [40/412], Loss: 0.869
Epoch:55 [50/412], Loss: 0.676
Epoch:55 [60/412], Loss: 0.534
Epoch:55 [70/412], Loss: 0.405
Epoch:55 [80/412], Loss: 0.764
Epoch:55 [90/412], Loss: 0.455
Epoch:55 [100/412], Loss: 0.500
Epoch:55 [110/412], Loss: 0.696
Epoch:55 [120/412], Loss: 0.491
Epoch:55 [130/412], Loss: 0.737
Epoch:55 [140/412], Loss: 0.594
Epoch:55 [150/412], Loss: 0.517
Epoch:55 [160/412], Loss: 0.619
Epoch:55 [170/412], Loss: 0.572
Epoch:55 [180/412], Loss: 0.625
Epoch:55 [190/412], Loss: 0.668
Epoch:55 [200/412], Loss: 0.763
Epoch:55 [210/412], Loss: 0.578
Epoch:55 [220/412], Loss: 0.740
Epoch:55 [230/412], Loss: 0.671
Epoch:55 [240/412], Loss: 0.489
Epoch:55 [250/412], Loss: 0.585
Epoch:55 [260/412], Loss: 0.794
Epoch:55 [270/412], Loss: 0.695
Epoch:55 [280/412], Loss: 0.642
Epoch:55 [290/412], Loss: 0.919
Epoch:55 [300/412], Loss: 0.583
Epoch:55 [310/412], Loss: 0.639
Epoch:55 [320/412], Loss: 0.495
Epoch:55 [330/412], Loss: 0.575
Epoch:55 [340/412], Loss: 0.817
Epoch:55 [350/412], Loss: 0.734
Epoch:55 [360/412], Loss: 0.732
Epoch:55 [370/412], Loss: 0.854
Epoch:55 [380/412], Loss: 0.626
Epoch:55 [390/412], Loss: 0.684
Epoch:55 [400/412], Loss: 0.572
Epoch:55 [410/412], Loss: 0.813
Epoch:55, Train IoU: [0.98474054 0.87247186 0.89603231]
Epoch:55, Valid Loss: 0.483, mIoU: 0.9309253572190967
EarlyStopping counter: 21 out of 100
Epoch:56 [0/412], Loss: 0.579
Epoch:56 [10/412], Loss: 0.591
Epoch:56 [20/412], Loss: 0.520
Epoch:56 [30/412], Loss: 0.623
Epoch:56 [40/412], Loss: 0.689
Epoch:56 [50/412], Loss: 1.045
Epoch:56 [60/412], Loss: 0.555
Epoch:56 [70/412], Loss: 0.572
Epoch:56 [80/412], Loss: 0.495
Epoch:56 [90/412], Loss: 0.551
Epoch:56 [100/412], Loss: 0.800
Epoch:56 [110/412], Loss: 0.534
Epoch:56 [120/412], Loss: 0.737
Epoch:56 [130/412], Loss: 0.642
Epoch:56 [140/412], Loss: 0.610
Epoch:56 [150/412], Loss: 0.552
Epoch:56 [160/412], Loss: 0.490
Epoch:56 [170/412], Loss: 0.551
Epoch:56 [180/412], Loss: 0.620
Epoch:56 [190/412], Loss: 0.410
Epoch:56 [200/412], Loss: 0.680
Epoch:56 [210/412], Loss: 0.854
Epoch:56 [220/412], Loss: 0.473
Epoch:56 [230/412], Loss: 0.892
Epoch:56 [240/412], Loss: 0.784
Epoch:56 [250/412], Loss: 0.653
Epoch:56 [260/412], Loss: 0.425
Epoch:56 [270/412], Loss: 0.560
Epoch:56 [280/412], Loss: 0.564
Epoch:56 [290/412], Loss: 0.716
Epoch:56 [300/412], Loss: 0.763
Epoch:56 [310/412], Loss: 0.664
Epoch:56 [320/412], Loss: 0.909
Epoch:56 [330/412], Loss: 0.729
Epoch:56 [340/412], Loss: 0.850
Epoch:56 [350/412], Loss: 0.488
Epoch:56 [360/412], Loss: 0.707
Epoch:56 [370/412], Loss: 0.661
Epoch:56 [380/412], Loss: 0.909
Epoch:56 [390/412], Loss: 0.563
Epoch:56 [400/412], Loss: 0.686
Epoch:56 [410/412], Loss: 0.740
Epoch:56, Train IoU: [0.98471867 0.87298041 0.89645528]
Epoch:56, Valid Loss: 0.471, mIoU: 0.9308564361322142
EarlyStopping counter: 22 out of 100
Epoch:57 [0/412], Loss: 0.648
Epoch:57 [10/412], Loss: 0.441
Epoch:57 [20/412], Loss: 0.682
Epoch:57 [30/412], Loss: 0.468
Epoch:57 [40/412], Loss: 0.757
Epoch:57 [50/412], Loss: 0.568
Epoch:57 [60/412], Loss: 0.719
Epoch:57 [70/412], Loss: 0.807
Epoch:57 [80/412], Loss: 1.176
Epoch:57 [90/412], Loss: 0.820
Epoch:57 [100/412], Loss: 0.499
Epoch:57 [110/412], Loss: 0.747
Epoch:57 [120/412], Loss: 0.652
Epoch:57 [130/412], Loss: 0.566
Epoch:57 [140/412], Loss: 0.592
Epoch:57 [150/412], Loss: 0.611
Epoch:57 [160/412], Loss: 0.501
Epoch:57 [170/412], Loss: 0.469
Epoch:57 [180/412], Loss: 0.728
Epoch:57 [190/412], Loss: 0.805
Epoch:57 [200/412], Loss: 0.809
Epoch:57 [210/412], Loss: 0.531
Epoch:57 [220/412], Loss: 0.427
Epoch:57 [230/412], Loss: 0.546
Epoch:57 [240/412], Loss: 0.715
Epoch:57 [250/412], Loss: 0.655
Epoch:57 [260/412], Loss: 0.676
Epoch:57 [270/412], Loss: 0.516
Epoch:57 [280/412], Loss: 0.636
Epoch:57 [290/412], Loss: 0.741
Epoch:57 [300/412], Loss: 0.518
Epoch:57 [310/412], Loss: 0.578
Epoch:57 [320/412], Loss: 0.667
Epoch:57 [330/412], Loss: 0.727
Epoch:57 [340/412], Loss: 0.648
Epoch:57 [350/412], Loss: 0.442
Epoch:57 [360/412], Loss: 0.576
Epoch:57 [370/412], Loss: 0.667
Epoch:57 [380/412], Loss: 0.682
Epoch:57 [390/412], Loss: 0.751
Epoch:57 [400/412], Loss: 0.504
Epoch:57 [410/412], Loss: 0.547
Epoch:57, Train IoU: [0.98471793 0.87276169 0.89630398]
Epoch:57, Valid Loss: 0.460, mIoU: 0.9310766960077702
EarlyStopping counter: 23 out of 100
Epoch:58 [0/412], Loss: 0.899
Epoch:58 [10/412], Loss: 0.687
Epoch:58 [20/412], Loss: 0.649
Epoch:58 [30/412], Loss: 0.481
Epoch:58 [40/412], Loss: 0.514
Epoch:58 [50/412], Loss: 0.589
Epoch:58 [60/412], Loss: 0.550
Epoch:58 [70/412], Loss: 0.819
Epoch:58 [80/412], Loss: 0.605
Epoch:58 [90/412], Loss: 0.600
Epoch:58 [100/412], Loss: 0.463
Epoch:58 [110/412], Loss: 0.639
Epoch:58 [120/412], Loss: 0.626
Epoch:58 [130/412], Loss: 0.548
Epoch:58 [140/412], Loss: 0.772
Epoch:58 [150/412], Loss: 0.499
Epoch:58 [160/412], Loss: 0.569
Epoch:58 [170/412], Loss: 0.810
Epoch:58 [180/412], Loss: 0.534
Epoch:58 [190/412], Loss: 0.481
Epoch:58 [200/412], Loss: 0.545
Epoch:58 [210/412], Loss: 0.573
Epoch:58 [220/412], Loss: 0.708
Epoch:58 [230/412], Loss: 0.543
Epoch:58 [240/412], Loss: 0.601
Epoch:58 [250/412], Loss: 0.616
Epoch:58 [260/412], Loss: 0.507
Epoch:58 [270/412], Loss: 0.521
Epoch:58 [280/412], Loss: 0.661
Epoch:58 [290/412], Loss: 0.607
Epoch:58 [300/412], Loss: 0.670
Epoch:58 [310/412], Loss: 0.605
Epoch:58 [320/412], Loss: 0.561
Epoch:58 [330/412], Loss: 0.687
Epoch:58 [340/412], Loss: 0.469
Epoch:58 [350/412], Loss: 0.495
Epoch:58 [360/412], Loss: 0.798
Epoch:58 [370/412], Loss: 0.627
Epoch:58 [380/412], Loss: 0.675
Epoch:58 [390/412], Loss: 0.580
Epoch:58 [400/412], Loss: 0.586
Epoch:58 [410/412], Loss: 0.647
Epoch:58, Train IoU: [0.98477224 0.87280653 0.89622257]
Epoch:58, Valid Loss: 0.449, mIoU: 0.9311294945058789
EarlyStopping counter: 24 out of 100
Epoch:59 [0/412], Loss: 0.603
Epoch:59 [10/412], Loss: 0.453
Epoch:59 [20/412], Loss: 0.510
Epoch:59 [30/412], Loss: 0.848
Epoch:59 [40/412], Loss: 0.512
Epoch:59 [50/412], Loss: 0.704
Epoch:59 [60/412], Loss: 0.712
Epoch:59 [70/412], Loss: 0.361
Epoch:59 [80/412], Loss: 0.809
Epoch:59 [90/412], Loss: 0.499
Epoch:59 [100/412], Loss: 0.525
Epoch:59 [110/412], Loss: 0.560
Epoch:59 [120/412], Loss: 0.642
Epoch:59 [130/412], Loss: 0.456
Epoch:59 [140/412], Loss: 0.674
Epoch:59 [150/412], Loss: 0.697
Epoch:59 [160/412], Loss: 0.589
Epoch:59 [170/412], Loss: 0.545
Epoch:59 [180/412], Loss: 0.714
Epoch:59 [190/412], Loss: 0.766
Epoch:59 [200/412], Loss: 0.602
Epoch:59 [210/412], Loss: 0.644
Epoch:59 [220/412], Loss: 0.873
Epoch:59 [230/412], Loss: 0.495
Epoch:59 [240/412], Loss: 0.573
Epoch:59 [250/412], Loss: 0.580
Epoch:59 [260/412], Loss: 0.824
Epoch:59 [270/412], Loss: 0.630
Epoch:59 [280/412], Loss: 0.543
Epoch:59 [290/412], Loss: 0.898
Epoch:59 [300/412], Loss: 0.560
Epoch:59 [310/412], Loss: 0.538
Epoch:59 [320/412], Loss: 0.746
Epoch:59 [330/412], Loss: 0.454
Epoch:59 [340/412], Loss: 0.671
Epoch:59 [350/412], Loss: 0.873
Epoch:59 [360/412], Loss: 0.738
Epoch:59 [370/412], Loss: 0.560
Epoch:59 [380/412], Loss: 0.621
Epoch:59 [390/412], Loss: 0.636
Epoch:59 [400/412], Loss: 0.481
Epoch:59 [410/412], Loss: 0.625
Epoch:59, Train IoU: [0.98470861 0.87274904 0.89598548]
Epoch:59, Valid Loss: 0.438, mIoU: 0.9311760812888341
EarlyStopping counter: 25 out of 100
Epoch:60 [0/412], Loss: 0.518
Epoch:60 [10/412], Loss: 0.579
Epoch:60 [20/412], Loss: 0.505
Epoch:60 [30/412], Loss: 0.489
Epoch:60 [40/412], Loss: 0.625
Epoch:60 [50/412], Loss: 0.552
Epoch:60 [60/412], Loss: 0.641
Epoch:60 [70/412], Loss: 0.670
Epoch:60 [80/412], Loss: 0.451
Epoch:60 [90/412], Loss: 0.504
Epoch:60 [100/412], Loss: 0.683
Epoch:60 [110/412], Loss: 0.695
Epoch:60 [120/412], Loss: 0.466
Epoch:60 [130/412], Loss: 0.408
Epoch:60 [140/412], Loss: 0.561
Epoch:60 [150/412], Loss: 0.405
Epoch:60 [160/412], Loss: 0.496
Epoch:60 [170/412], Loss: 0.569
Epoch:60 [180/412], Loss: 0.589
Epoch:60 [190/412], Loss: 0.678
Epoch:60 [200/412], Loss: 0.775
Epoch:60 [210/412], Loss: 0.598
Epoch:60 [220/412], Loss: 0.573
Epoch:60 [230/412], Loss: 0.510
Epoch:60 [240/412], Loss: 0.792
Epoch:60 [250/412], Loss: 0.362
Epoch:60 [260/412], Loss: 0.513
Epoch:60 [270/412], Loss: 0.451
Epoch:60 [280/412], Loss: 0.875
Epoch:60 [290/412], Loss: 0.414
Epoch:60 [300/412], Loss: 0.694
Epoch:60 [310/412], Loss: 0.437
Epoch:60 [320/412], Loss: 0.637
Epoch:60 [330/412], Loss: 0.476
Epoch:60 [340/412], Loss: 0.665
Epoch:60 [350/412], Loss: 0.842
Epoch:60 [360/412], Loss: 0.510
Epoch:60 [370/412], Loss: 0.494
Epoch:60 [380/412], Loss: 0.512
Epoch:60 [390/412], Loss: 0.475
Epoch:60 [400/412], Loss: 0.747
Epoch:60 [410/412], Loss: 0.497
Epoch:60, Train IoU: [0.98475668 0.872747   0.8961757 ]
Epoch:60, Valid Loss: 0.427, mIoU: 0.9311225373343649
EarlyStopping counter: 26 out of 100
Epoch:61 [0/412], Loss: 0.537
Epoch:61 [10/412], Loss: 0.799
Epoch:61 [20/412], Loss: 0.567
Epoch:61 [30/412], Loss: 0.736
Epoch:61 [40/412], Loss: 0.502
Epoch:61 [50/412], Loss: 0.516
Epoch:61 [60/412], Loss: 0.454
Epoch:61 [70/412], Loss: 0.425
Epoch:61 [80/412], Loss: 0.615
Epoch:61 [90/412], Loss: 0.745
Epoch:61 [100/412], Loss: 0.639
Epoch:61 [110/412], Loss: 0.708
Epoch:61 [120/412], Loss: 0.513
Epoch:61 [130/412], Loss: 0.365
Epoch:61 [140/412], Loss: 0.465
Epoch:61 [150/412], Loss: 0.496
Epoch:61 [160/412], Loss: 0.573
Epoch:61 [170/412], Loss: 0.620
Epoch:61 [180/412], Loss: 0.678
Epoch:61 [190/412], Loss: 0.565
Epoch:61 [200/412], Loss: 0.616
Epoch:61 [210/412], Loss: 0.417
Epoch:61 [220/412], Loss: 0.491
Epoch:61 [230/412], Loss: 0.596
Epoch:61 [240/412], Loss: 0.503
Epoch:61 [250/412], Loss: 0.613
Epoch:61 [260/412], Loss: 0.357
Epoch:61 [270/412], Loss: 0.544
Epoch:61 [280/412], Loss: 0.405
Epoch:61 [290/412], Loss: 0.451
Epoch:61 [300/412], Loss: 0.473
Epoch:61 [310/412], Loss: 0.575
Epoch:61 [320/412], Loss: 0.797
Epoch:61 [330/412], Loss: 0.575
Epoch:61 [340/412], Loss: 0.523
Epoch:61 [350/412], Loss: 0.407
Epoch:61 [360/412], Loss: 0.446
Epoch:61 [370/412], Loss: 0.557
Epoch:61 [380/412], Loss: 0.595
Epoch:61 [390/412], Loss: 0.509
Epoch:61 [400/412], Loss: 0.629
Epoch:61 [410/412], Loss: 0.430
Epoch:61, Train IoU: [0.98472132 0.8728032  0.89582845]
Epoch:61, Valid Loss: 0.416, mIoU: 0.9311710697880814
EarlyStopping counter: 27 out of 100
Epoch:62 [0/412], Loss: 0.548
Epoch:62 [10/412], Loss: 0.598
Epoch:62 [20/412], Loss: 0.440
Epoch:62 [30/412], Loss: 0.569
Epoch:62 [40/412], Loss: 0.627
Epoch:62 [50/412], Loss: 0.453
Epoch:62 [60/412], Loss: 0.521
Epoch:62 [70/412], Loss: 0.541
Epoch:62 [80/412], Loss: 0.689
Epoch:62 [90/412], Loss: 0.583
Epoch:62 [100/412], Loss: 0.666
Epoch:62 [110/412], Loss: 0.482
Epoch:62 [120/412], Loss: 0.573
Epoch:62 [130/412], Loss: 0.393
Epoch:62 [140/412], Loss: 0.451
Epoch:62 [150/412], Loss: 0.422
Epoch:62 [160/412], Loss: 0.551
Epoch:62 [170/412], Loss: 0.373
Epoch:62 [180/412], Loss: 0.621
Epoch:62 [190/412], Loss: 0.488
Epoch:62 [200/412], Loss: 0.475
Epoch:62 [210/412], Loss: 0.466
Epoch:62 [220/412], Loss: 0.689
Epoch:62 [230/412], Loss: 0.445
Epoch:62 [240/412], Loss: 0.565
Epoch:62 [250/412], Loss: 0.606
Epoch:62 [260/412], Loss: 0.496
Epoch:62 [270/412], Loss: 0.439
Epoch:62 [280/412], Loss: 0.457
Epoch:62 [290/412], Loss: 0.528
Epoch:62 [300/412], Loss: 0.591
Epoch:62 [310/412], Loss: 0.448
Epoch:62 [320/412], Loss: 0.717
Epoch:62 [330/412], Loss: 0.563
Epoch:62 [340/412], Loss: 0.513
Epoch:62 [350/412], Loss: 0.775
Epoch:62 [360/412], Loss: 0.623
Epoch:62 [370/412], Loss: 0.536
Epoch:62 [380/412], Loss: 0.509
Epoch:62 [390/412], Loss: 0.522
Epoch:62 [400/412], Loss: 0.964
Epoch:62 [410/412], Loss: 0.771
Epoch:62, Train IoU: [0.98475888 0.87304665 0.89607362]
Epoch:62, Valid Loss: 0.405, mIoU: 0.931171426039831
EarlyStopping counter: 28 out of 100
Epoch:63 [0/412], Loss: 0.443
Epoch:63 [10/412], Loss: 0.454
Epoch:63 [20/412], Loss: 0.422
Epoch:63 [30/412], Loss: 0.406
Epoch:63 [40/412], Loss: 0.408
Epoch:63 [50/412], Loss: 0.410
Epoch:63 [60/412], Loss: 0.561
Epoch:63 [70/412], Loss: 0.629
Epoch:63 [80/412], Loss: 0.582
Epoch:63 [90/412], Loss: 0.421
Epoch:63 [100/412], Loss: 0.495
Epoch:63 [110/412], Loss: 0.640
Epoch:63 [120/412], Loss: 0.609
Epoch:63 [130/412], Loss: 0.309
Epoch:63 [140/412], Loss: 0.680
Epoch:63 [150/412], Loss: 0.495
Epoch:63 [160/412], Loss: 0.626
Epoch:63 [170/412], Loss: 0.419
Epoch:63 [180/412], Loss: 0.534
Epoch:63 [190/412], Loss: 0.754
Epoch:63 [200/412], Loss: 0.789
Epoch:63 [210/412], Loss: 0.542
Epoch:63 [220/412], Loss: 0.550
Epoch:63 [230/412], Loss: 0.531
Epoch:63 [240/412], Loss: 0.813
Epoch:63 [250/412], Loss: 0.595
Epoch:63 [260/412], Loss: 0.456
Epoch:63 [270/412], Loss: 0.747
Epoch:63 [280/412], Loss: 0.800
Epoch:63 [290/412], Loss: 0.372
Epoch:63 [300/412], Loss: 0.664
Epoch:63 [310/412], Loss: 0.555
Epoch:63 [320/412], Loss: 0.692
Epoch:63 [330/412], Loss: 0.485
Epoch:63 [340/412], Loss: 0.550
Epoch:63 [350/412], Loss: 0.417
Epoch:63 [360/412], Loss: 0.436
Epoch:63 [370/412], Loss: 0.644
Epoch:63 [380/412], Loss: 0.499
Epoch:63 [390/412], Loss: 0.424
Epoch:63 [400/412], Loss: 0.418
Epoch:63 [410/412], Loss: 0.745
Epoch:63, Train IoU: [0.98463112 0.87255268 0.89639353]
Epoch:63, Valid Loss: 0.394, mIoU: 0.9312079203763224
EarlyStopping counter: 29 out of 100
Epoch:64 [0/412], Loss: 0.544
Epoch:64 [10/412], Loss: 0.351
Epoch:64 [20/412], Loss: 0.531
Epoch:64 [30/412], Loss: 0.541
Epoch:64 [40/412], Loss: 0.452
Epoch:64 [50/412], Loss: 0.328
Epoch:64 [60/412], Loss: 0.745
Epoch:64 [70/412], Loss: 0.553
Epoch:64 [80/412], Loss: 0.524
Epoch:64 [90/412], Loss: 0.425
Epoch:64 [100/412], Loss: 0.519
Epoch:64 [110/412], Loss: 0.394
Epoch:64 [120/412], Loss: 0.418
Epoch:64 [130/412], Loss: 0.453
Epoch:64 [140/412], Loss: 0.523
Epoch:64 [150/412], Loss: 0.800
Epoch:64 [160/412], Loss: 0.499
Epoch:64 [170/412], Loss: 0.599
Epoch:64 [180/412], Loss: 0.477
Epoch:64 [190/412], Loss: 0.559
Epoch:64 [200/412], Loss: 0.426
Epoch:64 [210/412], Loss: 0.564
Epoch:64 [220/412], Loss: 0.496
Epoch:64 [230/412], Loss: 0.501
Epoch:64 [240/412], Loss: 0.642
Epoch:64 [250/412], Loss: 0.639
Epoch:64 [260/412], Loss: 0.474
Epoch:64 [270/412], Loss: 0.694
Epoch:64 [280/412], Loss: 0.541
Epoch:64 [290/412], Loss: 0.474
Epoch:64 [300/412], Loss: 0.462
Epoch:64 [310/412], Loss: 0.654
Epoch:64 [320/412], Loss: 0.417
Epoch:64 [330/412], Loss: 0.544
Epoch:64 [340/412], Loss: 0.483
Epoch:64 [350/412], Loss: 0.461
Epoch:64 [360/412], Loss: 0.445
Epoch:64 [370/412], Loss: 0.331
Epoch:64 [380/412], Loss: 0.409
Epoch:64 [390/412], Loss: 0.496
Epoch:64 [400/412], Loss: 0.468
Epoch:64 [410/412], Loss: 0.589
Epoch:64, Train IoU: [0.98480591 0.87347822 0.89727937]
Epoch:64, Valid Loss: 0.383, mIoU: 0.9311970547846693
EarlyStopping counter: 30 out of 100
Epoch:65 [0/412], Loss: 0.448
Epoch:65 [10/412], Loss: 0.361
Epoch:65 [20/412], Loss: 0.416
Epoch:65 [30/412], Loss: 0.423
Epoch:65 [40/412], Loss: 0.456
Epoch:65 [50/412], Loss: 0.752
Epoch:65 [60/412], Loss: 0.597
Epoch:65 [70/412], Loss: 0.489
Epoch:65 [80/412], Loss: 0.548
Epoch:65 [90/412], Loss: 0.358
Epoch:65 [100/412], Loss: 0.513
Epoch:65 [110/412], Loss: 0.461
Epoch:65 [120/412], Loss: 0.462
Epoch:65 [130/412], Loss: 0.627
Epoch:65 [140/412], Loss: 0.640
Epoch:65 [150/412], Loss: 0.407
Epoch:65 [160/412], Loss: 0.521
Epoch:65 [170/412], Loss: 0.552
Epoch:65 [180/412], Loss: 0.652
Epoch:65 [190/412], Loss: 0.732
Epoch:65 [200/412], Loss: 0.440
Epoch:65 [210/412], Loss: 0.545
Epoch:65 [220/412], Loss: 0.400
Epoch:65 [230/412], Loss: 0.675
Epoch:65 [240/412], Loss: 0.464
Epoch:65 [250/412], Loss: 0.602
Epoch:65 [260/412], Loss: 0.748
Epoch:65 [270/412], Loss: 0.331
Epoch:65 [280/412], Loss: 0.535
Epoch:65 [290/412], Loss: 0.484
Epoch:65 [300/412], Loss: 0.645
Epoch:65 [310/412], Loss: 0.563
Epoch:65 [320/412], Loss: 0.509
Epoch:65 [330/412], Loss: 0.613
Epoch:65 [340/412], Loss: 0.630
Epoch:65 [350/412], Loss: 0.397
Epoch:65 [360/412], Loss: 0.471
Epoch:65 [370/412], Loss: 0.450
Epoch:65 [380/412], Loss: 0.388
Epoch:65 [390/412], Loss: 0.533
Epoch:65 [400/412], Loss: 0.333
Epoch:65 [410/412], Loss: 0.572
Epoch:65, Train IoU: [0.98479334 0.87310923 0.89705331]
Epoch:65, Valid Loss: 0.372, mIoU: 0.931194450576157
EarlyStopping counter: 31 out of 100
Epoch:66 [0/412], Loss: 0.459
Epoch:66 [10/412], Loss: 0.315
Epoch:66 [20/412], Loss: 0.372
Epoch:66 [30/412], Loss: 0.435
Epoch:66 [40/412], Loss: 0.541
Epoch:66 [50/412], Loss: 0.526
Epoch:66 [60/412], Loss: 0.496
Epoch:66 [70/412], Loss: 0.524
Epoch:66 [80/412], Loss: 0.476
Epoch:66 [90/412], Loss: 0.750
Epoch:66 [100/412], Loss: 0.466
Epoch:66 [110/412], Loss: 0.697
Epoch:66 [120/412], Loss: 0.452
Epoch:66 [130/412], Loss: 0.406
Epoch:66 [140/412], Loss: 0.560
Epoch:66 [150/412], Loss: 0.483
Epoch:66 [160/412], Loss: 0.457
Epoch:66 [170/412], Loss: 0.366
Epoch:66 [180/412], Loss: 0.552
Epoch:66 [190/412], Loss: 0.507
Epoch:66 [200/412], Loss: 0.599
Epoch:66 [210/412], Loss: 0.471
Epoch:66 [220/412], Loss: 0.616
Epoch:66 [230/412], Loss: 0.803
Epoch:66 [240/412], Loss: 0.638
Epoch:66 [250/412], Loss: 0.476
Epoch:66 [260/412], Loss: 0.410
Epoch:66 [270/412], Loss: 0.550
Epoch:66 [280/412], Loss: 0.405
Epoch:66 [290/412], Loss: 0.556
Epoch:66 [300/412], Loss: 0.587
Epoch:66 [310/412], Loss: 0.584
Epoch:66 [320/412], Loss: 0.442
Epoch:66 [330/412], Loss: 0.455
Epoch:66 [340/412], Loss: 0.421
Epoch:66 [350/412], Loss: 0.429
Epoch:66 [360/412], Loss: 0.445
Epoch:66 [370/412], Loss: 0.728
Epoch:66 [380/412], Loss: 0.545
Epoch:66 [390/412], Loss: 0.510
Epoch:66 [400/412], Loss: 0.562
Epoch:66 [410/412], Loss: 0.586
Epoch:66, Train IoU: [0.98481425 0.87324818 0.89635648]
Epoch:66, Valid Loss: 0.361, mIoU: 0.9311904185553069
EarlyStopping counter: 32 out of 100
Epoch:67 [0/412], Loss: 0.505
Epoch:67 [10/412], Loss: 0.577
Epoch:67 [20/412], Loss: 0.524
Epoch:67 [30/412], Loss: 0.413
Epoch:67 [40/412], Loss: 0.588
Epoch:67 [50/412], Loss: 0.366
Epoch:67 [60/412], Loss: 0.320
Epoch:67 [70/412], Loss: 0.446
Epoch:67 [80/412], Loss: 0.880
Epoch:67 [90/412], Loss: 0.589
Epoch:67 [100/412], Loss: 0.556
Epoch:67 [110/412], Loss: 0.463
Epoch:67 [120/412], Loss: 0.471
Epoch:67 [130/412], Loss: 0.641
Epoch:67 [140/412], Loss: 0.607
Epoch:67 [150/412], Loss: 0.629
Epoch:67 [160/412], Loss: 0.397
Epoch:67 [170/412], Loss: 0.383
Epoch:67 [180/412], Loss: 0.625
Epoch:67 [190/412], Loss: 0.454
Epoch:67 [200/412], Loss: 0.434
Epoch:67 [210/412], Loss: 0.411
Epoch:67 [220/412], Loss: 0.348
Epoch:67 [230/412], Loss: 0.537
Epoch:67 [240/412], Loss: 0.457
Epoch:67 [250/412], Loss: 0.653
Epoch:67 [260/412], Loss: 0.434
Epoch:67 [270/412], Loss: 0.363
Epoch:67 [280/412], Loss: 0.496
Epoch:67 [290/412], Loss: 0.352
Epoch:67 [300/412], Loss: 0.301
Epoch:67 [310/412], Loss: 0.657
Epoch:67 [320/412], Loss: 0.364
Epoch:67 [330/412], Loss: 0.647
Epoch:67 [340/412], Loss: 0.433
Epoch:67 [350/412], Loss: 0.460
Epoch:67 [360/412], Loss: 0.477
Epoch:67 [370/412], Loss: 0.350
Epoch:67 [380/412], Loss: 0.529
Epoch:67 [390/412], Loss: 0.556
Epoch:67 [400/412], Loss: 0.377
Epoch:67 [410/412], Loss: 0.463
Epoch:67, Train IoU: [0.98475225 0.87299046 0.89628546]
Epoch:67, Valid Loss: 0.350, mIoU: 0.9311924930332397
EarlyStopping counter: 33 out of 100
Epoch:68 [0/412], Loss: 0.439
Epoch:68 [10/412], Loss: 0.481
Epoch:68 [20/412], Loss: 0.675
Epoch:68 [30/412], Loss: 0.360
Epoch:68 [40/412], Loss: 0.324
Epoch:68 [50/412], Loss: 0.571
Epoch:68 [60/412], Loss: 0.463
Epoch:68 [70/412], Loss: 0.477
Epoch:68 [80/412], Loss: 0.686
Epoch:68 [90/412], Loss: 0.336
Epoch:68 [100/412], Loss: 0.413
Epoch:68 [110/412], Loss: 0.457
Epoch:68 [120/412], Loss: 0.471
Epoch:68 [130/412], Loss: 0.620
Epoch:68 [140/412], Loss: 0.365
Epoch:68 [150/412], Loss: 0.398
Epoch:68 [160/412], Loss: 0.268
Epoch:68 [170/412], Loss: 0.478
Epoch:68 [180/412], Loss: 0.473
Epoch:68 [190/412], Loss: 0.489
Epoch:68 [200/412], Loss: 0.264
Epoch:68 [210/412], Loss: 0.662
Epoch:68 [220/412], Loss: 0.414
Epoch:68 [230/412], Loss: 0.472
Epoch:68 [240/412], Loss: 0.307
Epoch:68 [250/412], Loss: 0.339
Epoch:68 [260/412], Loss: 0.508
Epoch:68 [270/412], Loss: 0.459
Epoch:68 [280/412], Loss: 0.335
Epoch:68 [290/412], Loss: 0.454
Epoch:68 [300/412], Loss: 0.518
Epoch:68 [310/412], Loss: 0.346
Epoch:68 [320/412], Loss: 0.432
Epoch:68 [330/412], Loss: 0.460
Epoch:68 [340/412], Loss: 0.351
Epoch:68 [350/412], Loss: 0.649
Epoch:68 [360/412], Loss: 0.555
Epoch:68 [370/412], Loss: 0.590
Epoch:68 [380/412], Loss: 0.393
Epoch:68 [390/412], Loss: 0.329
Epoch:68 [400/412], Loss: 0.715
Epoch:68 [410/412], Loss: 0.359
Epoch:68, Train IoU: [0.98483478 0.87322621 0.89644331]
Epoch:68, Valid Loss: 0.339, mIoU: 0.9311886848037458
EarlyStopping counter: 34 out of 100
Epoch:69 [0/412], Loss: 0.497
Epoch:69 [10/412], Loss: 0.553
Epoch:69 [20/412], Loss: 0.518
Epoch:69 [30/412], Loss: 0.602
Epoch:69 [40/412], Loss: 0.445
Epoch:69 [50/412], Loss: 0.738
Epoch:69 [60/412], Loss: 0.388
Epoch:69 [70/412], Loss: 0.566
Epoch:69 [80/412], Loss: 0.388
Epoch:69 [90/412], Loss: 0.365
Epoch:69 [100/412], Loss: 0.306
Epoch:69 [110/412], Loss: 0.497
Epoch:69 [120/412], Loss: 0.535
Epoch:69 [130/412], Loss: 0.395
Epoch:69 [140/412], Loss: 0.509
Epoch:69 [150/412], Loss: 0.342
Epoch:69 [160/412], Loss: 0.415
Epoch:69 [170/412], Loss: 0.491
Epoch:69 [180/412], Loss: 0.484
Epoch:69 [190/412], Loss: 0.673
Epoch:69 [200/412], Loss: 0.447
Epoch:69 [210/412], Loss: 0.559
Epoch:69 [220/412], Loss: 0.323
Epoch:69 [230/412], Loss: 0.567
Epoch:69 [240/412], Loss: 0.318
Epoch:69 [250/412], Loss: 0.507
Epoch:69 [260/412], Loss: 0.347
Epoch:69 [270/412], Loss: 0.299
Epoch:69 [280/412], Loss: 0.464
Epoch:69 [290/412], Loss: 0.366
Epoch:69 [300/412], Loss: 0.646
Epoch:69 [310/412], Loss: 0.287
Epoch:69 [320/412], Loss: 0.408
Epoch:69 [330/412], Loss: 0.467
Epoch:69 [340/412], Loss: 0.684
Epoch:69 [350/412], Loss: 0.569
Epoch:69 [360/412], Loss: 0.655
Epoch:69 [370/412], Loss: 0.595
Epoch:69 [380/412], Loss: 0.411
Epoch:69 [390/412], Loss: 0.468
Epoch:69 [400/412], Loss: 0.392
Epoch:69 [410/412], Loss: 0.359
Epoch:69, Train IoU: [0.98479148 0.8730793  0.89676374]
Epoch:69, Valid Loss: 0.328, mIoU: 0.9311900746451682
EarlyStopping counter: 35 out of 100
Epoch:70 [0/412], Loss: 0.320
Epoch:70 [10/412], Loss: 0.328
Epoch:70 [20/412], Loss: 0.494
Epoch:70 [30/412], Loss: 0.526
Epoch:70 [40/412], Loss: 0.548
Epoch:70 [50/412], Loss: 0.451
Epoch:70 [60/412], Loss: 0.448
Epoch:70 [70/412], Loss: 0.634
Epoch:70 [80/412], Loss: 0.547
Epoch:70 [90/412], Loss: 0.318
Epoch:70 [100/412], Loss: 0.354
Epoch:70 [110/412], Loss: 0.351
Epoch:70 [120/412], Loss: 0.440
Epoch:70 [130/412], Loss: 0.700
Epoch:70 [140/412], Loss: 0.497
Epoch:70 [150/412], Loss: 0.568
Epoch:70 [160/412], Loss: 0.286
Epoch:70 [170/412], Loss: 0.434
Epoch:70 [180/412], Loss: 0.707
Epoch:70 [190/412], Loss: 0.450
Epoch:70 [200/412], Loss: 0.457
Epoch:70 [210/412], Loss: 0.315
Epoch:70 [220/412], Loss: 0.295
Epoch:70 [230/412], Loss: 0.421
Epoch:70 [240/412], Loss: 0.356
Epoch:70 [250/412], Loss: 0.437
Epoch:70 [260/412], Loss: 0.650
Epoch:70 [270/412], Loss: 0.412
Epoch:70 [280/412], Loss: 0.537
Epoch:70 [290/412], Loss: 0.479
Epoch:70 [300/412], Loss: 0.520
Epoch:70 [310/412], Loss: 0.360
Epoch:70 [320/412], Loss: 0.646
Epoch:70 [330/412], Loss: 0.500
Epoch:70 [340/412], Loss: 0.479
Epoch:70 [350/412], Loss: 0.624
Epoch:70 [360/412], Loss: 0.365
Epoch:70 [370/412], Loss: 0.508
Epoch:70 [380/412], Loss: 0.374
Epoch:70 [390/412], Loss: 0.467
Epoch:70 [400/412], Loss: 0.360
Epoch:70 [410/412], Loss: 0.439
Epoch:70, Train IoU: [0.98467467 0.87275499 0.89639392]
Epoch:70, Valid Loss: 0.317, mIoU: 0.9311888135551531
EarlyStopping counter: 36 out of 100
Epoch:71 [0/412], Loss: 0.458
Epoch:71 [10/412], Loss: 0.421
Epoch:71 [20/412], Loss: 0.391
Epoch:71 [30/412], Loss: 0.393
Epoch:71 [40/412], Loss: 0.469
Epoch:71 [50/412], Loss: 0.384
Epoch:71 [60/412], Loss: 0.434
Epoch:71 [70/412], Loss: 0.464
Epoch:71 [80/412], Loss: 0.315
Epoch:71 [90/412], Loss: 0.662
Epoch:71 [100/412], Loss: 0.568
Epoch:71 [110/412], Loss: 0.641
Epoch:71 [120/412], Loss: 0.386
Epoch:71 [130/412], Loss: 0.395
Epoch:71 [140/412], Loss: 0.463
Epoch:71 [150/412], Loss: 0.343
Epoch:71 [160/412], Loss: 0.542
Epoch:71 [170/412], Loss: 0.415
Epoch:71 [180/412], Loss: 0.436
Epoch:71 [190/412], Loss: 0.470
Epoch:71 [200/412], Loss: 0.427
Epoch:71 [210/412], Loss: 0.421
Epoch:71 [220/412], Loss: 0.348
Epoch:71 [230/412], Loss: 0.619
Epoch:71 [240/412], Loss: 0.742
Epoch:71 [250/412], Loss: 0.372
Epoch:71 [260/412], Loss: 0.362
Epoch:71 [270/412], Loss: 0.332
Epoch:71 [280/412], Loss: 0.367
Epoch:71 [290/412], Loss: 0.381
Epoch:71 [300/412], Loss: 0.469
Epoch:71 [310/412], Loss: 0.192
Epoch:71 [320/412], Loss: 0.455
Epoch:71 [330/412], Loss: 0.351
Epoch:71 [340/412], Loss: 0.749
Epoch:71 [350/412], Loss: 0.303
Epoch:71 [360/412], Loss: 0.425
Epoch:71 [370/412], Loss: 0.438
Epoch:71 [380/412], Loss: 0.615
Epoch:71 [390/412], Loss: 0.376
Epoch:71 [400/412], Loss: 0.404
Epoch:71 [410/412], Loss: 0.469
Epoch:71, Train IoU: [0.98478388 0.87320457 0.89674862]
Epoch:71, Valid Loss: 0.306, mIoU: 0.9311822648221444
EarlyStopping counter: 37 out of 100
Epoch:72 [0/412], Loss: 0.558
Epoch:72 [10/412], Loss: 0.546
Epoch:72 [20/412], Loss: 0.301
Epoch:72 [30/412], Loss: 0.385
Epoch:72 [40/412], Loss: 0.318
Epoch:72 [50/412], Loss: 0.402
Epoch:72 [60/412], Loss: 0.319
Epoch:72 [70/412], Loss: 0.259
Epoch:72 [80/412], Loss: 0.436
Epoch:72 [90/412], Loss: 0.463
Epoch:72 [100/412], Loss: 0.703
Epoch:72 [110/412], Loss: 0.528
Epoch:72 [120/412], Loss: 0.312
Epoch:72 [130/412], Loss: 0.497
Epoch:72 [140/412], Loss: 0.376
Epoch:72 [150/412], Loss: 0.237
Epoch:72 [160/412], Loss: 0.544
Epoch:72 [170/412], Loss: 0.603
Epoch:72 [180/412], Loss: 0.682
Epoch:72 [190/412], Loss: 0.424
Epoch:72 [200/412], Loss: 0.476
Epoch:72 [210/412], Loss: 0.591
Epoch:72 [220/412], Loss: 0.317
Epoch:72 [230/412], Loss: 0.353
Epoch:72 [240/412], Loss: 0.305
Epoch:72 [250/412], Loss: 0.532
Epoch:72 [260/412], Loss: 0.304
Epoch:72 [270/412], Loss: 0.422
Epoch:72 [280/412], Loss: 0.466
Epoch:72 [290/412], Loss: 0.521
Epoch:72 [300/412], Loss: 0.285
Epoch:72 [310/412], Loss: 0.421
Epoch:72 [320/412], Loss: 0.306
Epoch:72 [330/412], Loss: 0.363
Epoch:72 [340/412], Loss: 0.396
Epoch:72 [350/412], Loss: 0.608
Epoch:72 [360/412], Loss: 0.230
Epoch:72 [370/412], Loss: 0.403
Epoch:72 [380/412], Loss: 0.337
Epoch:72 [390/412], Loss: 0.347
Epoch:72 [400/412], Loss: 0.583
Epoch:72 [410/412], Loss: 0.359
Epoch:72, Train IoU: [0.98477537 0.87289149 0.89632831]
Epoch:72, Valid Loss: 0.295, mIoU: 0.9311815842099788
EarlyStopping counter: 38 out of 100
Epoch:73 [0/412], Loss: 0.510
Epoch:73 [10/412], Loss: 0.335
Epoch:73 [20/412], Loss: 0.558
Epoch:73 [30/412], Loss: 0.507
Epoch:73 [40/412], Loss: 0.246
Epoch:73 [50/412], Loss: 0.588
Epoch:73 [60/412], Loss: 0.293
Epoch:73 [70/412], Loss: 0.573
Epoch:73 [80/412], Loss: 0.321
Epoch:73 [90/412], Loss: 0.690
Epoch:73 [100/412], Loss: 0.345
Epoch:73 [110/412], Loss: 0.428
Epoch:73 [120/412], Loss: 0.543
Epoch:73 [130/412], Loss: 0.412
Epoch:73 [140/412], Loss: 0.306
Epoch:73 [150/412], Loss: 0.401
Epoch:73 [160/412], Loss: 0.345
Epoch:73 [170/412], Loss: 0.609
Epoch:73 [180/412], Loss: 0.362
Epoch:73 [190/412], Loss: 0.510
Epoch:73 [200/412], Loss: 0.375
Epoch:73 [210/412], Loss: 0.492
Epoch:73 [220/412], Loss: 0.395
Epoch:73 [230/412], Loss: 0.565
Epoch:73 [240/412], Loss: 0.408
Epoch:73 [250/412], Loss: 0.357
Epoch:73 [260/412], Loss: 0.393
Epoch:73 [270/412], Loss: 0.264
Epoch:73 [280/412], Loss: 0.508
Epoch:73 [290/412], Loss: 0.579
Epoch:73 [300/412], Loss: 0.216
Epoch:73 [310/412], Loss: 0.333
Epoch:73 [320/412], Loss: 0.389
Epoch:73 [330/412], Loss: 0.428
Epoch:73 [340/412], Loss: 0.146
Epoch:73 [350/412], Loss: 0.220
Epoch:73 [360/412], Loss: 0.476
Epoch:73 [370/412], Loss: 0.429
Epoch:73 [380/412], Loss: 0.333
Epoch:73 [390/412], Loss: 0.417
Epoch:73 [400/412], Loss: 0.476
Epoch:73 [410/412], Loss: 0.653
Epoch:73, Train IoU: [0.98478636 0.8730477  0.8961346 ]
Epoch:73, Valid Loss: 0.284, mIoU: 0.931180779021792
EarlyStopping counter: 39 out of 100
Epoch:74 [0/412], Loss: 0.500
Epoch:74 [10/412], Loss: 0.441
Epoch:74 [20/412], Loss: 0.323
Epoch:74 [30/412], Loss: 0.425
Epoch:74 [40/412], Loss: 0.407
Epoch:74 [50/412], Loss: 0.323
Epoch:74 [60/412], Loss: 0.564
Epoch:74 [70/412], Loss: 0.332
Epoch:74 [80/412], Loss: 0.465
Epoch:74 [90/412], Loss: 0.551
Epoch:74 [100/412], Loss: 0.497
Epoch:74 [110/412], Loss: 0.333
Epoch:74 [120/412], Loss: 0.253
Epoch:74 [130/412], Loss: 0.353
Epoch:74 [140/412], Loss: 0.356
Epoch:74 [150/412], Loss: 0.392
Epoch:74 [160/412], Loss: 0.608
Epoch:74 [170/412], Loss: 0.433
Epoch:74 [180/412], Loss: 0.445
Epoch:74 [190/412], Loss: 0.445
Epoch:74 [200/412], Loss: 0.439
Epoch:74 [210/412], Loss: 0.574
Epoch:74 [220/412], Loss: 0.364
Epoch:74 [230/412], Loss: 0.454
Epoch:74 [240/412], Loss: 0.470
Epoch:74 [250/412], Loss: 0.426
Epoch:74 [260/412], Loss: 0.718
Epoch:74 [270/412], Loss: 0.716
Epoch:74 [280/412], Loss: 0.304
Epoch:74 [290/412], Loss: 0.411
Epoch:74 [300/412], Loss: 0.573
Epoch:74 [310/412], Loss: 0.330
Epoch:74 [320/412], Loss: 0.448
Epoch:74 [330/412], Loss: 0.451
Epoch:74 [340/412], Loss: 0.422
Epoch:74 [350/412], Loss: 0.344
Epoch:74 [360/412], Loss: 0.611
Epoch:74 [370/412], Loss: 0.205
Epoch:74 [380/412], Loss: 0.224
Epoch:74 [390/412], Loss: 0.373
Epoch:74 [400/412], Loss: 0.470
Epoch:74 [410/412], Loss: 0.474
Epoch:74, Train IoU: [0.9847366  0.87303705 0.8966279 ]
Epoch:74, Valid Loss: 0.273, mIoU: 0.9311843645413932
Validation metric decreased (0.264443 --> 0.272650).  Saving model ...
Epoch:75 [0/412], Loss: 0.286
Epoch:75 [10/412], Loss: 0.229
Epoch:75 [20/412], Loss: 0.305
Epoch:75 [30/412], Loss: 0.334
Epoch:75 [40/412], Loss: 0.485
Epoch:75 [50/412], Loss: 0.372
Epoch:75 [60/412], Loss: 0.595
Epoch:75 [70/412], Loss: 0.307
Epoch:75 [80/412], Loss: 0.382
Epoch:75 [90/412], Loss: 0.301
Epoch:75 [100/412], Loss: 0.278
Epoch:75 [110/412], Loss: 0.325
Epoch:75 [120/412], Loss: 0.572
Epoch:75 [130/412], Loss: 0.383
Epoch:75 [140/412], Loss: 0.551
Epoch:75 [150/412], Loss: 0.274
Epoch:75 [160/412], Loss: 0.352
Epoch:75 [170/412], Loss: 0.436
Epoch:75 [180/412], Loss: 0.283
Epoch:75 [190/412], Loss: 0.460
Epoch:75 [200/412], Loss: 0.345
Epoch:75 [210/412], Loss: 0.444
Epoch:75 [220/412], Loss: 0.282
Epoch:75 [230/412], Loss: 0.229
Epoch:75 [240/412], Loss: 0.389
Epoch:75 [250/412], Loss: 0.441
Epoch:75 [260/412], Loss: 0.353
Epoch:75 [270/412], Loss: 0.450
Epoch:75 [280/412], Loss: 0.399
Epoch:75 [290/412], Loss: 0.301
Epoch:75 [300/412], Loss: 0.395
Epoch:75 [310/412], Loss: 0.302
Epoch:75 [320/412], Loss: 0.333
Epoch:75 [330/412], Loss: 0.325
Epoch:75 [340/412], Loss: 0.396
Epoch:75 [350/412], Loss: 0.342
Epoch:75 [360/412], Loss: 0.450
Epoch:75 [370/412], Loss: 0.462
Epoch:75 [380/412], Loss: 0.332
Epoch:75 [390/412], Loss: 0.413
Epoch:75 [400/412], Loss: 0.507
Epoch:75 [410/412], Loss: 0.260
Epoch:75, Train IoU: [0.98475549 0.87289803 0.89593543]
Epoch:75, Valid Loss: 0.262, mIoU: 0.9311857217580758
Validation metric decreased (0.272650 --> 0.261665).  Saving model ...
Epoch:76 [0/412], Loss: 0.365
Epoch:76 [10/412], Loss: 0.422
Epoch:76 [20/412], Loss: 0.426
Epoch:76 [30/412], Loss: 0.309
Epoch:76 [40/412], Loss: 0.667
Epoch:76 [50/412], Loss: 0.212
Epoch:76 [60/412], Loss: 0.529
Epoch:76 [70/412], Loss: 0.461
Epoch:76 [80/412], Loss: 0.321
Epoch:76 [90/412], Loss: 0.229
Epoch:76 [100/412], Loss: 0.427
Epoch:76 [110/412], Loss: 0.395
Epoch:76 [120/412], Loss: 0.330
Epoch:76 [130/412], Loss: 0.286
Epoch:76 [140/412], Loss: 0.304
Epoch:76 [150/412], Loss: 0.411
Epoch:76 [160/412], Loss: 0.397
Epoch:76 [170/412], Loss: 0.340
Epoch:76 [180/412], Loss: 0.515
Epoch:76 [190/412], Loss: 0.240
Epoch:76 [200/412], Loss: 0.492
Epoch:76 [210/412], Loss: 0.370
Epoch:76 [220/412], Loss: 0.348
Epoch:76 [230/412], Loss: 0.313
Epoch:76 [240/412], Loss: 0.478
Epoch:76 [250/412], Loss: 0.277
Epoch:76 [260/412], Loss: 0.592
Epoch:76 [270/412], Loss: 0.448
Epoch:76 [280/412], Loss: 0.526
Epoch:76 [290/412], Loss: 0.379
Epoch:76 [300/412], Loss: 0.244
Epoch:76 [310/412], Loss: 0.454
Epoch:76 [320/412], Loss: 0.409
Epoch:76 [330/412], Loss: 0.517
Epoch:76 [340/412], Loss: 0.442
Epoch:76 [350/412], Loss: 0.320
Epoch:76 [360/412], Loss: 0.350
Epoch:76 [370/412], Loss: 0.381
Epoch:76 [380/412], Loss: 0.449
Epoch:76 [390/412], Loss: 0.274
Epoch:76 [400/412], Loss: 0.216
Epoch:76 [410/412], Loss: 0.319
Epoch:76, Train IoU: [0.984769   0.87302609 0.89613863]
Epoch:76, Valid Loss: 0.251, mIoU: 0.9311839564641673
Validation metric decreased (0.261665 --> 0.250676).  Saving model ...
Epoch:77 [0/412], Loss: 0.462
Epoch:77 [10/412], Loss: 0.464
Epoch:77 [20/412], Loss: 0.382
Epoch:77 [30/412], Loss: 0.335
Epoch:77 [40/412], Loss: 0.257
Epoch:77 [50/412], Loss: 0.457
Epoch:77 [60/412], Loss: 0.538
Epoch:77 [70/412], Loss: 0.421
Epoch:77 [80/412], Loss: 0.463
Epoch:77 [90/412], Loss: 0.512
Epoch:77 [100/412], Loss: 0.388
Epoch:77 [110/412], Loss: 0.476
Epoch:77 [120/412], Loss: 0.352
Epoch:77 [130/412], Loss: 0.319
Epoch:77 [140/412], Loss: 0.274
Epoch:77 [150/412], Loss: 0.480
Epoch:77 [160/412], Loss: 0.384
Epoch:77 [170/412], Loss: 0.398
Epoch:77 [180/412], Loss: 0.475
Epoch:77 [190/412], Loss: 0.363
Epoch:77 [200/412], Loss: 0.301
Epoch:77 [210/412], Loss: 0.522
Epoch:77 [220/412], Loss: 0.431
Epoch:77 [230/412], Loss: 0.337
Epoch:77 [240/412], Loss: 0.308
Epoch:77 [250/412], Loss: 0.408
Epoch:77 [260/412], Loss: 0.342
Epoch:77 [270/412], Loss: 0.338
Epoch:77 [280/412], Loss: 0.336
Epoch:77 [290/412], Loss: 0.358
Epoch:77 [300/412], Loss: 0.395
Epoch:77 [310/412], Loss: 0.480
Epoch:77 [320/412], Loss: 0.299
Epoch:77 [330/412], Loss: 0.417
Epoch:77 [340/412], Loss: 0.315
Epoch:77 [350/412], Loss: 0.196
Epoch:77 [360/412], Loss: 0.299
Epoch:77 [370/412], Loss: 0.588
Epoch:77 [380/412], Loss: 0.360
Epoch:77 [390/412], Loss: 0.498
Epoch:77 [400/412], Loss: 0.364
Epoch:77 [410/412], Loss: 0.495
Epoch:77, Train IoU: [0.9846942  0.87249244 0.89602961]
Epoch:77, Valid Loss: 0.240, mIoU: 0.9311827289791409
Validation metric decreased (0.250676 --> 0.239685).  Saving model ...
Epoch:78 [0/412], Loss: 0.383
Epoch:78 [10/412], Loss: 0.299
Epoch:78 [20/412], Loss: 0.490
Epoch:78 [30/412], Loss: 0.381
Epoch:78 [40/412], Loss: 0.399
Epoch:78 [50/412], Loss: 0.303
Epoch:78 [60/412], Loss: 0.305
Epoch:78 [70/412], Loss: 0.258
Epoch:78 [80/412], Loss: 0.198
Epoch:78 [90/412], Loss: 0.314
Epoch:78 [100/412], Loss: 0.486
Epoch:78 [110/412], Loss: 0.434
Epoch:78 [120/412], Loss: 0.413
Epoch:78 [130/412], Loss: 0.337
Epoch:78 [140/412], Loss: 0.339
Epoch:78 [150/412], Loss: 0.357
Epoch:78 [160/412], Loss: 0.380
Epoch:78 [170/412], Loss: 0.206
Epoch:78 [180/412], Loss: 0.396
Epoch:78 [190/412], Loss: 0.390
Epoch:78 [200/412], Loss: 0.349
Epoch:78 [210/412], Loss: 0.212
Epoch:78 [220/412], Loss: 0.271
Epoch:78 [230/412], Loss: 0.310
Epoch:78 [240/412], Loss: 0.273
Epoch:78 [250/412], Loss: 0.321
Epoch:78 [260/412], Loss: 0.608
Epoch:78 [270/412], Loss: 0.337
Epoch:78 [280/412], Loss: 0.181
Epoch:78 [290/412], Loss: 0.634
Epoch:78 [300/412], Loss: 0.501
Epoch:78 [310/412], Loss: 0.372
Epoch:78 [320/412], Loss: 0.539
Epoch:78 [330/412], Loss: 0.380
Epoch:78 [340/412], Loss: 0.382
Epoch:78 [350/412], Loss: 0.236
Epoch:78 [360/412], Loss: 0.398
Epoch:78 [370/412], Loss: 0.297
Epoch:78 [380/412], Loss: 0.468
Epoch:78 [390/412], Loss: 0.408
Epoch:78 [400/412], Loss: 0.541
Epoch:78 [410/412], Loss: 0.306
Epoch:78, Train IoU: [0.98476653 0.87295476 0.8961951 ]
Epoch:78, Valid Loss: 0.229, mIoU: 0.9311778479868882
Validation metric decreased (0.239685 --> 0.228696).  Saving model ...
Epoch:79 [0/412], Loss: 0.299
Epoch:79 [10/412], Loss: 0.350
Epoch:79 [20/412], Loss: 0.358
Epoch:79 [30/412], Loss: 0.355
Epoch:79 [40/412], Loss: 0.290
Epoch:79 [50/412], Loss: 0.486
Epoch:79 [60/412], Loss: 0.407
Epoch:79 [70/412], Loss: 0.196
Epoch:79 [80/412], Loss: 0.265
Epoch:79 [90/412], Loss: 0.565
Epoch:79 [100/412], Loss: 0.289
Epoch:79 [110/412], Loss: 0.254
Epoch:79 [120/412], Loss: 0.263
Epoch:79 [130/412], Loss: 0.337
Epoch:79 [140/412], Loss: 0.396
Epoch:79 [150/412], Loss: 0.357
Epoch:79 [160/412], Loss: 0.523
Epoch:79 [170/412], Loss: 0.599
Epoch:79 [180/412], Loss: 0.441
Epoch:79 [190/412], Loss: 0.266
Epoch:79 [200/412], Loss: 0.342
Epoch:79 [210/412], Loss: 0.380
Epoch:79 [220/412], Loss: 0.388
Epoch:79 [230/412], Loss: 0.237
Epoch:79 [240/412], Loss: 0.404
Epoch:79 [250/412], Loss: 0.352
Epoch:79 [260/412], Loss: 0.380
Epoch:79 [270/412], Loss: 0.344
Epoch:79 [280/412], Loss: 0.242
Epoch:79 [290/412], Loss: 0.500
Epoch:79 [300/412], Loss: 0.205
Epoch:79 [310/412], Loss: 0.352
Epoch:79 [320/412], Loss: 0.260
Epoch:79 [330/412], Loss: 0.480
Epoch:79 [340/412], Loss: 0.381
Epoch:79 [350/412], Loss: 0.346
Epoch:79 [360/412], Loss: 0.237
Epoch:79 [370/412], Loss: 0.314
Epoch:79 [380/412], Loss: 0.376
Epoch:79 [390/412], Loss: 0.230
Epoch:79 [400/412], Loss: 0.465
Epoch:79 [410/412], Loss: 0.215
Epoch:79, Train IoU: [0.98466409 0.87247067 0.89622905]
Epoch:79, Valid Loss: 0.218, mIoU: 0.9311783218887403
Validation metric decreased (0.228696 --> 0.217702).  Saving model ...
Epoch:80 [0/412], Loss: 0.298
Epoch:80 [10/412], Loss: 0.328
Epoch:80 [20/412], Loss: 0.444
Epoch:80 [30/412], Loss: 0.312
Epoch:80 [40/412], Loss: 0.336
Epoch:80 [50/412], Loss: 0.258
Epoch:80 [60/412], Loss: 0.392
Epoch:80 [70/412], Loss: 0.335
Epoch:80 [80/412], Loss: 0.343
Epoch:80 [90/412], Loss: 0.373
Epoch:80 [100/412], Loss: 0.340
Epoch:80 [110/412], Loss: 0.275
Epoch:80 [120/412], Loss: 0.320
Epoch:80 [130/412], Loss: 0.372
Epoch:80 [140/412], Loss: 0.515
Epoch:80 [150/412], Loss: 0.199
Epoch:80 [160/412], Loss: 0.133
Epoch:80 [170/412], Loss: 0.413
Epoch:80 [180/412], Loss: 0.568
Epoch:80 [190/412], Loss: 0.213
Epoch:80 [200/412], Loss: 0.241
Epoch:80 [210/412], Loss: 0.226
Epoch:80 [220/412], Loss: 0.302
Epoch:80 [230/412], Loss: 0.280
Epoch:80 [240/412], Loss: 0.297
Epoch:80 [250/412], Loss: 0.260
Epoch:80 [260/412], Loss: 0.220
Epoch:80 [270/412], Loss: 0.414
Epoch:80 [280/412], Loss: 0.336
Epoch:80 [290/412], Loss: 0.307
Epoch:80 [300/412], Loss: 0.353
Epoch:80 [310/412], Loss: 0.296
Epoch:80 [320/412], Loss: 0.790
Epoch:80 [330/412], Loss: 0.242
Epoch:80 [340/412], Loss: 0.605
Epoch:80 [350/412], Loss: 0.456
Epoch:80 [360/412], Loss: 0.326
Epoch:80 [370/412], Loss: 0.142
Epoch:80 [380/412], Loss: 0.231
Epoch:80 [390/412], Loss: 0.284
Epoch:80 [400/412], Loss: 0.346
Epoch:80 [410/412], Loss: 0.251
Epoch:80, Train IoU: [0.98476988 0.87297277 0.89676435]
Epoch:80, Valid Loss: 0.207, mIoU: 0.9311823465139145
Validation metric decreased (0.217702 --> 0.206721).  Saving model ...
Epoch:81 [0/412], Loss: 0.134
Epoch:81 [10/412], Loss: 0.486
Epoch:81 [20/412], Loss: 0.251
Epoch:81 [30/412], Loss: 0.700
Epoch:81 [40/412], Loss: 0.228
Epoch:81 [50/412], Loss: 0.173
Epoch:81 [60/412], Loss: 0.302
Epoch:81 [70/412], Loss: 0.203
Epoch:81 [80/412], Loss: 0.421
Epoch:81 [90/412], Loss: 0.381
Epoch:81 [100/412], Loss: 0.187
Epoch:81 [110/412], Loss: 0.334
Epoch:81 [120/412], Loss: 0.367
Epoch:81 [130/412], Loss: 0.421
Epoch:81 [140/412], Loss: 0.364
Epoch:81 [150/412], Loss: 0.245
Epoch:81 [160/412], Loss: 0.219
Epoch:81 [170/412], Loss: 0.320
Epoch:81 [180/412], Loss: 0.379
Epoch:81 [190/412], Loss: 0.278
Epoch:81 [200/412], Loss: 0.500
Epoch:81 [210/412], Loss: 0.527
Epoch:81 [220/412], Loss: 0.262
Epoch:81 [230/412], Loss: 0.354
Epoch:81 [240/412], Loss: 0.484
Epoch:81 [250/412], Loss: 0.594
Epoch:81 [260/412], Loss: 0.347
Epoch:81 [270/412], Loss: 0.218
Epoch:81 [280/412], Loss: 0.208
Epoch:81 [290/412], Loss: 0.558
Epoch:81 [300/412], Loss: 0.220
Epoch:81 [310/412], Loss: 0.519
Epoch:81 [320/412], Loss: 0.345
Epoch:81 [330/412], Loss: 0.430
Epoch:81 [340/412], Loss: 0.248
Epoch:81 [350/412], Loss: 0.432
Epoch:81 [360/412], Loss: 0.341
Epoch:81 [370/412], Loss: 0.394
Epoch:81 [380/412], Loss: 0.390
Epoch:81 [390/412], Loss: 0.215
Epoch:81 [400/412], Loss: 0.529
Epoch:81 [410/412], Loss: 0.210
Epoch:81, Train IoU: [0.98469763 0.87245714 0.8962335 ]
Epoch:81, Valid Loss: 0.196, mIoU: 0.9311831780986909
Validation metric decreased (0.206721 --> 0.195727).  Saving model ...
Epoch:82 [0/412], Loss: 0.471
Epoch:82 [10/412], Loss: 0.241
Epoch:82 [20/412], Loss: 0.327
Epoch:82 [30/412], Loss: 0.283
Epoch:82 [40/412], Loss: 0.224
Epoch:82 [50/412], Loss: 0.235
Epoch:82 [60/412], Loss: 0.321
Epoch:82 [70/412], Loss: 0.299
Epoch:82 [80/412], Loss: 0.238
Epoch:82 [90/412], Loss: 0.312
Epoch:82 [100/412], Loss: 0.337
Epoch:82 [110/412], Loss: 0.165
Epoch:82 [120/412], Loss: 0.151
Epoch:82 [130/412], Loss: 0.342
Epoch:82 [140/412], Loss: 0.293
Epoch:82 [150/412], Loss: 0.275
Epoch:82 [160/412], Loss: 0.353
Epoch:82 [170/412], Loss: 0.508
Epoch:82 [180/412], Loss: 0.251
Epoch:82 [190/412], Loss: 0.284
Epoch:82 [200/412], Loss: 0.197
Epoch:82 [210/412], Loss: 0.323
Epoch:82 [220/412], Loss: 0.395
Epoch:82 [230/412], Loss: 0.308
Epoch:82 [240/412], Loss: 0.337
Epoch:82 [250/412], Loss: 0.448
Epoch:82 [260/412], Loss: 0.391
Epoch:82 [270/412], Loss: 0.366
Epoch:82 [280/412], Loss: 0.128
Epoch:82 [290/412], Loss: 0.393
Epoch:82 [300/412], Loss: 0.167
Epoch:82 [310/412], Loss: 0.272
Epoch:82 [320/412], Loss: 0.288
Epoch:82 [330/412], Loss: 0.395
Epoch:82 [340/412], Loss: 0.184
Epoch:82 [350/412], Loss: 0.363
Epoch:82 [360/412], Loss: 0.283
Epoch:82 [370/412], Loss: 0.352
Epoch:82 [380/412], Loss: 0.428
Epoch:82 [390/412], Loss: 0.253
Epoch:82 [400/412], Loss: 0.488
Epoch:82 [410/412], Loss: 0.249
Epoch:82, Train IoU: [0.98480714 0.8733589  0.89660234]
Epoch:82, Valid Loss: 0.185, mIoU: 0.9311847044514877
Validation metric decreased (0.195727 --> 0.184731).  Saving model ...
Epoch:83 [0/412], Loss: 0.591
Epoch:83 [10/412], Loss: 0.129
Epoch:83 [20/412], Loss: 0.302
Epoch:83 [30/412], Loss: 0.563
Epoch:83 [40/412], Loss: 0.192
Epoch:83 [50/412], Loss: 0.292
Epoch:83 [60/412], Loss: 0.359
Epoch:83 [70/412], Loss: 0.441
Epoch:83 [80/412], Loss: 0.202
Epoch:83 [90/412], Loss: 0.309
Epoch:83 [100/412], Loss: 0.192
Epoch:83 [110/412], Loss: 0.572
Epoch:83 [120/412], Loss: 0.154
Epoch:83 [130/412], Loss: 0.270
Epoch:83 [140/412], Loss: 0.458
Epoch:83 [150/412], Loss: 0.261
Epoch:83 [160/412], Loss: 0.370
Epoch:83 [170/412], Loss: 0.243
Epoch:83 [180/412], Loss: 0.341
Epoch:83 [190/412], Loss: 0.298
Epoch:83 [200/412], Loss: 0.352
Epoch:83 [210/412], Loss: 0.219
Epoch:83 [220/412], Loss: 0.313
Epoch:83 [230/412], Loss: 0.210
Epoch:83 [240/412], Loss: 0.390
Epoch:83 [250/412], Loss: 0.120
Epoch:83 [260/412], Loss: 0.142
Epoch:83 [270/412], Loss: 0.411
Epoch:83 [280/412], Loss: 0.299
Epoch:83 [290/412], Loss: 0.286
Epoch:83 [300/412], Loss: 0.433
Epoch:83 [310/412], Loss: 0.292
Epoch:83 [320/412], Loss: 0.264
Epoch:83 [330/412], Loss: 0.277
Epoch:83 [340/412], Loss: 0.274
Epoch:83 [350/412], Loss: 0.217
Epoch:83 [360/412], Loss: 0.183
Epoch:83 [370/412], Loss: 0.217
Epoch:83 [380/412], Loss: 0.442
Epoch:83 [390/412], Loss: 0.213
Epoch:83 [400/412], Loss: 0.497
Epoch:83 [410/412], Loss: 0.357
Epoch:83, Train IoU: [0.98464075 0.87208667 0.89574691]
Epoch:83, Valid Loss: 0.174, mIoU: 0.9311861758061292
Validation metric decreased (0.184731 --> 0.173739).  Saving model ...
Epoch:84 [0/412], Loss: 0.402
Epoch:84 [10/412], Loss: 0.553
Epoch:84 [20/412], Loss: 0.230
Epoch:84 [30/412], Loss: 0.325
Epoch:84 [40/412], Loss: 0.248
Epoch:84 [50/412], Loss: 0.427
Epoch:84 [60/412], Loss: 0.394
Epoch:84 [70/412], Loss: 0.143
Epoch:84 [80/412], Loss: 0.259
Epoch:84 [90/412], Loss: 1.000
Epoch:84 [100/412], Loss: 0.292
Epoch:84 [110/412], Loss: 0.349
Epoch:84 [120/412], Loss: 0.228
Epoch:84 [130/412], Loss: 0.324
Epoch:84 [140/412], Loss: 0.314
Epoch:84 [150/412], Loss: 0.300
Epoch:84 [160/412], Loss: 0.520
Epoch:84 [170/412], Loss: 0.141
Epoch:84 [180/412], Loss: 0.370
Epoch:84 [190/412], Loss: 0.259
Epoch:84 [200/412], Loss: 0.299
Epoch:84 [210/412], Loss: 0.264
Epoch:84 [220/412], Loss: 0.338
Epoch:84 [230/412], Loss: 0.362
Epoch:84 [240/412], Loss: 0.491
Epoch:84 [250/412], Loss: 0.388
Epoch:84 [260/412], Loss: 0.470
Epoch:84 [270/412], Loss: 0.311
Epoch:84 [280/412], Loss: 0.263
Epoch:84 [290/412], Loss: 0.453
Epoch:84 [300/412], Loss: 0.383
Epoch:84 [310/412], Loss: 0.330
Epoch:84 [320/412], Loss: 0.420
Epoch:84 [330/412], Loss: 0.268
Epoch:84 [340/412], Loss: 0.290
Epoch:84 [350/412], Loss: 0.300
Epoch:84 [360/412], Loss: 0.349
Epoch:84 [370/412], Loss: 0.397
Epoch:84 [380/412], Loss: 0.281
Epoch:84 [390/412], Loss: 0.339
Epoch:84 [400/412], Loss: 0.524
Epoch:84 [410/412], Loss: 0.239
Epoch:84, Train IoU: [0.98479    0.87293339 0.89551681]
Epoch:84, Valid Loss: 0.163, mIoU: 0.9311881263895345
Validation metric decreased (0.173739 --> 0.162750).  Saving model ...
Epoch:85 [0/412], Loss: 0.274
Epoch:85 [10/412], Loss: 0.142
Epoch:85 [20/412], Loss: 0.338
Epoch:85 [30/412], Loss: 0.321
Epoch:85 [40/412], Loss: 0.204
Epoch:85 [50/412], Loss: 0.337
Epoch:85 [60/412], Loss: 0.401
Epoch:85 [70/412], Loss: 0.332
Epoch:85 [80/412], Loss: 0.149
Epoch:85 [90/412], Loss: 0.323
Epoch:85 [100/412], Loss: 0.097
Epoch:85 [110/412], Loss: 0.225
Epoch:85 [120/412], Loss: 0.202
Epoch:85 [130/412], Loss: 0.370
Epoch:85 [140/412], Loss: 0.061
Epoch:85 [150/412], Loss: 0.261
Epoch:85 [160/412], Loss: 0.164
Epoch:85 [170/412], Loss: 0.288
Epoch:85 [180/412], Loss: 0.386
Epoch:85 [190/412], Loss: 0.376
Epoch:85 [200/412], Loss: 0.306
Epoch:85 [210/412], Loss: 0.243
Epoch:85 [220/412], Loss: 0.259
Epoch:85 [230/412], Loss: 0.214
Epoch:85 [240/412], Loss: 0.275
Epoch:85 [250/412], Loss: 0.195
Epoch:85 [260/412], Loss: 0.267
Epoch:85 [270/412], Loss: 0.507
Epoch:85 [280/412], Loss: 0.288
Epoch:85 [290/412], Loss: 0.141
Epoch:85 [300/412], Loss: 0.341
Epoch:85 [310/412], Loss: 0.260
Epoch:85 [320/412], Loss: 0.343
Epoch:85 [330/412], Loss: 0.335
Epoch:85 [340/412], Loss: 0.355
Epoch:85 [350/412], Loss: 0.379
Epoch:85 [360/412], Loss: 0.263
Epoch:85 [370/412], Loss: 0.283
Epoch:85 [380/412], Loss: 0.509
Epoch:85 [390/412], Loss: 0.399
Epoch:85 [400/412], Loss: 0.318
Epoch:85 [410/412], Loss: 0.397
Epoch:85, Train IoU: [0.98477362 0.8730269  0.89605211]
Epoch:85, Valid Loss: 0.152, mIoU: 0.9311912459583064
Validation metric decreased (0.162750 --> 0.151756).  Saving model ...
Epoch:86 [0/412], Loss: 0.361
Epoch:86 [10/412], Loss: 0.068
Epoch:86 [20/412], Loss: 0.400
Epoch:86 [30/412], Loss: 0.323
Epoch:86 [40/412], Loss: 0.405
Epoch:86 [50/412], Loss: 0.285
Epoch:86 [60/412], Loss: 0.113
Epoch:86 [70/412], Loss: 0.247
Epoch:86 [80/412], Loss: 0.275
Epoch:86 [90/412], Loss: 0.360
Epoch:86 [100/412], Loss: 0.217
Epoch:86 [110/412], Loss: 0.563
Epoch:86 [120/412], Loss: 0.244
Epoch:86 [130/412], Loss: 0.157
Epoch:86 [140/412], Loss: 0.199
Epoch:86 [150/412], Loss: 0.185
Epoch:86 [160/412], Loss: 0.103
Epoch:86 [170/412], Loss: 0.359
Epoch:86 [180/412], Loss: 0.268
Epoch:86 [190/412], Loss: 0.238
Epoch:86 [200/412], Loss: 0.237
Epoch:86 [210/412], Loss: 0.334
Epoch:86 [220/412], Loss: 0.299
Epoch:86 [230/412], Loss: 0.448
Epoch:86 [240/412], Loss: 0.390
Epoch:86 [250/412], Loss: 0.162
Epoch:86 [260/412], Loss: 0.289
Epoch:86 [270/412], Loss: 0.287
Epoch:86 [280/412], Loss: 0.498
Epoch:86 [290/412], Loss: 0.224
Epoch:86 [300/412], Loss: 0.194
Epoch:86 [310/412], Loss: 0.146
Epoch:86 [320/412], Loss: 0.201
Epoch:86 [330/412], Loss: 0.264
Epoch:86 [340/412], Loss: 0.248
Epoch:86 [350/412], Loss: 0.132
Epoch:86 [360/412], Loss: 0.215
Epoch:86 [370/412], Loss: 0.398
Epoch:86 [380/412], Loss: 0.176
Epoch:86 [390/412], Loss: 0.265
Epoch:86 [400/412], Loss: 0.381
Epoch:86 [410/412], Loss: 0.137
Epoch:86, Train IoU: [0.98471371 0.87298194 0.89623697]
Epoch:86, Valid Loss: 0.141, mIoU: 0.9311917803955261
Validation metric decreased (0.151756 --> 0.140755).  Saving model ...
Epoch:87 [0/412], Loss: 0.291
Epoch:87 [10/412], Loss: 0.396
Epoch:87 [20/412], Loss: 0.166
Epoch:87 [30/412], Loss: 0.212
Epoch:87 [40/412], Loss: 0.169
Epoch:87 [50/412], Loss: 0.186
Epoch:87 [60/412], Loss: 0.240
Epoch:87 [70/412], Loss: 0.578
Epoch:87 [80/412], Loss: 0.107
Epoch:87 [90/412], Loss: 0.271
Epoch:87 [100/412], Loss: 0.338
Epoch:87 [110/412], Loss: 0.272
Epoch:87 [120/412], Loss: 0.096
Epoch:87 [130/412], Loss: 0.211
Epoch:87 [140/412], Loss: 0.183
Epoch:87 [150/412], Loss: 0.214
Epoch:87 [160/412], Loss: 0.432
Epoch:87 [170/412], Loss: 0.349
Epoch:87 [180/412], Loss: 0.475
Epoch:87 [190/412], Loss: 0.259
Epoch:87 [200/412], Loss: 0.221
Epoch:87 [210/412], Loss: 0.254
Epoch:87 [220/412], Loss: 0.094
Epoch:87 [230/412], Loss: 0.180
Epoch:87 [240/412], Loss: 0.328
Epoch:87 [250/412], Loss: 0.272
Epoch:87 [260/412], Loss: 0.424
Epoch:87 [270/412], Loss: 0.243
Epoch:87 [280/412], Loss: 0.401
Epoch:87 [290/412], Loss: 0.189
Epoch:87 [300/412], Loss: 0.050
Epoch:87 [310/412], Loss: 0.278
Epoch:87 [320/412], Loss: 0.396
Epoch:87 [330/412], Loss: 0.144
Epoch:87 [340/412], Loss: 0.229
Epoch:87 [350/412], Loss: 0.357
Epoch:87 [360/412], Loss: 0.258
Epoch:87 [370/412], Loss: 0.136
Epoch:87 [380/412], Loss: 0.075
Epoch:87 [390/412], Loss: 0.293
Epoch:87 [400/412], Loss: 0.202
Epoch:87 [410/412], Loss: 0.085
Epoch:87, Train IoU: [0.98478301 0.87321601 0.89672488]
Epoch:87, Valid Loss: 0.130, mIoU: 0.9311935791761851
Validation metric decreased (0.140755 --> 0.129763).  Saving model ...
Epoch:88 [0/412], Loss: 0.324
Epoch:88 [10/412], Loss: 0.143
Epoch:88 [20/412], Loss: 0.270
Epoch:88 [30/412], Loss: 0.268
Epoch:88 [40/412], Loss: 0.525
Epoch:88 [50/412], Loss: 0.119
Epoch:88 [60/412], Loss: 0.373
Epoch:88 [70/412], Loss: 0.311
Epoch:88 [80/412], Loss: 0.288
Epoch:88 [90/412], Loss: 0.408
Epoch:88 [100/412], Loss: 0.196
Epoch:88 [110/412], Loss: 0.367
Epoch:88 [120/412], Loss: 0.088
Epoch:88 [130/412], Loss: 0.144
Epoch:88 [140/412], Loss: 0.113
Epoch:88 [150/412], Loss: 0.148
Epoch:88 [160/412], Loss: 0.160
Epoch:88 [170/412], Loss: 0.202
Epoch:88 [180/412], Loss: 0.202
Epoch:88 [190/412], Loss: 0.226
Epoch:88 [200/412], Loss: 0.301
Epoch:88 [210/412], Loss: 0.210
Epoch:88 [220/412], Loss: 0.258
Epoch:88 [230/412], Loss: 0.273
Epoch:88 [240/412], Loss: 0.382
Epoch:88 [250/412], Loss: 0.372
Epoch:88 [260/412], Loss: 0.242
Epoch:88 [270/412], Loss: 0.312
Epoch:88 [280/412], Loss: 0.211
Epoch:88 [290/412], Loss: 0.094
Epoch:88 [300/412], Loss: 0.237
Epoch:88 [310/412], Loss: 0.328
Epoch:88 [320/412], Loss: 0.378
Epoch:88 [330/412], Loss: 0.289
Epoch:88 [340/412], Loss: 0.084
Epoch:88 [350/412], Loss: 0.215
Epoch:88 [360/412], Loss: 0.289
Epoch:88 [370/412], Loss: 0.368
Epoch:88 [380/412], Loss: 0.306
Epoch:88 [390/412], Loss: 0.289
Epoch:88 [400/412], Loss: 0.240
Epoch:88 [410/412], Loss: 0.142
Epoch:88, Train IoU: [0.98468286 0.87260089 0.89634275]
Epoch:88, Valid Loss: 0.119, mIoU: 0.931196319199334
Validation metric decreased (0.129763 --> 0.118763).  Saving model ...
Epoch:89 [0/412], Loss: 0.297
Epoch:89 [10/412], Loss: 0.413
Epoch:89 [20/412], Loss: 0.327
Epoch:89 [30/412], Loss: 0.135
Epoch:89 [40/412], Loss: 0.316
Epoch:89 [50/412], Loss: 0.009
Epoch:89 [60/412], Loss: 0.255
Epoch:89 [70/412], Loss: 0.356
Epoch:89 [80/412], Loss: 0.229
Epoch:89 [90/412], Loss: 0.311
Epoch:89 [100/412], Loss: 0.414
Epoch:89 [110/412], Loss: 0.423
Epoch:89 [120/412], Loss: 0.336
Epoch:89 [130/412], Loss: 0.377
Epoch:89 [140/412], Loss: 0.370
Epoch:89 [150/412], Loss: 0.292
Epoch:89 [160/412], Loss: 0.243
Epoch:89 [170/412], Loss: 0.239
Epoch:89 [180/412], Loss: 0.115
Epoch:89 [190/412], Loss: 0.283
Epoch:89 [200/412], Loss: 0.268
Epoch:89 [210/412], Loss: 0.405
Epoch:89 [220/412], Loss: 0.264
Epoch:89 [230/412], Loss: 0.470
Epoch:89 [240/412], Loss: 0.272
Epoch:89 [250/412], Loss: 0.138
Epoch:89 [260/412], Loss: 0.123
Epoch:89 [270/412], Loss: 0.304
Epoch:89 [280/412], Loss: 0.163
Epoch:89 [290/412], Loss: 0.049
Epoch:89 [300/412], Loss: 0.301
Epoch:89 [310/412], Loss: 0.431
Epoch:89 [320/412], Loss: 0.172
Epoch:89 [330/412], Loss: 0.250
Epoch:89 [340/412], Loss: 0.188
Epoch:89 [350/412], Loss: 0.330
Epoch:89 [360/412], Loss: 0.383
Epoch:89 [370/412], Loss: 0.185
Epoch:89 [380/412], Loss: 0.293
Epoch:89 [390/412], Loss: 0.118
Epoch:89 [400/412], Loss: 0.283
Epoch:89 [410/412], Loss: 0.314
Epoch:89, Train IoU: [0.98473336 0.87286172 0.89647547]
Epoch:89, Valid Loss: 0.108, mIoU: 0.9312019157724034
Validation metric decreased (0.118763 --> 0.107774).  Saving model ...
Epoch:90 [0/412], Loss: 0.091
Epoch:90 [10/412], Loss: 0.051
Epoch:90 [20/412], Loss: 0.237
Epoch:90 [30/412], Loss: 0.133
Epoch:90 [40/412], Loss: 0.456
Epoch:90 [50/412], Loss: 0.114
Epoch:90 [60/412], Loss: 0.141
Epoch:90 [70/412], Loss: 0.200
Epoch:90 [80/412], Loss: 0.126
Epoch:90 [90/412], Loss: -0.037
Epoch:90 [100/412], Loss: 0.123
Epoch:90 [110/412], Loss: 0.139
Epoch:90 [120/412], Loss: 0.250
Epoch:90 [130/412], Loss: 0.307
Epoch:90 [140/412], Loss: -0.011
Epoch:90 [150/412], Loss: 0.171
Epoch:90 [160/412], Loss: 0.018
Epoch:90 [170/412], Loss: 0.214
Epoch:90 [180/412], Loss: 0.083
Epoch:90 [190/412], Loss: 0.257
Epoch:90 [200/412], Loss: 0.169
Epoch:90 [210/412], Loss: 0.561
Epoch:90 [220/412], Loss: 0.205
Epoch:90 [230/412], Loss: 0.099
Epoch:90 [240/412], Loss: 0.344
Epoch:90 [250/412], Loss: 0.134
Epoch:90 [260/412], Loss: 0.065
Epoch:90 [270/412], Loss: 0.206
Epoch:90 [280/412], Loss: 0.087
Epoch:90 [290/412], Loss: 0.196
Epoch:90 [300/412], Loss: 0.162
Epoch:90 [310/412], Loss: 0.162
Epoch:90 [320/412], Loss: 0.314
Epoch:90 [330/412], Loss: 0.206
Epoch:90 [340/412], Loss: -0.002
Epoch:90 [350/412], Loss: 0.246
Epoch:90 [360/412], Loss: 0.264
Epoch:90 [370/412], Loss: 0.200
Epoch:90 [380/412], Loss: 0.138
Epoch:90 [390/412], Loss: 0.090
Epoch:90 [400/412], Loss: 0.210
Epoch:90 [410/412], Loss: 0.119
Epoch:90, Train IoU: [0.98468632 0.87307164 0.89698549]
Epoch:90, Valid Loss: 0.097, mIoU: 0.9311991812449419
Validation metric decreased (0.107774 --> 0.096759).  Saving model ...
Epoch:91 [0/412], Loss: 0.113
Epoch:91 [10/412], Loss: 0.287
Epoch:91 [20/412], Loss: 0.195
Epoch:91 [30/412], Loss: 0.200
Epoch:91 [40/412], Loss: 0.335
Epoch:91 [50/412], Loss: 0.193
Epoch:91 [60/412], Loss: 0.322
Epoch:91 [70/412], Loss: 0.298
Epoch:91 [80/412], Loss: 0.247
Epoch:91 [90/412], Loss: 0.052
Epoch:91 [100/412], Loss: 0.399
Epoch:91 [110/412], Loss: 0.251
Epoch:91 [120/412], Loss: 0.250
Epoch:91 [130/412], Loss: 0.223
Epoch:91 [140/412], Loss: 0.190
Epoch:91 [150/412], Loss: 0.226
Epoch:91 [160/412], Loss: 0.119
Epoch:91 [170/412], Loss: 0.195
Epoch:91 [180/412], Loss: 0.238
Epoch:91 [190/412], Loss: 0.105
Epoch:91 [200/412], Loss: 0.413
Epoch:91 [210/412], Loss: 0.278
Epoch:91 [220/412], Loss: 0.366
Epoch:91 [230/412], Loss: 0.264
Epoch:91 [240/412], Loss: 0.295
Epoch:91 [250/412], Loss: 0.174
Epoch:91 [260/412], Loss: 0.125
Epoch:91 [270/412], Loss: 0.254
Epoch:91 [280/412], Loss: 0.521
Epoch:91 [290/412], Loss: 0.138
Epoch:91 [300/412], Loss: 0.323
Epoch:91 [310/412], Loss: 0.209
Epoch:91 [320/412], Loss: 0.206
Epoch:91 [330/412], Loss: 0.115
Epoch:91 [340/412], Loss: 0.263
Epoch:91 [350/412], Loss: 0.246
Epoch:91 [360/412], Loss: 0.120
Epoch:91 [370/412], Loss: 0.248
Epoch:91 [380/412], Loss: 0.209
Epoch:91 [390/412], Loss: 0.217
Epoch:91 [400/412], Loss: 0.066
Epoch:91 [410/412], Loss: 0.104
Epoch:91, Train IoU: [0.98472435 0.87284029 0.89663421]
Epoch:91, Valid Loss: 0.086, mIoU: 0.9312008730476878
Validation metric decreased (0.096759 --> 0.085742).  Saving model ...
Epoch:92 [0/412], Loss: 0.117
Epoch:92 [10/412], Loss: 0.059
Epoch:92 [20/412], Loss: 0.095
Epoch:92 [30/412], Loss: 0.218
Epoch:92 [40/412], Loss: 0.264
Epoch:92 [50/412], Loss: 0.066
Epoch:92 [60/412], Loss: 0.237
Epoch:92 [70/412], Loss: 0.139
Epoch:92 [80/412], Loss: 0.314
Epoch:92 [90/412], Loss: 0.234
Epoch:92 [100/412], Loss: 0.160
Epoch:92 [110/412], Loss: 0.238
Epoch:92 [120/412], Loss: 0.117
Epoch:92 [130/412], Loss: 0.258
Epoch:92 [140/412], Loss: 0.155
Epoch:92 [150/412], Loss: 0.263
Epoch:92 [160/412], Loss: 0.180
Epoch:92 [170/412], Loss: 0.151
Epoch:92 [180/412], Loss: 0.119
Epoch:92 [190/412], Loss: 0.208
Epoch:92 [200/412], Loss: 0.118
Epoch:92 [210/412], Loss: 0.140
Epoch:92 [220/412], Loss: 0.222
Epoch:92 [230/412], Loss: 0.277
Epoch:92 [240/412], Loss: 0.306
Epoch:92 [250/412], Loss: 0.181
Epoch:92 [260/412], Loss: 0.380
Epoch:92 [270/412], Loss: 0.320
Epoch:92 [280/412], Loss: 0.070
Epoch:92 [290/412], Loss: 0.191
Epoch:92 [300/412], Loss: 0.176
Epoch:92 [310/412], Loss: 0.193
Epoch:92 [320/412], Loss: 0.453
Epoch:92 [330/412], Loss: 0.361
Epoch:92 [340/412], Loss: 0.114
Epoch:92 [350/412], Loss: 0.239
Epoch:92 [360/412], Loss: 0.122
Epoch:92 [370/412], Loss: 0.133
Epoch:92 [380/412], Loss: 0.207
Epoch:92 [390/412], Loss: 0.302
Epoch:92 [400/412], Loss: 0.185
Epoch:92 [410/412], Loss: 0.280
Epoch:92, Train IoU: [0.98481862 0.87324007 0.8967615 ]
Epoch:92, Valid Loss: 0.075, mIoU: 0.9312009546773371
Validation metric decreased (0.085742 --> 0.074732).  Saving model ...
Epoch:93 [0/412], Loss: 0.159
Epoch:93 [10/412], Loss: 0.056
Epoch:93 [20/412], Loss: 0.116
Epoch:93 [30/412], Loss: 0.100
Epoch:93 [40/412], Loss: 0.215
Epoch:93 [50/412], Loss: 0.281
Epoch:93 [60/412], Loss: 0.254
Epoch:93 [70/412], Loss: 0.153
Epoch:93 [80/412], Loss: 0.034
Epoch:93 [90/412], Loss: 0.211
Epoch:93 [100/412], Loss: 0.150
Epoch:93 [110/412], Loss: 0.125
Epoch:93 [120/412], Loss: 0.239
Epoch:93 [130/412], Loss: 0.248
Epoch:93 [140/412], Loss: 0.114
Epoch:93 [150/412], Loss: 0.106
Epoch:93 [160/412], Loss: 0.132
Epoch:93 [170/412], Loss: 0.466
Epoch:93 [180/412], Loss: 0.309
Epoch:93 [190/412], Loss: 0.352
Epoch:93 [200/412], Loss: 0.238
Epoch:93 [210/412], Loss: 0.045
Epoch:93 [220/412], Loss: 0.285
Epoch:93 [230/412], Loss: 0.187
Epoch:93 [240/412], Loss: 0.144
Epoch:93 [250/412], Loss: 0.089
Epoch:93 [260/412], Loss: 0.100
Epoch:93 [270/412], Loss: 0.118
Epoch:93 [280/412], Loss: 0.155
Epoch:93 [290/412], Loss: 0.226
Epoch:93 [300/412], Loss: 0.155
Epoch:93 [310/412], Loss: 0.171
Epoch:93 [320/412], Loss: 0.189
Epoch:93 [330/412], Loss: 0.192
Epoch:93 [340/412], Loss: 0.398
Epoch:93 [350/412], Loss: 0.138
Epoch:93 [360/412], Loss: 0.183
Epoch:93 [370/412], Loss: 0.218
Epoch:93 [380/412], Loss: 0.079
Epoch:93 [390/412], Loss: 0.118
Epoch:93 [400/412], Loss: 0.167
Epoch:93 [410/412], Loss: -0.058
Epoch:93, Train IoU: [0.98476137 0.87308586 0.89655178]
Epoch:93, Valid Loss: 0.064, mIoU: 0.9311995899208133
Validation metric decreased (0.074732 --> 0.063722).  Saving model ...
Epoch:94 [0/412], Loss: 0.164
Epoch:94 [10/412], Loss: 0.030
Epoch:94 [20/412], Loss: 0.303
Epoch:94 [30/412], Loss: 0.303
Epoch:94 [40/412], Loss: 0.065
Epoch:94 [50/412], Loss: 0.118
Epoch:94 [60/412], Loss: 0.462
Epoch:94 [70/412], Loss: 0.129
Epoch:94 [80/412], Loss: 0.172
Epoch:94 [90/412], Loss: 0.147
Epoch:94 [100/412], Loss: 0.032
Epoch:94 [110/412], Loss: 0.165
Epoch:94 [120/412], Loss: 0.107
Epoch:94 [130/412], Loss: 0.252
Epoch:94 [140/412], Loss: 0.129
Epoch:94 [150/412], Loss: 0.123
Epoch:94 [160/412], Loss: 0.192
Epoch:94 [170/412], Loss: 0.193
Epoch:94 [180/412], Loss: 0.325
Epoch:94 [190/412], Loss: 0.252
Epoch:94 [200/412], Loss: 0.156
Epoch:94 [210/412], Loss: 0.133
Epoch:94 [220/412], Loss: 0.115
Epoch:94 [230/412], Loss: 0.488
Epoch:94 [240/412], Loss: 0.011
Epoch:94 [250/412], Loss: 0.366
Epoch:94 [260/412], Loss: 0.154
Epoch:94 [270/412], Loss: 0.173
Epoch:94 [280/412], Loss: 0.258
Epoch:94 [290/412], Loss: 0.016
Epoch:94 [300/412], Loss: 0.205
Epoch:94 [310/412], Loss: 0.070
Epoch:94 [320/412], Loss: 0.276
Epoch:94 [330/412], Loss: 0.124
Epoch:94 [340/412], Loss: 0.294
Epoch:94 [350/412], Loss: 0.062
Epoch:94 [360/412], Loss: 0.099
Epoch:94 [370/412], Loss: 0.164
Epoch:94 [380/412], Loss: 0.209
Epoch:94 [390/412], Loss: 0.150
Epoch:94 [400/412], Loss: 0.211
Epoch:94 [410/412], Loss: 0.184
Epoch:94, Train IoU: [0.98478904 0.87324947 0.89647843]
Epoch:94, Valid Loss: 0.053, mIoU: 0.9311964441263308
Validation metric decreased (0.063722 --> 0.052709).  Saving model ...
Epoch:95 [0/412], Loss: 0.118
Epoch:95 [10/412], Loss: 0.087
Epoch:95 [20/412], Loss: 0.174
Epoch:95 [30/412], Loss: 0.192
Epoch:95 [40/412], Loss: 0.052
Epoch:95 [50/412], Loss: 0.244
Epoch:95 [60/412], Loss: 0.048
Epoch:95 [70/412], Loss: 0.234
Epoch:95 [80/412], Loss: 0.192
Epoch:95 [90/412], Loss: 0.181
Epoch:95 [100/412], Loss: 0.162
Epoch:95 [110/412], Loss: 0.316
Epoch:95 [120/412], Loss: 0.100
Epoch:95 [130/412], Loss: 0.233
Epoch:95 [140/412], Loss: 0.197
Epoch:95 [150/412], Loss: 0.069
Epoch:95 [160/412], Loss: 0.192
Epoch:95 [170/412], Loss: 0.121
Epoch:95 [180/412], Loss: 0.001
Epoch:95 [190/412], Loss: 0.102
Epoch:95 [200/412], Loss: 0.203
Epoch:95 [210/412], Loss: 0.225
Epoch:95 [220/412], Loss: 0.020
Epoch:95 [230/412], Loss: 0.202
Epoch:95 [240/412], Loss: 0.195
Epoch:95 [250/412], Loss: 0.439
Epoch:95 [260/412], Loss: 0.085
Epoch:95 [270/412], Loss: 0.098
Epoch:95 [280/412], Loss: 0.315
Epoch:95 [290/412], Loss: 0.180
Epoch:95 [300/412], Loss: 0.174
Epoch:95 [310/412], Loss: 0.122
Epoch:95 [320/412], Loss: 0.066
Epoch:95 [330/412], Loss: 0.042
Epoch:95 [340/412], Loss: 0.149
Epoch:95 [350/412], Loss: 0.227
Epoch:95 [360/412], Loss: 0.142
Epoch:95 [370/412], Loss: 0.151
Epoch:95 [380/412], Loss: -0.036
Epoch:95 [390/412], Loss: 0.159
Epoch:95 [400/412], Loss: 0.233
Epoch:95 [410/412], Loss: 0.140
Epoch:95, Train IoU: [0.98469135 0.87258354 0.89602468]
Epoch:95, Valid Loss: 0.042, mIoU: 0.9311982315730308
Validation metric decreased (0.052709 --> 0.041695).  Saving model ...
Epoch:96 [0/412], Loss: 0.078
Epoch:96 [10/412], Loss: 0.105
Epoch:96 [20/412], Loss: 0.090
Epoch:96 [30/412], Loss: 0.158
Epoch:96 [40/412], Loss: 0.223
Epoch:96 [50/412], Loss: 0.046
Epoch:96 [60/412], Loss: 0.029
Epoch:96 [70/412], Loss: 0.107
Epoch:96 [80/412], Loss: 0.114
Epoch:96 [90/412], Loss: 0.130
Epoch:96 [100/412], Loss: 0.192
Epoch:96 [110/412], Loss: 0.354
Epoch:96 [120/412], Loss: 0.101
Epoch:96 [130/412], Loss: 0.093
Epoch:96 [140/412], Loss: 0.406
Epoch:96 [150/412], Loss: 0.210
Epoch:96 [160/412], Loss: 0.276
Epoch:96 [170/412], Loss: 0.164
Epoch:96 [180/412], Loss: 0.170
Epoch:96 [190/412], Loss: -0.033
Epoch:96 [200/412], Loss: -0.049
Epoch:96 [210/412], Loss: 0.095
Epoch:96 [220/412], Loss: 0.058
Epoch:96 [230/412], Loss: 0.238
Epoch:96 [240/412], Loss: 0.150
Epoch:96 [250/412], Loss: 0.119
Epoch:96 [260/412], Loss: 0.073
Epoch:96 [270/412], Loss: 0.225
Epoch:96 [280/412], Loss: 0.051
Epoch:96 [290/412], Loss: 0.241
Epoch:96 [300/412], Loss: 0.121
Epoch:96 [310/412], Loss: -0.081
Epoch:96 [320/412], Loss: 0.059
Epoch:96 [330/412], Loss: 0.042
Epoch:96 [340/412], Loss: 0.079
Epoch:96 [350/412], Loss: 0.202
Epoch:96 [360/412], Loss: 0.155
Epoch:96 [370/412], Loss: 0.039
Epoch:96 [380/412], Loss: 0.504
Epoch:96 [390/412], Loss: 0.077
Epoch:96 [400/412], Loss: 0.225
Epoch:96 [410/412], Loss: 0.176
Epoch:96, Train IoU: [0.98475572 0.87309122 0.89621945]
Epoch:96, Valid Loss: 0.031, mIoU: 0.9312003231183265
Validation metric decreased (0.041695 --> 0.030677).  Saving model ...
Epoch:97 [0/412], Loss: 0.089
Epoch:97 [10/412], Loss: -0.000
Epoch:97 [20/412], Loss: 0.730
Epoch:97 [30/412], Loss: 0.033
Epoch:97 [40/412], Loss: 0.120
Epoch:97 [50/412], Loss: -0.042
Epoch:97 [60/412], Loss: 0.211
Epoch:97 [70/412], Loss: 0.058
Epoch:97 [80/412], Loss: 0.117
Epoch:97 [90/412], Loss: 0.041
Epoch:97 [100/412], Loss: 0.036
Epoch:97 [110/412], Loss: 0.194
Epoch:97 [120/412], Loss: 0.145
Epoch:97 [130/412], Loss: 0.345
Epoch:97 [140/412], Loss: 0.241
Epoch:97 [150/412], Loss: 0.160
Epoch:97 [160/412], Loss: 0.306
Epoch:97 [170/412], Loss: 0.243
Epoch:97 [180/412], Loss: 0.162
Epoch:97 [190/412], Loss: -0.063
Epoch:97 [200/412], Loss: 0.224
Epoch:97 [210/412], Loss: 0.049
Epoch:97 [220/412], Loss: 0.222
Epoch:97 [230/412], Loss: -0.111
Epoch:97 [240/412], Loss: 0.090
Epoch:97 [250/412], Loss: 0.137
Epoch:97 [260/412], Loss: -0.031
Epoch:97 [270/412], Loss: 0.015
Epoch:97 [280/412], Loss: 0.243
Epoch:97 [290/412], Loss: 0.091
Epoch:97 [300/412], Loss: 0.139
Epoch:97 [310/412], Loss: 0.128
Epoch:97 [320/412], Loss: 0.193
Epoch:97 [330/412], Loss: 0.181
Epoch:97 [340/412], Loss: 0.099
Epoch:97 [350/412], Loss: 0.290
Epoch:97 [360/412], Loss: 0.118
Epoch:97 [370/412], Loss: 0.063
Epoch:97 [380/412], Loss: 0.326
Epoch:97 [390/412], Loss: 0.057
Epoch:97 [400/412], Loss: 0.144
Epoch:97 [410/412], Loss: 0.222
Epoch:97, Train IoU: [0.98476574 0.87328348 0.89634726]
Epoch:97, Valid Loss: 0.020, mIoU: 0.9312018565225854
Validation metric decreased (0.030677 --> 0.019664).  Saving model ...
Epoch:98 [0/412], Loss: 0.137
Epoch:98 [10/412], Loss: -0.047
Epoch:98 [20/412], Loss: 0.193
Epoch:98 [30/412], Loss: 0.053
Epoch:98 [40/412], Loss: 0.146
Epoch:98 [50/412], Loss: 0.100
Epoch:98 [60/412], Loss: 0.171
Epoch:98 [70/412], Loss: 0.194
Epoch:98 [80/412], Loss: 0.249
Epoch:98 [90/412], Loss: 0.076
Epoch:98 [100/412], Loss: 0.554
Epoch:98 [110/412], Loss: 0.226
Epoch:98 [120/412], Loss: 0.165
Epoch:98 [130/412], Loss: 0.171
Epoch:98 [140/412], Loss: -0.058
Epoch:98 [150/412], Loss: 0.128
Epoch:98 [160/412], Loss: 0.071
Epoch:98 [170/412], Loss: 0.268
Epoch:98 [180/412], Loss: 0.217
Epoch:98 [190/412], Loss: 0.033
Epoch:98 [200/412], Loss: 0.120
Epoch:98 [210/412], Loss: 0.115
Epoch:98 [220/412], Loss: 0.134
Epoch:98 [230/412], Loss: 0.200
Epoch:98 [240/412], Loss: 0.240
Epoch:98 [250/412], Loss: 0.081
Epoch:98 [260/412], Loss: 0.066
Epoch:98 [270/412], Loss: 0.209
Epoch:98 [280/412], Loss: 0.133
Epoch:98 [290/412], Loss: 0.039
Epoch:98 [300/412], Loss: -0.012
Epoch:98 [310/412], Loss: 0.064
Epoch:98 [320/412], Loss: 0.036
Epoch:98 [330/412], Loss: 0.284
Epoch:98 [340/412], Loss: 0.124
Epoch:98 [350/412], Loss: 0.061
Epoch:98 [360/412], Loss: 0.245
Epoch:98 [370/412], Loss: 0.108
Epoch:98 [380/412], Loss: 0.160
Epoch:98 [390/412], Loss: 0.153
Epoch:98 [400/412], Loss: 0.284
Epoch:98 [410/412], Loss: 0.200
Epoch:98, Train IoU: [0.98479974 0.87326488 0.89635664]
Epoch:98, Valid Loss: 0.009, mIoU: 0.9311994098077684
Validation metric decreased (0.019664 --> 0.008639).  Saving model ...
Epoch:99 [0/412], Loss: 0.086
Epoch:99 [10/412], Loss: -0.001
Epoch:99 [20/412], Loss: -0.020
Epoch:99 [30/412], Loss: -0.037
Epoch:99 [40/412], Loss: 0.084
Epoch:99 [50/412], Loss: 0.246
Epoch:99 [60/412], Loss: 0.102
Epoch:99 [70/412], Loss: -0.027
Epoch:99 [80/412], Loss: 0.150
Epoch:99 [90/412], Loss: 0.264
Epoch:99 [100/412], Loss: 0.084
Epoch:99 [110/412], Loss: 0.214
Epoch:99 [120/412], Loss: 0.070
Epoch:99 [130/412], Loss: 0.124
Epoch:99 [140/412], Loss: 0.158
Epoch:99 [150/412], Loss: 0.061
Epoch:99 [160/412], Loss: 0.028
Epoch:99 [170/412], Loss: 0.185
Epoch:99 [180/412], Loss: 0.170
Epoch:99 [190/412], Loss: 0.131
Epoch:99 [200/412], Loss: 0.059
Epoch:99 [210/412], Loss: 0.136
Epoch:99 [220/412], Loss: 0.253
Epoch:99 [230/412], Loss: 0.092
Epoch:99 [240/412], Loss: 0.236
Epoch:99 [250/412], Loss: 0.208
Epoch:99 [260/412], Loss: 0.151
Epoch:99 [270/412], Loss: 0.198
Epoch:99 [280/412], Loss: 0.180
Epoch:99 [290/412], Loss: 0.036
Epoch:99 [300/412], Loss: 0.179
Epoch:99 [310/412], Loss: 0.207
Epoch:99 [320/412], Loss: 0.130
Epoch:99 [330/412], Loss: 0.050
Epoch:99 [340/412], Loss: 0.106
Epoch:99 [350/412], Loss: 0.324
Epoch:99 [360/412], Loss: 0.122
Epoch:99 [370/412], Loss: 0.148
Epoch:99 [380/412], Loss: 0.217
Epoch:99 [390/412], Loss: 0.104
Epoch:99 [400/412], Loss: -0.011
Epoch:99 [410/412], Loss: 0.150
Epoch:99, Train IoU: [0.98471923 0.87319568 0.89691649]
Epoch:99, Valid Loss: -0.002, mIoU: 0.9311992841962002
Validation metric decreased (0.008639 --> -0.002388).  Saving model ...
